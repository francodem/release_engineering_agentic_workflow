{
  "name": "re_agent",
  "nodes": [
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.4,
      "position": [
        -128,
        -352
      ],
      "id": "ae95f14c-3603-4171-944f-2b7d94a366b8",
      "name": "When chat message received",
      "webhookId": "630dbc32-417a-4456-a8c1-b9f3b0906e16"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "temperature": 0.1,
          "topK": 1,
          "topP": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        96,
        -128
      ],
      "id": "63512c83-cd9f-470d-9b4c-ccf64d51798d",
      "name": "Google Vertex Chat Model",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}{{ JSON.stringify($json.output) }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=You're called TA-01 Agent. You are an agent restricted to assisting communication support on Microsoft Teams. \nYour only responsibilities are:\n- Obtaining the Microsoft Teams post ID.\n- Obtaining the replies to that post.\n- Determining whether a SCRUM Master has given approval to start a deployment.\n\nYou must never generate explanations or text outside the required JSON response.\n\nThe tool for retrieving a post ID is:\n\"TA-01 - Get Microsoft Teams post ID\"\n\nThe tool for retrieving replies is:\n\"TA-01 - Get Microsoft Teams post replies\"\n\nYou must always call the post ID tool first, and only after obtaining the post ID may you call the replies tool.\n\n---\n\n## TRIGGERS\n\nYou will receive JSON input in one of the following forms:\n\n1. {\n     \"command\": \"start\",\n     \"conversation_thread_title\": \"Mxxx.x.x ABC Abcde Example\"\n   }\n\n2. {\n     \"command\": \"check_again\",\n     \"conversation_thread_title\": \"Mxxx.x.x ABC Abcde Example\"\n   }\n\nRules:\n- If \"command\" = \"start\", begin the evaluation process.\n- If \"command\" = \"check_again\", repeat the evaluation by querying the post ID again and then the replies again.\n\n---\n\n## INSTRUCTIONS\n\n1. Using the conversation_thread_title value:\n   - Call the tool **TA-01 - Get Microsoft Teams post ID**.\n   - Identify the post whose title matches or closely resembles the provided conversation_thread_title.\n   - Extract its post ID.\n\n2. After obtaining the post ID:\n   - Call the tool **TA-01 - Get Microsoft Teams post replies**.\n   - Retrieve all replies associated with that post ID.\n\n3. Analyze the replies:\n   - Determine whether any reply is authored by a user whose role contains \"SCRUM Master\" (any capitalization allowed).\n   - Determine whether the reply expresses approval to begin the deployment.\n\n4. If such approval exists:\n   - Return JSON with message_available = true,\n     can_start = true,\n     reason = the SCRUM Master reply content,\n     component_id = the component ID extracted from the post content if applicable,\n     conversation_thread_title = the same title received.\n\n5. If no approval is found:\n   - Return JSON with message_available = true,\n     can_start = false,\n     reason = the most relevant reply or null,\n     component_id = null or inferred if appropriate,\n     conversation_thread_title = the title received.\n\n---\n\n## CONSIDERATIONS\n\n- You must always obtain the post ID **before** querying replies.\n- You must always use the provided tools; do not infer data not provided by the tools.\n- Each time you receive \"check_again\", you must:\n  - Fetch the post ID again.\n  - Fetch replies again.\n  - Reevaluate the SCRUM Master approval.\n- If you determine approval exists, always include the component_id value extracted from the post or from context if available.\n\n---\n\n## SUCCESS CRITERIA\n\n- A SCRUM Master reply clearly granting approval results in:\n  \"message_available\": true,\n  \"deployment.can_start\": true.\n\n- If no reply grants approval:\n  \"message_available\": true,\n  \"deployment.can_start\": false.\n\n- If no post or no messages are found:\n  \"message_available\": false,\n  deployment fields must be null.\n\n---\n\n## RESPONSE FORMAT\n\nYour output must always be one JSON object with this structure:\n\n{\n  \"message_available\": boolean,\n  \"deployment\": {\n    \"can_start\": boolean_or_null,\n    \"reason\": string_or_null,\n    \"component_id\": string_or_null,\n    \"conversation_thread_title\": string_or_null\n  }\n}\n\nRespect the boolean types; do not use quoted strings like \"true\" or \"false\".\n\nReturn only valid JSON. No explanations. No markdown.\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        288,
        -352
      ],
      "id": "9a28ccb5-7194-4bae-b857-ace26f53373e",
      "name": "(TA-01) Teams Agent",
      "retryOnFail": true,
      "maxTries": 5,
      "waitBetweenTries": 500,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "contextWindowLength": 50
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        224,
        -128
      ],
      "id": "f18b6d95-ae8c-4bf5-993f-cac703750511",
      "name": "TA-01"
    },
    {
      "parameters": {
        "toolDescription": "This tool retrieves all the post IDs.\n\nReturns\n- All the post IDs.",
        "url": "http://192.168.0.214:8000/api/posts",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.3,
      "position": [
        352,
        -128
      ],
      "id": "40be878d-dbe0-4658-b4e6-75d57f5190c1",
      "name": "TA-01 - Get Microsoft Teams post ID"
    },
    {
      "parameters": {
        "toolDescription": "This tool retrieves all the replies from a post ID.\n\nArguments\n- Post ID\n\nReturns\n- All the post replies.\n\nNotes\n- Use the following link using the Post ID argument.\nBASE LINK\nhttp://192.168.0.214:8000/api/posts/<POST_ID>/replies",
        "url": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('URL', ``, 'string') }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.3,
      "position": [
        480,
        -128
      ],
      "id": "262128ac-43eb-444b-9686-15be6a696a02",
      "name": "TA-01 - Get Microsoft Teams post replies"
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"message_available\": \"bool\",\n  \"deployment\": {\n    \"can_start\": \"bool\",\n    \"reason\": \"string\",\n    \"component_id\": \"string\",\n    \"conversation_thread_title\": \"string\"\n  }\n}",
        "autoFix": true
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        608,
        -128
      ],
      "id": "5e0a6d26-3bce-466d-adcc-7b659ebb31e3",
      "name": "Structured Output Parser"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "461e9e9b-0f04-4b8a-aa66-e1fcdce2e653",
              "leftValue": "={{ $json.output.message_available }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        896,
        -352
      ],
      "id": "ba9df080-4dd4-4f32-9644-d79d6881125a",
      "name": "if message available"
    },
    {
      "parameters": {
        "amount": 15
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        176,
        -544
      ],
      "id": "5c0f90ad-5530-4c99-b6dc-887700f97028",
      "name": "Wait",
      "webhookId": "ac36b5a1-914f-4bf8-9fa9-89526710c89d"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\"output\":{\"command\": \"check_again\"}}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        304,
        -544
      ],
      "id": "27e66251-25a7-4dc0-b965-18927410f559",
      "name": "check_again command"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "461e9e9b-0f04-4b8a-aa66-e1fcdce2e653",
              "leftValue": "={{ $json.output.deployment.can_start }}",
              "rightValue": "",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1120,
        -352
      ],
      "id": "7bcaddbf-a583-4f55-b385-291e7c343c16",
      "name": "if we can start"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ JSON.stringify($json.output) }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=## ROLE\nYou are GAWA-01 Agent.\nYour behavior is strictly deterministic.\nYou must NEVER invent data, NEVER infer values, NEVER generate text that was not provided to you.\nYou must NEVER add fields, NEVER rename fields, NEVER change booleans into strings,\nand NEVER wrap the output inside an \"output\" object.\n\nYou must ONLY:\n1. Receive JSON.\n2. Call the tools you are instructed to call.\n3. Produce JSON with the EXACT structure defined below.\n\nIf any required value is unavailable, ALWAYS return null instead of inventing a value.\n\n---\n\n## ABSOLUTE FORMAT RULE\nYou must ALWAYS return one JSON object with EXACTLY these top-level keys:\n\n{\n  \"message_available\": boolean,\n  \"deployment\": {\n    \"can_start\": boolean_or_null,\n    \"reason\": string_or_null,\n    \"component_id\": string_or_null,\n    \"conversation_thread_title\": string_or_null\n  },\n  \"workflow\": {\n    \"build_id\": integer_or_null,\n    \"status\": \"inProgress\" | \"success\" | \"failure\",\n    \"logs\": null,\n    \"logs_url\": string_or_null\n  }\n}\n\nNO OTHER KEYS ARE ALLOWED.\nNO \"output\" object is allowed.\nNO additional fields are allowed.\nNO explanations or text are allowed.\nOutput MUST be raw JSON only.\n\n---\n\n## TOOLING AND EXECUTION LOGIC\n\n### 1. INPUT\nYou will always receive:\n{\n  \"message_available\": boolean,\n  \"deployment\": {\n    \"can_start\": boolean,\n    \"reason\": \"string\",\n    \"conversation_thread_title\": \"string\",\n    \"component_id\": \"string\"\n  }\n}\n\nExtract only component_id.\n\n### 2. START WORKFLOW\nUse the extracted component_id to call:\n\"GAWA-01 - Run GitHub Workflow Tool\"\n\nAfter triggering, call:\n\"GAWA-01 - Get GitHub Workflow Build ID Tool\"\nStore the integer returned as build_id, or null if unavailable.\n\n### 3. FIRST RESPONSE\nReturn the original input JSON, but with the required \"workflow\" object appended:\n\n{\n  ...\n  \"workflow\": {\n    \"build_id\": build_id,\n    \"status\": \"inProgress\",\n    \"logs\": null,\n    \"logs_url\": null\n  }\n}\n\n### 4. WAIT FOR CHECK\nDo NOTHING until you receive exactly:\n{\"command\": \"check_again\"}\n\n### 5. CHECK CYCLE\nUpon receiving {\"command\": \"check_again\"}:\n\nCall:\n\"GAWA-01 - Get GitHub Workflow Build ID Status Tool\"\n\nInterpretation rules:\n- If the API reports queued or in_progress → status = \"inProgress\"\n- If the API reports success → status = \"success\"\n- If the API reports failed/failure/cancelled or similar → status = \"failure\"\n\n### 6. FAILURE HANDLING\nIf status = \"failure\":\nSet logs_url to:\n\"https://api.github.com/repos/francodem/{component_id}/actions/runs/{build_id}/logs\"\n\nNEVER invent URLs.\nNEVER modify component_id or build_id.\nIf either is missing, logs_url must be null.\n\n### 7. OUTPUT RULE\nYou MUST output ONLY the JSON conforming EXACTLY to the structure defined above.\nNo text.\nNo markdown.\nNo \"output\" wrapper.\nNo invented fields.\nNo invented values."
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        1520,
        -368
      ],
      "id": "7a584854-800e-4f99-861c-ef9511c94347",
      "name": "(GAWA-01) GitHub Actions Workflow Agent",
      "retryOnFail": true,
      "maxTries": 5,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "amount": 15
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        1392,
        -560
      ],
      "id": "fdb9581a-d596-4754-b6fa-d5258000b868",
      "name": "Wait1",
      "webhookId": "ac36b5a1-914f-4bf8-9fa9-89526710c89d"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "temperature": 0.1,
          "topK": 1,
          "topP": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        1376,
        -144
      ],
      "id": "eef35469-9980-487e-9e6d-795d8c0ed380",
      "name": "Google Vertex Chat Model1",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "001",
        "contextWindowLength": "=50"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        1536,
        -144
      ],
      "id": "fe2b2441-c7cf-41fc-9590-ec4454dae31b",
      "name": "GAWA-01"
    },
    {
      "parameters": {
        "toolDescription": "This tool triggers a GitHub Actions workflow for a given component or workflow ID.\n\n## CAPABILITIES\n- Accepts a single input: `workflow_id` (string).\n- Replaces the `<workflow ID>` segment inside the base URL.\n- Calls the GitHub API to dispatch the workflow.\n- Does not return the workflow run ID. It only triggers the dispatch.\n\n## BASE URL\nhttps://api.github.com/repos/francodem/<workflow ID>/actions/workflows/lint.yml/dispatches\n\n## EXPECTED BEHAVIOR\n1. Insert the received `workflow_id` into the base URL, replacing `<workflow ID>`.\n2. Perform a POST request to the resulting endpoint.\n3. Send the payload required by GitHub Actions for workflow_dispatch:\n```json\n{\n  \"ref\": \"main\"\n}\n",
        "method": "POST",
        "url": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('URL', ``, 'string') }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "{\"ref\": \"main\"}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.3,
      "position": [
        1680,
        -144
      ],
      "id": "1d8d1369-9273-4659-9986-cb321e7bb7e2",
      "name": "GAWA-01 - Run GitHub Workflow Tool",
      "credentials": {
        "httpBearerAuth": {
          "id": "0e1X9ctixNS8P5v4",
          "name": "GitHub Classic Token"
        }
      }
    },
    {
      "parameters": {
        "toolDescription": "This tool retrieves the latest GitHub Actions workflow run ID for a specific workflow.\n\n## CAPABILITIES\n- Builds the GitHub API URL by replacing exactly the `<workflow ID>` placeholder.\n- Fetches the list of workflow runs for that workflow.\n- Returns **only the latest workflow run ID** (integer), not JSON.\n\n## BASE URL\nhttps://api.github.com/repos/francodem/<workflow ID>/actions/workflows/lint.yml/runs?per_page=1\n\n## EXPECTED BEHAVIOR\n1. Receive `workflow_id` as input.\n2. Replace the string `<workflow ID>` in the base URL with the received `workflow_id`.\n3. Call the GitHub API endpoint using the resulting URL.\n4. Read the returned list of workflow runs.\n5. Extract the `id` from the most recent run (the first item).\n6. Return **only** that ID as the tool output.\n\n## OUTPUT FORMAT\n- A single integer (the latest workflow run ID).  \n- If no runs are present, return `null`.\n\n## RULES\n- Do not return JSON.\n- Do not wrap the ID in any structure.\n- The agent must use this output directly as the `build_id`.\n",
        "url": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('URL', ``, 'string') }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "options": {},
        "optimizeResponse": true,
        "dataField": "workflow_runs",
        "fieldsToInclude": "selected",
        "fields": "=id"
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.3,
      "position": [
        1840,
        -144
      ],
      "id": "9fa391a6-340e-4f6c-8c1b-47ce238ab5c2",
      "name": "GAWA-01 - Get GitHub Workflow Build ID Tool",
      "credentials": {
        "httpBearerAuth": {
          "id": "0e1X9ctixNS8P5v4",
          "name": "GitHub Classic Token"
        }
      }
    },
    {
      "parameters": {
        "toolDescription": "This tool retrieves the execution status of a specific GitHub Actions workflow run using its build ID.\n\n## NAME\nGAWA-01 - Get GitHub Workflow Build ID Status Tool\n\n## CAPABILITIES\n- Sends a GET request to GitHub Actions for a specific workflow run.\n- Reads and extracts the run execution status.\n- Returns only the status information relevant for monitoring the workflow.\n\n## BASE URL\nhttps://api.github.com/repos/francodem/<workflow ID>/actions/runs/<build_id>\n\n## EXPECTED INPUT\n- `workflow_id` (string): the workflow identifier used to replace `<workflow ID>` in the URL.\n- `build_id` (integer): the GitHub Actions workflow run ID.\n\n## EXPECTED BEHAVIOR\n1. Replace `<workflow ID>` in the base URL with the given `workflow_id`.\n2. Replace `<build_id>` with the provided workflow run ID.\n3. Perform a GET request to the resulting URL.\n4. Inspect the response fields:\n   - `status` → possible values: `queued`, `in_progress`, `completed`\n   - `conclusion` → possible values: `success`, `failure`, `cancelled`, etc.",
        "url": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('URL', ``, 'string') }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.3,
      "position": [
        1680,
        32
      ],
      "id": "abcc9e72-08aa-4a26-8f13-2a0fa7965fe6",
      "name": "GAWA-01 - Get GitHub Workflow Build ID Status Tool",
      "credentials": {
        "httpBearerAuth": {
          "id": "0e1X9ctixNS8P5v4",
          "name": "GitHub Classic Token"
        }
      }
    },
    {
      "parameters": {
        "binaryPropertyName": "logs.zip",
        "outputPrefix": "logs"
      },
      "type": "n8n-nodes-base.compression",
      "typeVersion": 1.1,
      "position": [
        2512,
        -592
      ],
      "id": "54e66b17-e392-41a7-b6f9-62573e77126c",
      "name": "Compression"
    },
    {
      "parameters": {
        "operation": "text",
        "binaryPropertyName": "logs0",
        "destinationKey": "logs_content",
        "options": {}
      },
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1.1,
      "position": [
        2720,
        -592
      ],
      "id": "777ab2c4-2729-4dad-a26d-4997c32d7382",
      "name": "Extract from File"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\"output\":{\"command\": \"check_again\"}}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1520,
        -560
      ],
      "id": "3f60a861-9976-45a6-9ac9-098744ac0bf0",
      "name": "check_again when inProgress"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        3136,
        -576
      ],
      "id": "b96dc39a-3fd0-4b4e-b662-a57758c64ab0",
      "name": "Merge"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "461e9e9b-0f04-4b8a-aa66-e1fcdce2e653",
              "leftValue": "={{ $json.output.workflow.status.toLowerCase() }}",
              "rightValue": "successful",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2544,
        -368
      ],
      "id": "f373e4c0-3605-4a6d-b8ea-dc86e8356bfa",
      "name": "was successful"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "461e9e9b-0f04-4b8a-aa66-e1fcdce2e653",
              "leftValue": "={{ $json.output.workflow.status.toLowerCase() }}",
              "rightValue": "inprogress",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        2304,
        -384
      ],
      "id": "31980742-7709-459d-baea-c1ecce906329",
      "name": "in progress"
    },
    {
      "parameters": {
        "url": "={{ $json.output.workflow.logs_url }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBearerAuth",
        "options": {
          "response": {
            "response": {
              "responseFormat": "file",
              "outputPropertyName": "logs.zip"
            }
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.3,
      "position": [
        2304,
        -592
      ],
      "id": "c5b88a3a-0135-48c9-ab77-f3785ee74d99",
      "name": "Logs Download",
      "credentials": {
        "httpBearerAuth": {
          "id": "0e1X9ctixNS8P5v4",
          "name": "GitHub Classic Token"
        }
      }
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={\"output\": { \"logs_content\": {{JSON.stringify($json.logs_content) }}}\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        2896,
        -592
      ],
      "id": "c0742e0e-2729-44b5-acdc-6438edfe61e1",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"message_available\": \"bool\",\n  \"deployment\": {\n    \"can_start\": \"bool\",\n    \"reason\": \"string\",\n    \"component_id\": \"string\",\n    \"conversation_thread_title\": \"string\"\n  },\n  \"workflow\": {\n  \"build_id\": \"integer\",\n  \"status\": \"string\",\n  \"logs_url\": \"string\"\n  }\n}",
        "autoFix": true
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        1984,
        -160
      ],
      "id": "6d157ad0-a94b-4a1d-add7-a7c4d4d027d4",
      "name": "Structured Output Parser1"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "maxOutputTokens": 2048,
          "temperature": 1,
          "topK": 40,
          "topP": 0.9
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        3712,
        -592
      ],
      "id": "73e8d903-ecc0-4780-b7c7-b2f03d1012fe",
      "name": "VertexAI3",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "maxOutputTokens": 2048,
          "temperature": 0.1,
          "topK": 1,
          "topP": 0.1
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        4800,
        -400
      ],
      "id": "95103623-c47e-4c7d-a2f8-bb21828b65fa",
      "name": "VertexAI5",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "001"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        4992,
        -400
      ],
      "id": "8e648ffc-87ed-406a-8542-906663cfd288",
      "name": "Simple Memory5"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"ranking\": [\n    {\n      \"hypothesis_key\": \"string\",\n      \"probability\": \"float\"\n    }\n  ],\n  \"winner\": {\n    \"hypothesis_key\": \"string\",\n    \"probability\": \"float\",\n    \"justification\": \"string\"\n  },\n  \"jira\": {\n    \"summary\": \"string\",\n    \"description\": \"string\"\n  }\n}\n",
        "autoFix": true
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        5168,
        -400
      ],
      "id": "18d7a185-ad7b-4219-90c6-299e5876ab54",
      "name": "Structured Output Parser7"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## Details and All Hipothesis\n{{ JSON.stringify($json.output)}}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=You are a Hypothesis Voting Agent specialized in evaluating multiple technical hypotheses and selecting the most probable root cause of a software or CI/CD pipeline failure.\n\nYou will receive:\n1. All deployment details.\n1. Three hypotheses, each referenced by a key (h1–h3).\n2. Logs, error messages, stacktraces, or any diagnostic output, \"logs_content\" key.\n\nYour tasks:\n- Evaluate each hypothesis strictly against the logs.\n- Score each hypothesis with a probability between 0.00 and 1.00 (max 2 decimals).\n- Identify a single winner (the hypothesis best supported by the evidence).\n- Provide a short Markdown justification explaining why the winner is the strongest.\n- Generate a JIRA-ready summary and description:\n    - The summary must be concise and reflect the likely root cause.\n    - The description must be Markdown that clearly explains the selected hypothesis and the supporting evidence.\n\nRules:\n- Do NOT assume facts not present in the logs.\n- Favor hypotheses that match concrete error patterns.\n- Penalize hypotheses that contradict or ignore evidence.\n- Your tone must be concise, technical, and evidence-based.\n- Do not add extra fields or text outside the JSON.\n\nYour output must ALWAYS be a STRICTLY valid JSON object with this exact structure:\n\n{\n  \"ranking\": [\n    {\n      \"hypothesis_key\": \"string\",\n      \"probability\": float\n    }\n  ],\n  \"winner\": {\n    \"hypothesis_key\": \"string\",\n    \"probability\": float,\n    \"justification\": \"markdown string explaining why this is the best-supported hypothesis\"\n  },\n  \"jira\": {\n    \"summary\": \"string\",\n    \"description\": \"markdown string including the winning hypothesis and supporting evidence\"\n  }\n}\n"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        4896,
        -640
      ],
      "id": "1ba024a1-1d2d-4b72-a6b2-f43ad581e16b",
      "name": "Hipothesis Voting Agent",
      "retryOnFail": true,
      "maxTries": 5,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "temperature": 0.1,
          "topK": 1,
          "topP": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        5232,
        -240
      ],
      "id": "18b4260a-4039-4f4a-946a-272daa672f7a",
      "name": "Google Vertex Chat Model7",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "numberInputs": 3,
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        4336,
        -608
      ],
      "id": "32cefed7-a6ac-4a8f-9134-3c1e8561adfc",
      "name": "Merge4"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={\n\t\"hipothesis_1\": {{ JSON.stringify($json.text) }}\n} ",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4000,
        -800
      ],
      "id": "2576de27-8a59-4ada-ac19-f7d60751fc9d",
      "name": "Edit Fields1"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "maxOutputTokens": 2048,
          "temperature": 1,
          "topK": 40,
          "topP": 0.9
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        3712,
        -224
      ],
      "id": "85249626-29ce-4e32-88a2-4142c19d0103",
      "name": "VertexAI",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={\n\t\"hipothesis_2\": {{ JSON.stringify($json.text) }}\n} ",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4000,
        -432
      ],
      "id": "b335a679-167e-41fa-9f03-b44e8dc32b94",
      "name": "Edit Fields3"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "maxOutputTokens": 2048,
          "temperature": 1,
          "topK": 40,
          "topP": 0.9
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        3728,
        144
      ],
      "id": "e521c240-27e2-449e-aa2b-0ab27baf0270",
      "name": "VertexAI4",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={\n\t\"hipothesis_3\": {{ JSON.stringify($json.text) }}\n} ",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4016,
        -64
      ],
      "id": "e66a5b5a-9743-44d9-8975-35a6b51aea0c",
      "name": "Edit Fields4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a specialized hypothesis generator for debugging failures in CI/CD pipelines and software systems.\n\nYou will receive as INPUT a string containing logs, error messages, stacktraces, or any relevant output produced during a system failure.\n\nYour task is to produce ONE single technical hypothesis that is:\n- specific,\n- distinct,\n- grounded strictly in the evidence from the logs.\n\nIMPORTANT:\nPrioritize the most grounded and evidenced cause found in the logs. Only explore non-obvious angles if the error message is ambiguous or the root cause is not explicitly stated in the logs.\nEach instance of this generator must produce a hypothesis meaningfully different from what other generators might produce.\n\nThe hypothesis must be a technical explanation of:\n- what might be failing,\n- why it could be failing,\n- and which part of the logs suggest this.\n\nOUTPUT REQUIREMENTS:\nYou must return ONLY the raw plain text.\n- Do NOT return a JSON object.\n- Do NOT use any Markdown formatting (no backticks, no asterisks, no headers).\n- Do NOT include introductory text or conversational filler (e.g., \"The hypothesis is:\").\n- Maintain a concise, technical tone.\n\nLOGS:\n{{ JSON.stringify($json.output.logs_content) }}",
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3712,
        -800
      ],
      "id": "f8a86f7c-e3b9-49fe-8c8a-bc286006f49e",
      "name": "Hypothesis Generator 1"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a specialized hypothesis generator for debugging failures in CI/CD pipelines and software systems.\n\nYou will receive as INPUT a string containing logs, error messages, stacktraces, or any relevant output produced during a system failure.\n\nYour task is to produce ONE single technical hypothesis that is:\n- specific,\n- distinct,\n- grounded strictly in the evidence from the logs.\n\nIMPORTANT:\nPrioritize the most grounded and evidenced cause found in the logs. Only explore non-obvious angles if the error message is ambiguous or the root cause is not explicitly stated in the logs.\nEach instance of this generator must produce a hypothesis meaningfully different from what other generators might produce.\n\nThe hypothesis must be a technical explanation of:\n- what might be failing,\n- why it could be failing,\n- and which part of the logs suggest this.\n\nOUTPUT REQUIREMENTS:\nYou must return ONLY the raw plain text.\n- Do NOT return a JSON object.\n- Do NOT use any Markdown formatting (no backticks, no asterisks, no headers).\n- Do NOT include introductory text or conversational filler (e.g., \"The hypothesis is:\").\n- Maintain a concise, technical tone.\n\nLOGS:\n{{ JSON.stringify($json.output.logs_content) }}",
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3712,
        -432
      ],
      "id": "c132d22a-fc4c-4851-ac44-79738c198497",
      "name": "Hypothesis Generator 2"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=You are a specialized hypothesis generator for debugging failures in CI/CD pipelines and software systems.\n\nYou will receive as INPUT a string containing logs, error messages, stacktraces, or any relevant output produced during a system failure.\n\nYour task is to produce ONE single technical hypothesis that is:\n- specific,\n- distinct,\n- grounded strictly in the evidence from the logs.\n\nIMPORTANT:\nPrioritize the most grounded and evidenced cause found in the logs. Only explore non-obvious angles if the error message is ambiguous or the root cause is not explicitly stated in the logs.\nEach instance of this generator must produce a hypothesis meaningfully different from what other generators might produce.\n\nThe hypothesis must be a technical explanation of:\n- what might be failing,\n- why it could be failing,\n- and which part of the logs suggest this.\n\nOUTPUT REQUIREMENTS:\nYou must return ONLY the raw plain text.\n- Do NOT return a JSON object.\n- Do NOT use any Markdown formatting (no backticks, no asterisks, no headers).\n- Do NOT include introductory text or conversational filler (e.g., \"The hypothesis is:\").\n- Maintain a concise, technical tone.\n\nLOGS:\n{{ JSON.stringify($json.output.logs_content) }}",
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        3728,
        -64
      ],
      "id": "7eb37cef-bb0d-4359-afb6-fe158be6660b",
      "name": "Hypothesis Generator 3"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\n  \"output\": {\n    \"logs_content\": \"2025-12-04T23:47:40.5492722Z Current runner version: '2.329.0'\\n2025-12-04T23:47:40.5568870Z ##[group]Runner Image Provisioner\\n2025-12-04T23:47:40.5570151Z Hosted Compute Agent\\n2025-12-04T23:47:40.5571091Z Version: 20251124.448\\n2025-12-04T23:47:40.5572083Z Commit: fda5086b43ec66ade217e5fcd18146c879571177\\n2025-12-04T23:47:40.5573237Z Build Date: 2025-11-24T21:16:26Z\\n2025-12-04T23:47:40.5574372Z ##[endgroup]\\n2025-12-04T23:47:40.5575322Z ##[group]Operating System\\n2025-12-04T23:47:40.5576179Z Ubuntu\\n2025-12-04T23:47:40.5577045Z 24.04.3\\n2025-12-04T23:47:40.5577725Z LTS\\n2025-12-04T23:47:40.5578731Z ##[endgroup]\\n2025-12-04T23:47:40.5579571Z ##[group]Runner Image\\n2025-12-04T23:47:40.5580520Z Image: ubuntu-24.04\\n2025-12-04T23:47:40.5581305Z Version: 20251126.144.1\\n2025-12-04T23:47:40.5583137Z Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20251126.144/images/ubuntu/Ubuntu2404-Readme.md\\n2025-12-04T23:47:40.5585834Z Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20251126.144\\n2025-12-04T23:47:40.5587658Z ##[endgroup]\\n2025-12-04T23:47:40.5620137Z ##[group]GITHUB_TOKEN Permissions\\n2025-12-04T23:47:40.5623063Z Contents: read\\n2025-12-04T23:47:40.5623870Z Metadata: read\\n2025-12-04T23:47:40.5624776Z Packages: read\\n2025-12-04T23:47:40.5625549Z ##[endgroup]\\n2025-12-04T23:47:40.5628729Z Secret source: Actions\\n2025-12-04T23:47:40.5629804Z Prepare workflow directory\\n2025-12-04T23:47:40.6447379Z Prepare all required actions\\n2025-12-04T23:47:40.6503997Z Getting action download info\\n2025-12-04T23:47:40.9686434Z Download action repository 'actions/checkout@v4' (SHA:34e114876b0b11c390a56381ad16ebd13914f8d5)\\n2025-12-04T23:47:41.2501060Z Download action repository 'actions/setup-python@v5' (SHA:a26af69be951a213d495a4c3e4e4022e16d87065)\\n2025-12-04T23:47:41.4069137Z Complete job name: lint\\n2025-12-04T23:47:41.4826715Z ##[group]Run actions/checkout@v4\\n2025-12-04T23:47:41.4828252Z with:\\n2025-12-04T23:47:41.4829150Z   repository: francodem/release_engineering_agentic_workflow\\n2025-12-04T23:47:41.4830448Z   token: ***\\n2025-12-04T23:47:41.4831137Z   ssh-strict: true\\n2025-12-04T23:47:41.4831785Z   ssh-user: git\\n2025-12-04T23:47:41.4832449Z   persist-credentials: true\\n2025-12-04T23:47:41.4833204Z   clean: true\\n2025-12-04T23:47:41.4833879Z   sparse-checkout-cone-mode: true\\n2025-12-04T23:47:41.4834744Z   fetch-depth: 1\\n2025-12-04T23:47:41.4835445Z   fetch-tags: false\\n2025-12-04T23:47:41.4836166Z   show-progress: true\\n2025-12-04T23:47:41.4836868Z   lfs: false\\n2025-12-04T23:47:41.4837518Z   submodules: false\\n2025-12-04T23:47:41.4838461Z   set-safe-directory: true\\n2025-12-04T23:47:41.4839625Z ##[endgroup]\\n2025-12-04T23:47:41.6865362Z Syncing repository: francodem/release_engineering_agentic_workflow\\n2025-12-04T23:47:41.6868508Z ##[group]Getting Git version info\\n2025-12-04T23:47:41.6870231Z Working directory is '/home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow'\\n2025-12-04T23:47:41.6872516Z [command]/usr/bin/git version\\n2025-12-04T23:47:41.6873305Z git version 2.52.0\\n2025-12-04T23:47:41.6875752Z ##[endgroup]\\n2025-12-04T23:47:41.6881783Z Temporarily overriding HOME='/home/runner/work/_temp/e8afb495-dad3-462d-94b3-3174a56a301b' before making global git config changes\\n2025-12-04T23:47:41.6883284Z Adding repository directory to the temporary git global config as a safe directory\\n2025-12-04T23:47:41.6884682Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-04T23:47:41.6887294Z Deleting the contents of '/home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow'\\n2025-12-04T23:47:41.6889251Z ##[group]Initializing the repository\\n2025-12-04T23:47:41.6890293Z [command]/usr/bin/git init /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-04T23:47:41.6891460Z hint: Using 'master' as the name for the initial branch. This default branch name\\n2025-12-04T23:47:41.6892816Z hint: will change to \\\"main\\\" in Git 3.0. To configure the initial branch name\\n2025-12-04T23:47:41.6894633Z hint: to use in all of your new repositories, which will suppress this warning,\\n2025-12-04T23:47:41.6895749Z hint: call:\\n2025-12-04T23:47:41.6896344Z hint:\\n2025-12-04T23:47:41.6897110Z hint: \\tgit config --global init.defaultBranch <name>\\n2025-12-04T23:47:41.6898367Z hint:\\n2025-12-04T23:47:41.6899275Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\\n2025-12-04T23:47:41.6900772Z hint: 'development'. The just-created branch can be renamed via this command:\\n2025-12-04T23:47:41.6901972Z hint:\\n2025-12-04T23:47:41.6902630Z hint: \\tgit branch -m <name>\\n2025-12-04T23:47:41.6903371Z hint:\\n2025-12-04T23:47:41.6904303Z hint: Disable this message with \\\"git config set advice.defaultBranchName false\\\"\\n2025-12-04T23:47:41.6906680Z Initialized empty Git repository in /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/.git/\\n2025-12-04T23:47:41.6910437Z [command]/usr/bin/git remote add origin https://github.com/francodem/release_engineering_agentic_workflow\\n2025-12-04T23:47:41.6913247Z ##[endgroup]\\n2025-12-04T23:47:41.6914394Z ##[group]Disabling automatic garbage collection\\n2025-12-04T23:47:41.6915420Z [command]/usr/bin/git config --local gc.auto 0\\n2025-12-04T23:47:41.6917539Z ##[endgroup]\\n2025-12-04T23:47:41.6918778Z ##[group]Setting up auth\\n2025-12-04T23:47:41.6919890Z [command]/usr/bin/git config --local --name-only --get-regexp core\\\\.sshCommand\\n2025-12-04T23:47:41.6923359Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'core\\\\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :\\\"\\n2025-12-04T23:47:41.7180145Z [command]/usr/bin/git config --local --name-only --get-regexp http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader\\n2025-12-04T23:47:41.7184794Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :\\\"\\n2025-12-04T23:47:41.7442356Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\\\\.gitdir:\\n2025-12-04T23:47:41.7446196Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url\\n2025-12-04T23:47:41.7697121Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***\\n2025-12-04T23:47:41.7734436Z ##[endgroup]\\n2025-12-04T23:47:41.7736543Z ##[group]Fetching the repository\\n2025-12-04T23:47:41.7745703Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +2161c4070034b2d4f93236804983b19c602fffb0:refs/remotes/origin/main\\n2025-12-04T23:47:42.0667803Z From https://github.com/francodem/release_engineering_agentic_workflow\\n2025-12-04T23:47:42.0673455Z  * [new ref]         2161c4070034b2d4f93236804983b19c602fffb0 -> origin/main\\n2025-12-04T23:47:42.0727349Z ##[endgroup]\\n2025-12-04T23:47:42.0729406Z ##[group]Determining the checkout info\\n2025-12-04T23:47:42.0731772Z ##[endgroup]\\n2025-12-04T23:47:42.0739569Z [command]/usr/bin/git sparse-checkout disable\\n2025-12-04T23:47:42.0804940Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig\\n2025-12-04T23:47:42.0852580Z ##[group]Checking out the ref\\n2025-12-04T23:47:42.0862317Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main\\n2025-12-04T23:47:42.0959052Z Switched to a new branch 'main'\\n2025-12-04T23:47:42.0963179Z branch 'main' set up to track 'origin/main'.\\n2025-12-04T23:47:42.0970407Z ##[endgroup]\\n2025-12-04T23:47:42.1006753Z [command]/usr/bin/git log -1 --format=%H\\n2025-12-04T23:47:42.1030922Z 2161c4070034b2d4f93236804983b19c602fffb0\\n2025-12-04T23:47:42.1312261Z ##[group]Run actions/setup-python@v5\\n2025-12-04T23:47:42.1313128Z with:\\n2025-12-04T23:47:42.1313622Z   python-version: 3.13\\n2025-12-04T23:47:42.1314223Z   cache: pip\\n2025-12-04T23:47:42.1314737Z   check-latest: false\\n2025-12-04T23:47:42.1315628Z   token: ***\\n2025-12-04T23:47:42.1316379Z   update-environment: true\\n2025-12-04T23:47:42.1317089Z   allow-prereleases: false\\n2025-12-04T23:47:42.1317770Z   freethreaded: false\\n2025-12-04T23:47:42.1318500Z ##[endgroup]\\n2025-12-04T23:47:42.3071795Z ##[group]Installed versions\\n2025-12-04T23:47:42.3202439Z Successfully set up CPython (3.13.9)\\n2025-12-04T23:47:42.3205986Z ##[endgroup]\\n2025-12-04T23:47:42.3725871Z [command]/opt/hostedtoolcache/Python/3.13.9/x64/bin/pip cache dir\\n2025-12-04T23:47:43.4696466Z /home/runner/.cache/pip\\n2025-12-04T23:47:43.6130095Z pip cache is not found\\n2025-12-04T23:47:43.6244786Z ##[group]Run pip install -r src/emulation/teams/requirements.txt\\n2025-12-04T23:47:43.6245374Z \\u001b[36;1mpip install -r src/emulation/teams/requirements.txt\\u001b[0m\\n2025-12-04T23:47:43.6284909Z shell: /usr/bin/bash -e {0}\\n2025-12-04T23:47:43.6285193Z env:\\n2025-12-04T23:47:43.6285481Z   pythonLocation: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:43.6285932Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib/pkgconfig\\n2025-12-04T23:47:43.6286387Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:43.6286776Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:43.6287156Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:43.6287571Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib\\n2025-12-04T23:47:43.6287891Z ##[endgroup]\\n2025-12-04T23:47:44.6872353Z Collecting fastapi==0.104.1 (from -r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:44.7883416Z   Downloading fastapi-0.104.1-py3-none-any.whl.metadata (24 kB)\\n2025-12-04T23:47:44.8341193Z Collecting uvicorn==0.24.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:44.8423969Z   Downloading uvicorn-0.24.0-py3-none-any.whl.metadata (6.4 kB)\\n2025-12-04T23:47:44.8643443Z Collecting jinja2==3.1.2 (from -r src/emulation/teams/requirements.txt (line 3))\\n2025-12-04T23:47:44.8720675Z   Downloading Jinja2-3.1.2-py3-none-any.whl.metadata (3.5 kB)\\n2025-12-04T23:47:44.8905342Z Collecting python-multipart==0.0.6 (from -r src/emulation/teams/requirements.txt (line 4))\\n2025-12-04T23:47:44.9088944Z   Downloading python_multipart-0.0.6-py3-none-any.whl.metadata (2.5 kB)\\n2025-12-04T23:47:44.9662284Z Collecting black==23.10.1 (from -r src/emulation/teams/requirements.txt (line 5))\\n2025-12-04T23:47:44.9780593Z   Downloading black-23.10.1-py3-none-any.whl.metadata (66 kB)\\n2025-12-04T23:47:45.0194716Z Collecting anyio<4.0.0,>=3.7.1 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:45.0292601Z   Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\\n2025-12-04T23:47:45.1980087Z Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:45.2064819Z   Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\\n2025-12-04T23:47:45.2490637Z Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:45.2602733Z   Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\\n2025-12-04T23:47:45.2871813Z Collecting typing-extensions>=4.8.0 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:45.2953730Z   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\\n2025-12-04T23:47:45.3195539Z Collecting click>=7.0 (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.3277236Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\\n2025-12-04T23:47:45.3435272Z Collecting h11>=0.8 (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.3514202Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\\n2025-12-04T23:47:45.4156433Z Collecting MarkupSafe>=2.0 (from jinja2==3.1.2->-r src/emulation/teams/requirements.txt (line 3))\\n2025-12-04T23:47:45.4236959Z   Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\\n2025-12-04T23:47:45.4453347Z Collecting mypy-extensions>=0.4.3 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-04T23:47:45.4537760Z   Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\\n2025-12-04T23:47:45.4754047Z Collecting packaging>=22.0 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-04T23:47:45.4832001Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\\n2025-12-04T23:47:45.5003921Z Collecting pathspec>=0.9.0 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-04T23:47:45.5083437Z   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\\n2025-12-04T23:47:45.5330203Z Collecting platformdirs>=2 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-04T23:47:45.5413509Z   Downloading platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\\n2025-12-04T23:47:45.5792527Z Collecting httptools>=0.5.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.5899121Z   Downloading httptools-0.7.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\\n2025-12-04T23:47:45.6120817Z Collecting python-dotenv>=0.13 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.6212371Z   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\\n2025-12-04T23:47:45.6711228Z Collecting pyyaml>=5.1 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.6795559Z   Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\\n2025-12-04T23:47:45.7282534Z Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.7394099Z   Downloading uvloop-0.22.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\\n2025-12-04T23:47:45.8266178Z Collecting watchfiles>=0.13 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.8347029Z   Downloading watchfiles-1.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\\n2025-12-04T23:47:45.9313466Z Collecting websockets>=10.4 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-04T23:47:45.9394955Z   Downloading websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\\n2025-12-04T23:47:45.9606960Z Collecting idna>=2.8 (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:45.9693173Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\\n2025-12-04T23:47:45.9850178Z Collecting sniffio>=1.1 (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:45.9939843Z   Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\\n2025-12-04T23:47:46.0104411Z Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:46.0177497Z   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\\n2025-12-04T23:47:46.7021922Z Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:46.7160195Z   Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\\n2025-12-04T23:47:46.7343428Z Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-04T23:47:46.7422535Z   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\\n2025-12-04T23:47:46.7817194Z Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\\n2025-12-04T23:47:46.7940485Z Downloading uvicorn-0.24.0-py3-none-any.whl (59 kB)\\n2025-12-04T23:47:46.8035046Z Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\\n2025-12-04T23:47:46.8152399Z Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\\n2025-12-04T23:47:46.8291131Z Downloading black-23.10.1-py3-none-any.whl (184 kB)\\n2025-12-04T23:47:46.8423322Z Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\\n2025-12-04T23:47:46.8613161Z Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\\n2025-12-04T23:47:46.8773484Z Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\\n2025-12-04T23:47:46.8936008Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 139.4 MB/s  0:00:00\\n2025-12-04T23:47:46.9013622Z Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\\n2025-12-04T23:47:46.9127217Z Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\\n2025-12-04T23:47:46.9229043Z Downloading click-8.3.1-py3-none-any.whl (108 kB)\\n2025-12-04T23:47:46.9338916Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)\\n2025-12-04T23:47:46.9545403Z Downloading httptools-0.7.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (478 kB)\\n2025-12-04T23:47:46.9752491Z Downloading idna-3.11-py3-none-any.whl (71 kB)\\n2025-12-04T23:47:46.9871676Z Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\\n2025-12-04T23:47:46.9972140Z Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\\n2025-12-04T23:47:47.0075239Z Downloading packaging-25.0-py3-none-any.whl (66 kB)\\n2025-12-04T23:47:47.0212743Z Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\\n2025-12-04T23:47:47.0316957Z Downloading platformdirs-4.5.0-py3-none-any.whl (18 kB)\\n2025-12-04T23:47:47.0435562Z Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\\n2025-12-04T23:47:47.0548168Z Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\\n2025-12-04T23:47:47.0624983Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 801.6/801.6 kB 118.1 MB/s  0:00:00\\n2025-12-04T23:47:47.0705486Z Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\\n2025-12-04T23:47:47.0819919Z Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\\n2025-12-04T23:47:47.0921230Z Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\\n2025-12-04T23:47:47.1024974Z Downloading uvloop-0.22.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\\n2025-12-04T23:47:47.1627222Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 73.0 MB/s  0:00:00\\n2025-12-04T23:47:47.1728061Z Downloading watchfiles-1.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\\n2025-12-04T23:47:47.1898358Z Downloading websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\\n2025-12-04T23:47:47.2717373Z Installing collected packages: websockets, uvloop, typing-extensions, sniffio, pyyaml, python-multipart, python-dotenv, platformdirs, pathspec, packaging, mypy-extensions, MarkupSafe, idna, httptools, h11, click, annotated-types, uvicorn, typing-inspection, pydantic-core, jinja2, black, anyio, watchfiles, starlette, pydantic, fastapi\\n2025-12-04T23:47:48.7555270Z \\n2025-12-04T23:47:48.7593168Z Successfully installed MarkupSafe-3.0.3 annotated-types-0.7.0 anyio-3.7.1 black-23.10.1 click-8.3.1 fastapi-0.104.1 h11-0.16.0 httptools-0.7.1 idna-3.11 jinja2-3.1.2 mypy-extensions-1.1.0 packaging-25.0 pathspec-0.12.1 platformdirs-4.5.0 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 python-multipart-0.0.6 pyyaml-6.0.3 sniffio-1.3.1 starlette-0.27.0 typing-extensions-4.15.0 typing-inspection-0.4.2 uvicorn-0.24.0 uvloop-0.22.1 watchfiles-1.1.1 websockets-15.0.1\\n2025-12-04T23:47:49.1218834Z ##[group]Run # black src/emulation/teams\\n2025-12-04T23:47:49.1219194Z \\u001b[36;1m# black src/emulation/teams\\u001b[0m\\n2025-12-04T23:47:49.1219743Z \\u001b[36;1mif ! black --check --diff --exclude='/(env|\\\\.git|__pycache__)/' .; then\\u001b[0m\\n2025-12-04T23:47:49.1220081Z \\u001b[36;1m  echo \\\"\\\" >&2\\u001b[0m\\n2025-12-04T23:47:49.1220444Z \\u001b[36;1m  echo \\\"::error::Black found code formatting issues. Some files need to be reformatted.\\\" >&2\\u001b[0m\\n2025-12-04T23:47:49.1221014Z \\u001b[36;1m  echo \\\"::notice::Run 'black --exclude='\\\\''/(env|\\\\.git|__pycache__)/'\\\\'' .' locally to fix formatting issues.\\\" >&2\\u001b[0m\\n2025-12-04T23:47:49.1221405Z \\u001b[36;1m  exit 1\\u001b[0m\\n2025-12-04T23:47:49.1221570Z \\u001b[36;1mfi\\u001b[0m\\n2025-12-04T23:47:49.1221794Z \\u001b[36;1mecho \\\"✓ All Python files are properly formatted!\\\"\\u001b[0m\\n2025-12-04T23:47:49.1256224Z shell: /usr/bin/bash -e {0}\\n2025-12-04T23:47:49.1256446Z env:\\n2025-12-04T23:47:49.1256675Z   pythonLocation: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:49.1257112Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib/pkgconfig\\n2025-12-04T23:47:49.1257489Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:49.1257850Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:49.1258470Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-04T23:47:49.1258808Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib\\n2025-12-04T23:47:49.1259088Z ##[endgroup]\\n2025-12-04T23:47:49.9395250Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\t2025-12-04 23:47:42.091627+00:00\\n2025-12-04T23:47:49.9397612Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\t2025-12-04 23:47:49.911785+00:00\\n2025-12-04T23:47:49.9398923Z @@ -12,10 +12,11 @@\\n2025-12-04T23:47:49.9399230Z      max_tokens=2000,\\n2025-12-04T23:47:49.9399542Z      max_retries=6,\\n2025-12-04T23:47:49.9399813Z      stop=None,\\n2025-12-04T23:47:49.9400126Z      # other params...\\n2025-12-04T23:47:49.9400443Z  )\\n2025-12-04T23:47:49.9400686Z +\\n2025-12-04T23:47:49.9400937Z  \\n2025-12-04T23:47:49.9401199Z  # Graph state\\n2025-12-04T23:47:49.9401542Z  class State(TypedDict):\\n2025-12-04T23:47:49.9401883Z      topic: str\\n2025-12-04T23:47:49.9402184Z      joke: str\\n2025-12-04T23:47:49.9402468Z @@ -71,11 +72,13 @@\\n2025-12-04T23:47:49.9402863Z  workflow.add_node(\\\"polish_joke\\\", polish_joke)\\n2025-12-04T23:47:49.9403338Z  \\n2025-12-04T23:47:49.9489949Z  # Add edges to connect nodes\\n2025-12-04T23:47:49.9490370Z  workflow.add_edge(START, \\\"generate_joke\\\")\\n2025-12-04T23:47:49.9490827Z  workflow.add_conditional_edges(\\n2025-12-04T23:47:49.9491466Z -    \\\"generate_joke\\\", check_punchline, {\\\"Fail\\\": \\\"improve_joke\\\", \\\"Pass\\\": \\\"ask_for_applause\\\"}\\n2025-12-04T23:47:49.9492889Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\n2025-12-04T23:47:49.9493879Z +    \\\"generate_joke\\\",\\n2025-12-04T23:47:49.9494213Z +    check_punchline,\\n2025-12-04T23:47:49.9494651Z +    {\\\"Fail\\\": \\\"improve_joke\\\", \\\"Pass\\\": \\\"ask_for_applause\\\"},\\n2025-12-04T23:47:49.9495133Z  )\\n2025-12-04T23:47:49.9495481Z  workflow.add_edge(\\\"improve_joke\\\", \\\"polish_joke\\\")\\n2025-12-04T23:47:49.9496083Z  workflow.add_edge(\\\"polish_joke\\\", \\\"ask_for_applause\\\")\\n2025-12-04T23:47:49.9496625Z  workflow.add_edge(\\\"ask_for_applause\\\", END)\\n2025-12-04T23:47:49.9497044Z  \\n2025-12-04T23:47:49.9497293Z @@ -102,6 +105,6 @@\\n2025-12-04T23:47:49.9497619Z      print(state[\\\"final_joke\\\"])\\n2025-12-04T23:47:49.9498322Z  elif \\\"ask_for_applause\\\" in state:\\n2025-12-04T23:47:49.9498771Z      print(\\\"Ask for applause:\\\")\\n2025-12-04T23:47:49.9499182Z      print(state[\\\"ask_for_applause\\\"])\\n2025-12-04T23:47:49.9499572Z  else:\\n2025-12-04T23:47:49.9499979Z -    print(\\\"Joke failed quality gate - no punchline detected!\\\")\\n2025-12-04T23:47:49.9500520Z \\\\ No newline at end of file\\n2025-12-04T23:47:49.9501003Z +    print(\\\"Joke failed quality gate - no punchline detected!\\\")\\n2025-12-04T23:47:50.2869246Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\t2025-12-04 23:47:42.091627+00:00\\n2025-12-04T23:47:50.2871077Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\t2025-12-04 23:47:50.280497+00:00\\n2025-12-04T23:47:50.2872376Z @@ -30,11 +30,16 @@\\n2025-12-04T23:47:50.2872761Z  AZURE_DEVOPS_ORG = os.getenv(\\\"AZURE_DEVOPS_ORG\\\")\\n2025-12-04T23:47:50.2873348Z  AZURE_DEVOPS_PROJECT = os.getenv(\\\"AZURE_DEVOPS_PROJECT\\\")\\n2025-12-04T23:47:50.2873998Z  AZURE_DEVOPS_PIPELINE_ID = os.getenv(\\\"AZURE_DEVOPS_PIPELINE_ID\\\")\\n2025-12-04T23:47:50.2874515Z  \\n2025-12-04T23:47:50.2874880Z  # Azure DevOps requires Base64 encoded token (format: :token)\\n2025-12-04T23:47:50.2875732Z -AZURE_DEVOPS_TOKEN = base64.b64encode(f\\\":{AZURE_DEVOPS_PAT}\\\".encode()).decode() if AZURE_DEVOPS_PAT else None\\n2025-12-04T23:47:50.2876494Z +AZURE_DEVOPS_TOKEN = (\\n2025-12-04T23:47:50.2876960Z +    base64.b64encode(f\\\":{AZURE_DEVOPS_PAT}\\\".encode()).decode()\\n2025-12-04T23:47:50.2877507Z +    if AZURE_DEVOPS_PAT\\n2025-12-04T23:47:50.2877842Z +    else None\\n2025-12-04T23:47:50.2912841Z +)\\n2025-12-04T23:47:50.2913120Z +\\n2025-12-04T23:47:50.2913368Z  \\n2025-12-04T23:47:50.2913615Z  # Graph state\\n2025-12-04T23:47:50.2913945Z  class State(TypedDict):\\n2025-12-04T23:47:50.2914346Z      channel: str  # Slack channel name or ID\\n2025-12-04T23:47:50.2914900Z      slack_messages: NotRequired[list]  # Messages from Slack\\n2025-12-04T23:47:50.2915406Z @@ -49,39 +54,42 @@\\n2025-12-04T23:47:50.2915731Z  # Helper functions for Slack API\\n2025-12-04T23:47:50.2916280Z  def get_slack_channel_id(channel_name: str) -> Optional[str]:\\n2025-12-04T23:47:50.2916845Z      \\\"\\\"\\\"Get Slack channel ID from channel name\\\"\\\"\\\"\\n2025-12-04T23:47:50.2917276Z      headers = {\\n2025-12-04T23:47:50.2918341Z          \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-04T23:47:50.2918794Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-04T23:47:50.2919278Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-04T23:47:50.2919684Z      }\\n2025-12-04T23:47:50.2919970Z      response = requests.get(\\n2025-12-04T23:47:50.2921055Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\n2025-12-04T23:47:50.2922096Z          f\\\"{SLACK_API_BASE}/conversations.list\\\",\\n2025-12-04T23:47:50.2922540Z          headers=headers,\\n2025-12-04T23:47:50.2922976Z -        params={\\\"types\\\": \\\"public_channel,private_channel\\\"}\\n2025-12-04T23:47:50.2923555Z +        params={\\\"types\\\": \\\"public_channel,private_channel\\\"},\\n2025-12-04T23:47:50.2924024Z      )\\n2025-12-04T23:47:50.2924273Z -    \\n2025-12-04T23:47:50.2924509Z +\\n2025-12-04T23:47:50.2924786Z      if response.status_code == 200:\\n2025-12-04T23:47:50.2925200Z          data = response.json()\\n2025-12-04T23:47:50.2925573Z          if data.get(\\\"ok\\\"):\\n2025-12-04T23:47:50.2925961Z              for channel in data.get(\\\"channels\\\", []):\\n2025-12-04T23:47:50.2926608Z -                if channel.get(\\\"name\\\") == channel_name or channel.get(\\\"id\\\") == channel_name:\\n2025-12-04T23:47:50.2927195Z +                if (\\n2025-12-04T23:47:50.2927536Z +                    channel.get(\\\"name\\\") == channel_name\\n2025-12-04T23:47:50.2928331Z +                    or channel.get(\\\"id\\\") == channel_name\\n2025-12-04T23:47:50.2928764Z +                ):\\n2025-12-04T23:47:50.2929099Z                      return channel.get(\\\"id\\\")\\n2025-12-04T23:47:50.2929499Z      return None\\n2025-12-04T23:47:50.2929775Z  \\n2025-12-04T23:47:50.2930000Z  \\n2025-12-04T23:47:50.2930407Z  def get_slack_messages(channel_id: str, limit: int = 100) -> list:\\n2025-12-04T23:47:50.2930979Z      \\\"\\\"\\\"Get messages from Slack channel\\\"\\\"\\\"\\n2025-12-04T23:47:50.2931375Z      headers = {\\n2025-12-04T23:47:50.2931787Z          \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-04T23:47:50.2932200Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-04T23:47:50.2932661Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-04T23:47:50.2933061Z      }\\n2025-12-04T23:47:50.2933346Z      response = requests.get(\\n2025-12-04T23:47:50.2934008Z          f\\\"{SLACK_API_BASE}/conversations.history\\\",\\n2025-12-04T23:47:50.2934471Z          headers=headers,\\n2025-12-04T23:47:50.2934882Z -        params={\\\"channel\\\": channel_id, \\\"limit\\\": limit}\\n2025-12-04T23:47:50.2935593Z +        params={\\\"channel\\\": channel_id, \\\"limit\\\": limit},\\n2025-12-04T23:47:50.2936093Z      )\\n2025-12-04T23:47:50.2936332Z -    \\n2025-12-04T23:47:50.2936593Z +\\n2025-12-04T23:47:50.2936918Z      if response.status_code == 200:\\n2025-12-04T23:47:50.2937329Z          data = response.json()\\n2025-12-04T23:47:50.2937704Z          if data.get(\\\"ok\\\"):\\n2025-12-04T23:47:50.2938270Z              return data.get(\\\"messages\\\", [])\\n2025-12-04T23:47:50.2938678Z      return []\\n2025-12-04T23:47:50.2938958Z @@ -90,165 +98,158 @@\\n2025-12-04T23:47:50.2939308Z  # Helper functions for Azure DevOps API\\n2025-12-04T23:47:50.2939984Z  def trigger_azure_pipeline(pipeline_id: int, branch: str = \\\"main\\\") -> Optional[dict]:\\n2025-12-04T23:47:50.2940676Z      \\\"\\\"\\\"Trigger Azure DevOps pipeline\\\"\\\"\\\"\\n2025-12-04T23:47:50.2941109Z      if not AZURE_DEVOPS_TOKEN:\\n2025-12-04T23:47:50.2941462Z          return None\\n2025-12-04T23:47:50.2941755Z -    \\n2025-12-04T23:47:50.2941991Z +\\n2025-12-04T23:47:50.2942241Z      headers = {\\n2025-12-04T23:47:50.2945348Z          \\\"Authorization\\\": f\\\"Basic {AZURE_DEVOPS_TOKEN}\\\",\\n2025-12-04T23:47:50.2945884Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-04T23:47:50.2946297Z -    }\\n2025-12-04T23:47:50.2946563Z -    \\n2025-12-04T23:47:50.2946873Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-04T23:47:50.2947278Z +    }\\n2025-12-04T23:47:50.2947526Z +\\n2025-12-04T23:47:50.2947760Z      url = (\\n2025-12-04T23:47:50.2948513Z          f\\\"https://dev.azure.com/{AZURE_DEVOPS_ORG}/{AZURE_DEVOPS_PROJECT}/\\\"\\n2025-12-04T23:47:50.2949195Z          f\\\"_apis/pipelines/{pipeline_id}/runs?api-version=7.1\\\"\\n2025-12-04T23:47:50.2949666Z      )\\n2025-12-04T23:47:50.2949903Z -    \\n2025-12-04T23:47:50.2950149Z +\\n2025-12-04T23:47:50.2950391Z      payload = {\\n2025-12-04T23:47:50.2950692Z -        \\\"resources\\\": {\\n2025-12-04T23:47:50.2951026Z -            \\\"repositories\\\": {\\n2025-12-04T23:47:50.2951377Z -                \\\"self\\\": {\\n2025-12-04T23:47:50.2951744Z -                    \\\"refName\\\": f\\\"refs/heads/{branch}\\\"\\n2025-12-04T23:47:50.2952148Z -                }\\n2025-12-04T23:47:50.2952428Z -            }\\n2025-12-04T23:47:50.2952691Z -        }\\n2025-12-04T23:47:50.2952943Z -    }\\n2025-12-04T23:47:50.2953177Z -    \\n2025-12-04T23:47:50.2953627Z +        \\\"resources\\\": {\\\"repositories\\\": {\\\"self\\\": {\\\"refName\\\": f\\\"refs/heads/{branch}\\\"}}}\\n2025-12-04T23:47:50.2954183Z +    }\\n2025-12-04T23:47:50.2954423Z +\\n2025-12-04T23:47:50.2954651Z      try:\\n2025-12-04T23:47:50.2955069Z          response = requests.post(url, headers=headers, json=payload)\\n2025-12-04T23:47:50.2955578Z -        \\n2025-12-04T23:47:50.2955818Z +\\n2025-12-04T23:47:50.2956089Z          if response.status_code == 200:\\n2025-12-04T23:47:50.2956511Z              return response.json()\\n2025-12-04T23:47:50.2956883Z          else:\\n2025-12-04T23:47:50.2957413Z -            print(f\\\"Error triggering pipeline: {response.status_code} - {response.text}\\\")\\n2025-12-04T23:47:50.2958236Z +            print(\\n2025-12-04T23:47:50.2958738Z +                f\\\"Error triggering pipeline: {response.status_code} - {response.text}\\\"\\n2025-12-04T23:47:50.2959318Z +            )\\n2025-12-04T23:47:50.2959602Z              return None\\n2025-12-04T23:47:50.2959934Z      except Exception as e:\\n2025-12-04T23:47:50.2960367Z          print(f\\\"Exception triggering pipeline: {str(e)}\\\")\\n2025-12-04T23:47:50.2960818Z          return None\\n2025-12-04T23:47:50.2961108Z  \\n2025-12-04T23:47:50.2961336Z  \\n2025-12-04T23:47:50.2961789Z  def get_pipeline_status(pipeline_id: int, run_id: int) -> Optional[dict]:\\n2025-12-04T23:47:50.2962412Z      \\\"\\\"\\\"Get Azure DevOps pipeline run status\\\"\\\"\\\"\\n2025-12-04T23:47:50.2962855Z      if not AZURE_DEVOPS_TOKEN:\\n2025-12-04T23:47:50.2963204Z          return None\\n2025-12-04T23:47:50.2963491Z -    \\n2025-12-04T23:47:50.2963740Z +\\n2025-12-04T23:47:50.2963976Z      headers = {\\n2025-12-04T23:47:50.2964570Z          \\\"Authorization\\\": f\\\"Basic {AZURE_DEVOPS_TOKEN}\\\",\\n2025-12-04T23:47:50.2965072Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-04T23:47:50.2965473Z -    }\\n2025-12-04T23:47:50.2965879Z -    \\n2025-12-04T23:47:50.2966176Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-04T23:47:50.2966569Z +    }\\n2025-12-04T23:47:50.2966807Z +\\n2025-12-04T23:47:50.2967067Z      url = (\\n2025-12-04T23:47:50.2967501Z          f\\\"https://dev.azure.com/{AZURE_DEVOPS_ORG}/{AZURE_DEVOPS_PROJECT}/\\\"\\n2025-12-04T23:47:50.2968351Z          f\\\"_apis/pipelines/{pipeline_id}/runs/{run_id}?api-version=7.1\\\"\\n2025-12-04T23:47:50.2968860Z      )\\n2025-12-04T23:47:50.2969104Z -    \\n2025-12-04T23:47:50.2969342Z +\\n2025-12-04T23:47:50.2969575Z      try:\\n2025-12-04T23:47:50.2969905Z          response = requests.get(url, headers=headers)\\n2025-12-04T23:47:50.2970337Z -        \\n2025-12-04T23:47:50.2970585Z +\\n2025-12-04T23:47:50.2970856Z          if response.status_code == 200:\\n2025-12-04T23:47:50.2971273Z              return response.json()\\n2025-12-04T23:47:50.2971630Z          else:\\n2025-12-04T23:47:50.2972170Z -            print(f\\\"Error getting pipeline status: {response.status_code} - {response.text}\\\")\\n2025-12-04T23:47:50.2972796Z +            print(\\n2025-12-04T23:47:50.2973303Z +                f\\\"Error getting pipeline status: {response.status_code} - {response.text}\\\"\\n2025-12-04T23:47:50.2973880Z +            )\\n2025-12-04T23:47:50.2974163Z              return None\\n2025-12-04T23:47:50.2974501Z      except Exception as e:\\n2025-12-04T23:47:50.2974941Z          print(f\\\"Exception getting pipeline status: {str(e)}\\\")\\n2025-12-04T23:47:50.2975415Z          return None\\n2025-12-04T23:47:50.2975692Z  \\n2025-12-04T23:47:50.2975926Z  \\n2025-12-04T23:47:50.2976136Z  # Nodes\\n2025-12-04T23:47:50.2976432Z  def consult_slack_messages(state: State):\\n2025-12-04T23:47:50.2976957Z      \\\"\\\"\\\"Node 1: Consult Slack messages from a specific channel\\\"\\\"\\\"\\n2025-12-04T23:47:50.2977488Z      channel = state[\\\"channel\\\"]\\n2025-12-04T23:47:50.2977842Z -    \\n2025-12-04T23:47:50.2978255Z +\\n2025-12-04T23:47:50.2978502Z      try:\\n2025-12-04T23:47:50.2979030Z          # Get channel ID\\n2025-12-04T23:47:50.2979464Z          channel_id = get_slack_channel_id(channel)\\n2025-12-04T23:47:50.2979927Z          if not channel_id:\\n2025-12-04T23:47:50.2980287Z -            return {\\n2025-12-04T23:47:50.2980728Z -                \\\"error\\\": f\\\"Channel '{channel}' not found or not accessible\\\"\\n2025-12-04T23:47:50.2981250Z -            }\\n2025-12-04T23:47:50.2981531Z -        \\n2025-12-04T23:47:50.2981975Z +            return {\\\"error\\\": f\\\"Channel '{channel}' not found or not accessible\\\"}\\n2025-12-04T23:47:50.2982516Z +\\n2025-12-04T23:47:50.2982790Z          # Get messages\\n2025-12-04T23:47:50.2983175Z          messages = get_slack_messages(channel_id)\\n2025-12-04T23:47:50.2983603Z -        \\n2025-12-04T23:47:50.2983875Z -        return {\\n2025-12-04T23:47:50.2984202Z -            \\\"slack_messages\\\": messages\\n2025-12-04T23:47:50.2984601Z -        }\\n2025-12-04T23:47:50.2984859Z +\\n2025-12-04T23:47:50.2985159Z +        return {\\\"slack_messages\\\": messages}\\n2025-12-04T23:47:50.2985605Z      except Exception as e:\\n2025-12-04T23:47:50.2985967Z -        return {\\n2025-12-04T23:47:50.2986358Z -            \\\"error\\\": f\\\"Error fetching Slack messages: {str(e)}\\\"\\n2025-12-04T23:47:50.2986837Z -        }\\n2025-12-04T23:47:50.2987243Z +        return {\\\"error\\\": f\\\"Error fetching Slack messages: {str(e)}\\\"}\\n2025-12-04T23:47:50.2987735Z  \\n2025-12-04T23:47:50.2988138Z  \\n2025-12-04T23:47:50.2988438Z  def check_albert_message(state: State):\\n2025-12-04T23:47:50.2988986Z      \\\"\\\"\\\"Node 1a: Check for Albert H. message and evaluate with LLM\\\"\\\"\\\"\\n2025-12-04T23:47:50.2989573Z      messages = state.get(\\\"slack_messages\\\", [])\\n2025-12-04T23:47:50.2990022Z      albert_message = None\\n2025-12-04T23:47:50.2990361Z -    \\n2025-12-04T23:47:50.2990622Z +\\n2025-12-04T23:47:50.2990895Z      # Find message from Albert H.\\n2025-12-04T23:47:50.2991310Z      for message in messages:\\n2025-12-04T23:47:50.2991704Z          user_id = message.get(\\\"user\\\", \\\"\\\")\\n2025-12-04T23:47:50.2992149Z          # Get user info to check name\\n2025-12-04T23:47:50.2992745Z          try:\\n2025-12-04T23:47:50.2993056Z              headers = {\\n2025-12-04T23:47:50.2993545Z                  \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-04T23:47:50.2994208Z -                \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-04T23:47:50.2994715Z +                \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-04T23:47:50.2995140Z              }\\n2025-12-04T23:47:50.2995471Z              user_response = requests.get(\\n2025-12-04T23:47:50.2995920Z                  f\\\"{SLACK_API_BASE}/users.info\\\",\\n2025-12-04T23:47:50.2996372Z                  headers=headers,\\n2025-12-04T23:47:50.2996778Z -                params={\\\"user\\\": user_id}\\n2025-12-04T23:47:50.2997219Z +                params={\\\"user\\\": user_id},\\n2025-12-04T23:47:50.2997616Z              )\\n2025-12-04T23:47:50.2998122Z              if user_response.status_code == 200:\\n2025-12-04T23:47:50.2998607Z                  user_data = user_response.json()\\n2025-12-04T23:47:50.2999052Z                  if user_data.get(\\\"ok\\\"):\\n2025-12-04T23:47:50.2999584Z                      user_name = user_data.get(\\\"user\\\", {}).get(\\\"real_name\\\", \\\"\\\")\\n2025-12-04T23:47:50.3000309Z -                    display_name = user_data.get(\\\"user\\\", {}).get(\\\"profile\\\", {}).get(\\\"display_name\\\", \\\"\\\")\\n2025-12-04T23:47:50.3000959Z +                    display_name = (\\n2025-12-04T23:47:50.3001373Z +                        user_data.get(\\\"user\\\", {})\\n2025-12-04T23:47:50.3001815Z +                        .get(\\\"profile\\\", {})\\n2025-12-04T23:47:50.3002250Z +                        .get(\\\"display_name\\\", \\\"\\\")\\n2025-12-04T23:47:50.3002651Z +                    )\\n2025-12-04T23:47:50.3003004Z                      # Check if user is Albert H.\\n2025-12-04T23:47:50.3003536Z                      if \\\"Albert H.\\\" in user_name or \\\"Albert H.\\\" in display_name:\\n2025-12-04T23:47:50.3004122Z                          albert_message = message.get(\\\"text\\\", \\\"\\\")\\n2025-12-04T23:47:50.3004584Z                          break\\n2025-12-04T23:47:50.3004933Z          except:\\n2025-12-04T23:47:50.3005384Z              # If we can't check user name, check if user field contains albert\\n2025-12-04T23:47:50.3006074Z              # This is a fallback - in production you'd want to store user mapping\\n2025-12-04T23:47:50.3006634Z              pass\\n2025-12-04T23:47:50.3006925Z -    \\n2025-12-04T23:47:50.3007191Z +\\n2025-12-04T23:47:50.3007460Z      if not albert_message:\\n2025-12-04T23:47:50.3007839Z          return {\\n2025-12-04T23:47:50.3008323Z              \\\"albert_message\\\": \\\"\\\",\\n2025-12-04T23:47:50.3008741Z              \\\"llm_approval\\\": \\\"Rejected\\\",\\n2025-12-04T23:47:50.3009230Z -            \\\"error\\\": \\\"No message from Albert H. found in channel\\\"\\n2025-12-04T23:47:50.3009812Z +            \\\"error\\\": \\\"No message from Albert H. found in channel\\\",\\n2025-12-04T23:47:50.3010280Z          }\\n2025-12-04T23:47:50.3010538Z -    \\n2025-12-04T23:47:50.3010791Z +\\n2025-12-04T23:47:50.3011058Z      # Evaluate with LLM\\n2025-12-04T23:47:50.3011393Z      try:\\n2025-12-04T23:47:50.3011658Z          prompt = (\\n2025-12-04T23:47:50.3012157Z              f\\\"Review the following Slack message from Albert H.:\\\\n\\\\n\\\"\\n2025-12-04T23:47:50.3012685Z              f\\\"{albert_message}\\\\n\\\\n\\\"\\n2025-12-04T23:47:50.3013303Z              f\\\"Determine if we should proceed with triggering the Azure DevOps pipeline. \\\"\\n2025-12-04T23:47:50.3014216Z              f\\\"Respond with 'Approved' if we should proceed, or 'Rejected' if we should not. \\\"\\n2025-12-04T23:47:50.3014975Z              f\\\"Only respond with one word: 'Approved' or 'Rejected'.\\\"\\n2025-12-04T23:47:50.3015467Z          )\\n2025-12-04T23:47:50.3015723Z -        \\n2025-12-04T23:47:50.3016015Z +\\n2025-12-04T23:47:50.3016303Z          msg = llm.invoke(prompt)\\n2025-12-04T23:47:50.3016725Z          approval = msg.content.strip()\\n2025-12-04T23:47:50.3017120Z -        \\n2025-12-04T23:47:50.3017396Z +\\n2025-12-04T23:47:50.3017703Z          # Ensure it's either Approved or Rejected\\n2025-12-04T23:47:50.3018347Z          if \\\"Approved\\\" in approval:\\n2025-12-04T23:47:50.3018767Z              approval = \\\"Approved\\\"\\n2025-12-04T23:47:50.3019134Z          else:\\n2025-12-04T23:47:50.3019664Z              approval = \\\"Rejected\\\"\\n2025-12-04T23:47:50.3020052Z -        \\n2025-12-04T23:47:50.3020324Z -        return {\\n2025-12-04T23:47:50.3020661Z -            \\\"albert_message\\\": albert_message,\\n2025-12-04T23:47:50.3021325Z -            \\\"llm_approval\\\": approval\\n2025-12-04T23:47:50.3021707Z -        }\\n2025-12-04T23:47:50.3021974Z +\\n2025-12-04T23:47:50.3022406Z +        return {\\\"albert_message\\\": albert_message, \\\"llm_approval\\\": approval}\\n2025-12-04T23:47:50.3022985Z      except Exception as e:\\n2025-12-04T23:47:50.3023344Z          return {\\n2025-12-04T23:47:50.3023673Z              \\\"albert_message\\\": albert_message,\\n2025-12-04T23:47:50.3024124Z              \\\"llm_approval\\\": \\\"Rejected\\\",\\n2025-12-04T23:47:50.3024631Z -            \\\"error\\\": f\\\"Error evaluating message with LLM: {str(e)}\\\"\\n2025-12-04T23:47:50.3025241Z +            \\\"error\\\": f\\\"Error evaluating message with LLM: {str(e)}\\\",\\n2025-12-04T23:47:50.3025721Z          }\\n2025-12-04T23:47:50.3025988Z  \\n2025-12-04T23:47:50.3026226Z  \\n2025-12-04T23:47:50.3026540Z  def validate_approval(state: State):\\n2025-12-04T23:47:50.3027004Z      \\\"\\\"\\\"Gate function: Validate LLM approval\\\"\\\"\\\"\\n2025-12-04T23:47:50.3027433Z @@ -260,17 +261,15 @@\\n2025-12-04T23:47:50.3027750Z  \\n2025-12-04T23:47:50.3028200Z  def trigger_pipeline(state: State):\\n2025-12-04T23:47:50.3028672Z      \\\"\\\"\\\"Node 2: Trigger Azure DevOps pipeline\\\"\\\"\\\"\\n2025-12-04T23:47:50.3029104Z      try:\\n2025-12-04T23:47:50.3029423Z          if not AZURE_DEVOPS_PIPELINE_ID:\\n2025-12-04T23:47:50.3029833Z -            return {\\n2025-12-04T23:47:50.3030256Z -                \\\"error\\\": \\\"Azure DevOps pipeline ID not configured\\\"\\n2025-12-04T23:47:50.3030735Z -            }\\n2025-12-04T23:47:50.3031013Z -        \\n2025-12-04T23:47:50.3031427Z +            return {\\\"error\\\": \\\"Azure DevOps pipeline ID not configured\\\"}\\n2025-12-04T23:47:50.3031919Z +\\n2025-12-04T23:47:50.3032247Z          pipeline_id = int(AZURE_DEVOPS_PIPELINE_ID)\\n2025-12-04T23:47:50.3032763Z          result = trigger_azure_pipeline(pipeline_id)\\n2025-12-04T23:47:50.3033200Z -        \\n2025-12-04T23:47:50.3033466Z +\\n2025-12-04T23:47:50.3033723Z          if result:\\n2025-12-04T23:47:50.3034065Z              # Extract build/run ID from response\\n2025-12-04T23:47:50.3034518Z              build_id = result.get(\\\"id\\\")\\n2025-12-04T23:47:50.3034923Z              if not build_id:\\n2025-12-04T23:47:50.3035307Z                  # Try to extract from _links\\n2025-12-04T23:47:50.3035766Z @@ -280,95 +279,97 @@\\n2025-12-04T23:47:50.3036114Z                      parts = href.split(\\\"/\\\")\\n2025-12-04T23:47:50.3036578Z                      for i, part in enumerate(parts):\\n2025-12-04T23:47:50.3037067Z                          if part == \\\"runs\\\" and i + 1 < len(parts):\\n2025-12-04T23:47:50.3037566Z                              build_id = parts[i + 1]\\n2025-12-04T23:47:50.3038142Z                              break\\n2025-12-04T23:47:50.3038510Z -            \\n2025-12-04T23:47:50.3038783Z +\\n2025-12-04T23:47:50.3039036Z              if build_id:\\n2025-12-04T23:47:50.3039369Z                  return {\\n2025-12-04T23:47:50.3039742Z                      \\\"pipeline_id\\\": pipeline_id,\\n2025-12-04T23:47:50.3040394Z -                    \\\"build_id\\\": int(build_id) if isinstance(build_id, (str, int)) else pipeline_id,\\n2025-12-04T23:47:50.3041034Z -                    \\\"build_status\\\": \\\"InProgress\\\"\\n2025-12-04T23:47:50.3041485Z +                    \\\"build_id\\\": int(build_id)\\n2025-12-04T23:47:50.3041933Z +                    if isinstance(build_id, (str, int))\\n2025-12-04T23:47:50.3042381Z +                    else pipeline_id,\\n2025-12-04T23:47:50.3042819Z +                    \\\"build_status\\\": \\\"InProgress\\\",\\n2025-12-04T23:47:50.3043225Z                  }\\n2025-12-04T23:47:50.3043513Z              else:\\n2025-12-04T23:47:50.3043804Z                  return {\\n2025-12-04T23:47:50.3044315Z                      \\\"error\\\": \\\"Failed to extract build ID from pipeline trigger response\\\",\\n2025-12-04T23:47:50.3044926Z -                    \\\"pipeline_id\\\": pipeline_id\\n2025-12-04T23:47:50.3045406Z +                    \\\"pipeline_id\\\": pipeline_id,\\n2025-12-04T23:47:50.3046036Z                  }\\n2025-12-04T23:47:50.3046355Z          else:\\n2025-12-04T23:47:50.3046660Z              return {\\n2025-12-04T23:47:50.3047183Z                  \\\"error\\\": \\\"Failed to trigger Azure DevOps pipeline - check logs for details\\\"\\n2025-12-04T23:47:50.3050357Z              }\\n2025-12-04T23:47:50.3050683Z      except ValueError as e:\\n2025-12-04T23:47:50.3051062Z -        return {\\n2025-12-04T23:47:50.3051458Z -            \\\"error\\\": f\\\"Invalid pipeline ID format: {str(e)}\\\"\\n2025-12-04T23:47:50.3051944Z -        }\\n2025-12-04T23:47:50.3052356Z +        return {\\\"error\\\": f\\\"Invalid pipeline ID format: {str(e)}\\\"}\\n2025-12-04T23:47:50.3052895Z      except Exception as e:\\n2025-12-04T23:47:50.3053252Z -        return {\\n2025-12-04T23:47:50.3053643Z -            \\\"error\\\": f\\\"Error triggering pipeline: {str(e)}\\\"\\n2025-12-04T23:47:50.3054121Z -        }\\n2025-12-04T23:47:50.3054525Z +        return {\\\"error\\\": f\\\"Error triggering pipeline: {str(e)}\\\"}\\n2025-12-04T23:47:50.3055034Z  \\n2025-12-04T23:47:50.3055272Z  \\n2025-12-04T23:47:50.3055590Z  def check_pipeline_status(state: State):\\n2025-12-04T23:47:50.3056098Z      \\\"\\\"\\\"Node 2a: Check pipeline status with polling\\\"\\\"\\\"\\n2025-12-04T23:47:50.3056615Z      pipeline_id = state.get(\\\"pipeline_id\\\")\\n2025-12-04T23:47:50.3057232Z      build_id = state.get(\\\"build_id\\\")  # This is the run_id from pipeline trigger\\n2025-12-04T23:47:50.3057807Z -    \\n2025-12-04T23:47:50.3058285Z +\\n2025-12-04T23:47:50.3058585Z      if not pipeline_id or not build_id:\\n2025-12-04T23:47:50.3059010Z -        return {\\n2025-12-04T23:47:50.3059396Z -            \\\"error\\\": \\\"No pipeline ID or build ID available\\\"\\n2025-12-04T23:47:50.3059855Z -        }\\n2025-12-04T23:47:50.3060115Z -    \\n2025-12-04T23:47:50.3060507Z +        return {\\\"error\\\": \\\"No pipeline ID or build ID available\\\"}\\n2025-12-04T23:47:50.3060994Z +\\n2025-12-04T23:47:50.3061271Z      # Wait 3 seconds before first check\\n2025-12-04T23:47:50.3061804Z      print(\\\"Waiting 3 seconds before first status check...\\\")\\n2025-12-04T23:47:50.3062318Z      time.sleep(3)\\n2025-12-04T23:47:50.3062616Z -    \\n2025-12-04T23:47:50.3062873Z +\\n2025-12-04T23:47:50.3063326Z      max_attempts = 100  # Maximum polling attempts (5 minutes with 3s intervals)\\n2025-12-04T23:47:50.3063928Z      attempt = 0\\n2025-12-04T23:47:50.3064209Z -    \\n2025-12-04T23:47:50.3064458Z +\\n2025-12-04T23:47:50.3064903Z      print(f\\\"Starting status polling for pipeline {pipeline_id}, run {build_id}...\\\")\\n2025-12-04T23:47:50.3065480Z -    \\n2025-12-04T23:47:50.3065702Z +\\n2025-12-04T23:47:50.3065956Z      while attempt < max_attempts:\\n2025-12-04T23:47:50.3066306Z          try:\\n2025-12-04T23:47:50.3066676Z              run_info = get_pipeline_status(pipeline_id, build_id)\\n2025-12-04T23:47:50.3067121Z -            \\n2025-12-04T23:47:50.3067387Z +\\n2025-12-04T23:47:50.3067649Z              if run_info:\\n2025-12-04T23:47:50.3068232Z                  state_value = run_info.get(\\\"state\\\", \\\"\\\").lower()\\n2025-12-04T23:47:50.3068970Z -                result_value = run_info.get(\\\"result\\\", \\\"\\\").lower() if run_info.get(\\\"result\\\") else None\\n2025-12-04T23:47:50.3069613Z -                \\n2025-12-04T23:47:50.3069941Z +                result_value = (\\n2025-12-04T23:47:50.3070361Z +                    run_info.get(\\\"result\\\", \\\"\\\").lower()\\n2025-12-04T23:47:50.3070833Z +                    if run_info.get(\\\"result\\\")\\n2025-12-04T23:47:50.3071253Z +                    else None\\n2025-12-04T23:47:50.3071597Z +                )\\n2025-12-04T23:47:50.3071885Z +\\n2025-12-04T23:47:50.3072158Z                  # Check if completed\\n2025-12-04T23:47:50.3072597Z                  if state_value == \\\"completed\\\":\\n2025-12-04T23:47:50.3073029Z                      if result_value:\\n2025-12-04T23:47:50.3073550Z                          status_msg = f\\\"Completed - {result_value.capitalize()}\\\"\\n2025-12-04T23:47:50.3074080Z                      else:\\n2025-12-04T23:47:50.3074466Z                          status_msg = \\\"Completed\\\"\\n2025-12-04T23:47:50.3075095Z -                    print(f\\\"Pipeline run {build_id} completed with status: {status_msg}\\\")\\n2025-12-04T23:47:50.3075705Z -                    return {\\n2025-12-04T23:47:50.3076708Z -                        \\\"build_status\\\": status_msg\\n2025-12-04T23:47:50.3077205Z -                    }\\n2025-12-04T23:47:50.3077732Z +                    print(\\n2025-12-04T23:47:50.3078434Z +                        f\\\"Pipeline run {build_id} completed with status: {status_msg}\\\"\\n2025-12-04T23:47:50.3078996Z +                    )\\n2025-12-04T23:47:50.3079359Z +                    return {\\\"build_status\\\": status_msg}\\n2025-12-04T23:47:50.3079792Z                  else:\\n2025-12-04T23:47:50.3080152Z                      # Still in progress, log and wait\\n2025-12-04T23:47:50.3080680Z                      current_status = run_info.get(\\\"state\\\", \\\"Unknown\\\")\\n2025-12-04T23:47:50.3081488Z -                    print(f\\\"Pipeline run {build_id} status: {current_status} (attempt {attempt + 1}/{max_attempts})\\\")\\n2025-12-04T23:47:50.3082198Z +                    print(\\n2025-12-04T23:47:50.3082827Z +                        f\\\"Pipeline run {build_id} status: {current_status} (attempt {attempt + 1}/{max_attempts})\\\"\\n2025-12-04T23:47:50.3083490Z +                    )\\n2025-12-04T23:47:50.3083830Z                      time.sleep(3)\\n2025-12-04T23:47:50.3084225Z                      attempt += 1\\n2025-12-04T23:47:50.3084592Z              else:\\n2025-12-04T23:47:50.3084950Z                  # If we can't get status, wait and retry\\n2025-12-04T23:47:50.3085707Z -                print(f\\\"Unable to get status for run {build_id}, retrying... (attempt {attempt + 1}/{max_attempts})\\\")\\n2025-12-04T23:47:50.3086420Z +                print(\\n2025-12-04T23:47:50.3087026Z +                    f\\\"Unable to get status for run {build_id}, retrying... (attempt {attempt + 1}/{max_attempts})\\\"\\n2025-12-04T23:47:50.3087690Z +                )\\n2025-12-04T23:47:50.3088160Z                  time.sleep(3)\\n2025-12-04T23:47:50.3088532Z                  attempt += 1\\n2025-12-04T23:47:50.3088878Z -                \\n2025-12-04T23:47:50.3089168Z +\\n2025-12-04T23:47:50.3089450Z          except Exception as e:\\n2025-12-04T23:47:50.3089816Z -            return {\\n2025-12-04T23:47:50.3090241Z -                \\\"error\\\": f\\\"Error checking pipeline status: {str(e)}\\\"\\n2025-12-04T23:47:50.3090717Z -            }\\n2025-12-04T23:47:50.3091016Z -    \\n2025-12-04T23:47:50.3091419Z +            return {\\\"error\\\": f\\\"Error checking pipeline status: {str(e)}\\\"}\\n2025-12-04T23:47:50.3091933Z +\\n2025-12-04T23:47:50.3092220Z      # If we exhausted attempts\\n2025-12-04T23:47:50.3092833Z      print(f\\\"Pipeline status check timed out after {max_attempts} attempts\\\")\\n2025-12-04T23:47:50.3093414Z      return {\\n2025-12-04T23:47:50.3093867Z          \\\"build_status\\\": \\\"Timeout - Status check exceeded maximum attempts\\\",\\n2025-12-04T23:47:50.3094480Z -        \\\"error\\\": \\\"Pipeline status check timed out\\\"\\n2025-12-04T23:47:50.3094979Z +        \\\"error\\\": \\\"Pipeline status check timed out\\\",\\n2025-12-04T23:47:50.3095409Z      }\\n2025-12-04T23:47:50.3095659Z  \\n2025-12-04T23:47:50.3095902Z  \\n2025-12-04T23:47:50.3096157Z  # Build workflow\\n2025-12-04T23:47:50.3096488Z  workflow = StateGraph(State)\\n2025-12-04T23:47:50.3096869Z @@ -383,14 +384,11 @@\\n2025-12-04T23:47:50.3097269Z  workflow.add_edge(START, \\\"consult_slack_messages\\\")\\n2025-12-04T23:47:50.3097917Z  workflow.add_edge(\\\"consult_slack_messages\\\", \\\"check_albert_message\\\")\\n2025-12-04T23:47:50.3098703Z  workflow.add_conditional_edges(\\n2025-12-04T23:47:50.3099114Z      \\\"check_albert_message\\\",\\n2025-12-04T23:47:50.3099485Z      validate_approval,\\n2025-12-04T23:47:50.3099807Z -    {\\n2025-12-04T23:47:50.3100115Z -        \\\"Approved\\\": \\\"trigger_pipeline\\\",\\n2025-12-04T23:47:50.3100546Z -        \\\"Rejected\\\": END\\n2025-12-04T23:47:50.3100873Z -    }\\n2025-12-04T23:47:50.3101215Z +    {\\\"Approved\\\": \\\"trigger_pipeline\\\", \\\"Rejected\\\": END},\\n2025-12-04T23:47:50.3101670Z  )\\n2025-12-04T23:47:50.3102078Z  workflow.add_edge(\\\"trigger_pipeline\\\", \\\"check_pipeline_status\\\")\\n2025-12-04T23:47:50.3102685Z  workflow.add_edge(\\\"check_pipeline_status\\\", END)\\n2025-12-04T23:47:50.3103127Z  \\n2025-12-04T23:47:50.3103382Z  # Compile\\n2025-12-04T23:47:50.3103652Z @@ -400,36 +398,35 @@\\n2025-12-04T23:47:50.3104230Z  if __name__ == \\\"__main__\\\":\\n2025-12-04T23:47:50.3104652Z      # Show workflow graph BEFORE execution\\n2025-12-04T23:47:50.3105072Z      print(\\\"=\\\" * 60)\\n2025-12-04T23:47:50.3105645Z      print(\\\"Generating workflow graph...\\\")\\n2025-12-04T23:47:50.3106064Z      print(\\\"=\\\" * 60)\\n2025-12-04T23:47:50.3106369Z -    \\n2025-12-04T23:47:50.3106621Z +\\n2025-12-04T23:47:50.3106974Z      graph_image = chain.get_graph().draw_mermaid_png()\\n2025-12-04T23:47:50.3107433Z -    \\n2025-12-04T23:47:50.3107693Z +\\n2025-12-04T23:47:50.3108134Z      # Save the graph image to file\\n2025-12-04T23:47:50.3108588Z      graph_file = \\\"workflow_graph_v2.png\\\"\\n2025-12-04T23:47:50.3109031Z      with open(graph_file, \\\"wb\\\") as f:\\n2025-12-04T23:47:50.3109458Z          f.write(graph_image)\\n2025-12-04T23:47:50.3110214Z      print(f\\\"✓ Workflow graph saved to: {graph_file}\\\")\\n2025-12-04T23:47:50.3110660Z -    \\n2025-12-04T23:47:50.3110917Z +\\n2025-12-04T23:47:50.3111198Z      # Display the graph image\\n2025-12-04T23:47:50.3111636Z      img = PILImage.open(io.BytesIO(graph_image))\\n2025-12-04T23:47:50.3112389Z      img.show()  # Abrirá la imagen con el visor predeterminado\\n2025-12-04T23:47:50.3113045Z      print(\\\"✓ Workflow graph displayed\\\")\\n2025-12-04T23:47:50.3113482Z      print(\\\"=\\\" * 60)\\n2025-12-04T23:47:50.3113871Z      print(\\\"\\\\nStarting workflow execution...\\\\n\\\")\\n2025-12-04T23:47:50.3114304Z -    \\n2025-12-04T23:47:50.3114556Z +\\n2025-12-04T23:47:50.3114906Z      # Example usage - replace with actual channel name\\n2025-12-04T23:47:50.3115429Z      state = chain.invoke({\\\"channel\\\": \\\"general\\\"})\\n2025-12-04T23:47:50.3115860Z -    \\n2025-12-04T23:47:50.3116112Z +\\n2025-12-04T23:47:50.3116444Z      print(\\\"\\\\n=== Workflow Execution Result ===\\\\n\\\")\\n2025-12-04T23:47:50.3116947Z      print(f\\\"Channel: {state.get('channel')}\\\")\\n2025-12-04T23:47:50.3117531Z      print(f\\\"Messages found: {len(state.get('slack_messages', []))}\\\")\\n2025-12-04T23:47:50.3118389Z      print(f\\\"Albert H. message: {state.get('albert_message', 'Not found')}\\\")\\n2025-12-04T23:47:50.3119065Z      print(f\\\"LLM Approval: {state.get('llm_approval', 'N/A')}\\\")\\n2025-12-04T23:47:50.3119717Z      print(f\\\"Pipeline ID: {state.get('pipeline_id', 'N/A')}\\\")\\n2025-12-04T23:47:50.3120305Z      print(f\\\"Build ID: {state.get('build_id', 'N/A')}\\\")\\n2025-12-04T23:47:50.3120905Z      print(f\\\"Build Status: {state.get('build_status', 'N/A')}\\\")\\n2025-12-04T23:47:50.3121386Z -    \\n2025-12-04T23:47:50.3121680Z -    if state.get('error'):\\n2025-12-04T23:47:50.3122018Z +\\n2025-12-04T23:47:50.3122297Z +    if state.get(\\\"error\\\"):\\n2025-12-04T23:47:50.3122692Z          print(f\\\"Error: {state.get('error')}\\\")\\n2025-12-04T23:47:50.3123099Z -\\n2025-12-04T23:47:50.3354761Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\t2025-12-04 23:47:42.091627+00:00\\n2025-12-04T23:47:50.3359961Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\t2025-12-04 23:47:50.334110+00:00\\n2025-12-04T23:47:50.3361027Z @@ -28,10 +28,11 @@\\n2025-12-04T23:47:50.3361536Z  app.mount(\\\"/static\\\", StaticFiles(directory=STATIC_DIR), name=\\\"static\\\")\\n2025-12-04T23:47:50.3362124Z  \\n2025-12-04T23:47:50.3362402Z  # In-memory database\\n2025-12-04T23:47:50.3362748Z  posts_db = []\\n2025-12-04T23:47:50.3363043Z  replies_db = []\\n2025-12-04T23:47:50.3363348Z +\\n2025-12-04T23:47:50.3363589Z  \\n2025-12-04T23:47:50.3363868Z  # Initialize with sample data\\n2025-12-04T23:47:50.3364245Z  def init_sample_data():\\n2025-12-04T23:47:50.3364637Z      \\\"\\\"\\\"Initialize with sample post data\\\"\\\"\\\"\\n2025-12-04T23:47:50.3365165Z      if not posts_db:  # Only add if database is empty\\n2025-12-04T23:47:50.3365622Z @@ -39,25 +40,26 @@\\n2025-12-04T23:47:50.3365951Z              \\\"id\\\": str(uuid.uuid4()),\\n2025-12-04T23:47:50.3366402Z              \\\"title\\\": \\\"M190.0.0 Google Vertex AI Release\\\",\\n2025-12-04T23:47:50.3366874Z              \\\"user\\\": \\\"Cristina M.\\\",\\n2025-12-04T23:47:50.3367274Z              \\\"role\\\": \\\"Program Manager\\\",\\n2025-12-04T23:47:50.3368711Z              \\\"message\\\": \\\"Hello everyone, this is the deployment plan to start today with it. Please check the component ID here: vertex-ai-re-agent.\\\",\\n2025-12-04T23:47:50.3369770Z -            \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-04T23:47:50.3370518Z +            \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-04T23:47:50.3370971Z          }\\n2025-12-04T23:47:50.3371290Z          posts_db.append(sample_post)\\n2025-12-04T23:47:50.3371699Z -        \\n2025-12-04T23:47:50.3371970Z +\\n2025-12-04T23:47:50.3372271Z          # Add sample reply to the post\\n2025-12-04T23:47:50.3372701Z          sample_reply = {\\n2025-12-04T23:47:50.3373084Z              \\\"id\\\": str(uuid.uuid4()),\\n2025-12-04T23:47:50.3373506Z              \\\"post_id\\\": sample_post[\\\"id\\\"],\\n2025-12-04T23:47:50.3373907Z              \\\"user\\\": \\\"Alexa A.\\\",\\n2025-12-04T23:47:50.3374271Z              \\\"role\\\": \\\"SCRUM Master\\\",\\n2025-12-04T23:47:50.3374958Z              \\\"message\\\": \\\"M190.0.0 GVA validated.\\\\n\\\\nThere is no pending SC tickets.\\\\n\\\\nPlease start with the release.\\\",\\n2025-12-04T23:47:50.3375734Z -            \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-04T23:47:50.3376209Z +            \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-04T23:47:50.3376623Z          }\\n2025-12-04T23:47:50.3376928Z          replies_db.append(sample_reply)\\n2025-12-04T23:47:50.3377329Z  \\n2025-12-04T23:47:50.3377566Z +\\n2025-12-04T23:47:50.3377831Z  # Initialize sample data on startup\\n2025-12-04T23:47:50.3382457Z  init_sample_data()\\n2025-12-04T23:47:50.3382735Z  \\n2025-12-04T23:47:50.3382950Z  \\n2025-12-04T23:47:50.3383167Z  # Models\\n2025-12-04T23:47:50.3383416Z @@ -80,10 +82,11 @@\\n2025-12-04T23:47:50.3383682Z      message: str\\n2025-12-04T23:47:50.3383943Z  \\n2025-12-04T23:47:50.3384153Z  \\n2025-12-04T23:47:50.3384413Z  class ReplyCreateSimple(BaseModel):\\n2025-12-04T23:47:50.3384962Z      \\\"\\\"\\\"Simplified reply creation without post_id (post_id comes from URL)\\\"\\\"\\\"\\n2025-12-04T23:47:50.3385479Z +\\n2025-12-04T23:47:50.3385693Z      user: str\\n2025-12-04T23:47:50.3385938Z      role: str\\n2025-12-04T23:47:50.3386193Z      message: str\\n2025-12-04T23:47:50.3386449Z  \\n2025-12-04T23:47:50.3386669Z  \\n2025-12-04T23:47:50.3386899Z @@ -110,10 +113,11 @@\\n2025-12-04T23:47:50.3387191Z      timestamp: str\\n2025-12-04T23:47:50.3387457Z  \\n2025-12-04T23:47:50.3387686Z  \\n2025-12-04T23:47:50.3387934Z  class PostSummary(BaseModel):\\n2025-12-04T23:47:50.3388528Z      \\\"\\\"\\\"Simplified post model for list view (no replies)\\\"\\\"\\\"\\n2025-12-04T23:47:50.3388941Z +\\n2025-12-04T23:47:50.3389147Z      id: str\\n2025-12-04T23:47:50.3389405Z      title: Optional[str] = None\\n2025-12-04T23:47:50.3389710Z      message: str\\n2025-12-04T23:47:50.3389956Z  \\n2025-12-04T23:47:50.3390167Z  \\n2025-12-04T23:47:50.3390399Z @@ -139,36 +143,39 @@\\n2025-12-04T23:47:50.3390695Z  async def get_posts_full():\\n2025-12-04T23:47:50.3391119Z      \\\"\\\"\\\"Get all posts with their replies - for frontend use\\\"\\\"\\\"\\n2025-12-04T23:47:50.3391560Z      try:\\n2025-12-04T23:47:50.3391834Z          posts_with_replies = []\\n2025-12-04T23:47:50.3392182Z          for post in posts_db:\\n2025-12-04T23:47:50.3392729Z -            post_replies = [reply for reply in replies_db if reply[\\\"post_id\\\"] == post[\\\"id\\\"]]\\n2025-12-04T23:47:50.3393307Z +            post_replies = [\\n2025-12-04T23:47:50.3393766Z +                reply for reply in replies_db if reply[\\\"post_id\\\"] == post[\\\"id\\\"]\\n2025-12-04T23:47:50.3394242Z +            ]\\n2025-12-04T23:47:50.3394496Z              post_dict = {\\n2025-12-04T23:47:50.3394798Z                  \\\"id\\\": post[\\\"id\\\"],\\n2025-12-04T23:47:50.3395141Z                  \\\"title\\\": post.get(\\\"title\\\"),\\n2025-12-04T23:47:50.3395515Z                  \\\"user\\\": post[\\\"user\\\"],\\n2025-12-04T23:47:50.3396602Z                  \\\"role\\\": post[\\\"role\\\"],\\n2025-12-04T23:47:50.3397021Z                  \\\"message\\\": post[\\\"message\\\"],\\n2025-12-04T23:47:50.3397442Z                  \\\"timestamp\\\": post[\\\"timestamp\\\"],\\n2025-12-04T23:47:50.3397873Z -                \\\"replies\\\": post_replies\\n2025-12-04T23:47:50.3398597Z +                \\\"replies\\\": post_replies,\\n2025-12-04T23:47:50.3398965Z              }\\n2025-12-04T23:47:50.3399290Z              posts_with_replies.append(post_dict)\\n2025-12-04T23:47:50.3399937Z          return posts_with_replies\\n2025-12-04T23:47:50.3400373Z      except Exception as e:\\n2025-12-04T23:47:50.3400793Z          print(f\\\"Error in get_posts_full: {str(e)}\\\")\\n2025-12-04T23:47:50.3401456Z          import traceback\\n2025-12-04T23:47:50.3401789Z +\\n2025-12-04T23:47:50.3402051Z          traceback.print_exc()\\n2025-12-04T23:47:50.3402614Z          raise HTTPException(status_code=500, detail=f\\\"Internal server error: {str(e)}\\\")\\n2025-12-04T23:47:50.3403189Z  \\n2025-12-04T23:47:50.3403428Z  \\n2025-12-04T23:47:50.3403773Z  @app.get(\\\"/api/posts/{post_id}\\\", response_model=Post)\\n2025-12-04T23:47:50.3404259Z  async def get_post(post_id: str):\\n2025-12-04T23:47:50.3404664Z      \\\"\\\"\\\"Get a specific post with its replies\\\"\\\"\\\"\\n2025-12-04T23:47:50.3405175Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-04T23:47:50.3405628Z      if not post:\\n2025-12-04T23:47:50.3406024Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-04T23:47:50.3406481Z -    \\n2025-12-04T23:47:50.3406699Z +\\n2025-12-04T23:47:50.3407111Z      post_replies = [reply for reply in replies_db if reply[\\\"post_id\\\"] == post_id]\\n2025-12-04T23:47:50.3407635Z      post_dict = post.copy()\\n2025-12-04T23:47:50.3408196Z      post_dict[\\\"replies\\\"] = post_replies\\n2025-12-04T23:47:50.3408582Z      return post_dict\\n2025-12-04T23:47:50.3408879Z  \\n2025-12-04T23:47:50.3409135Z @@ -187,11 +194,11 @@\\n2025-12-04T23:47:50.3409463Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-04T23:47:50.3409838Z          \\\"title\\\": post.title,\\n2025-12-04T23:47:50.3410190Z          \\\"user\\\": post.user,\\n2025-12-04T23:47:50.3410550Z          \\\"role\\\": post.role,\\n2025-12-04T23:47:50.3410889Z          \\\"message\\\": post.message,\\n2025-12-04T23:47:50.3411292Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-04T23:47:50.3411730Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-04T23:47:50.3412111Z      }\\n2025-12-04T23:47:50.3412372Z      posts_db.append(new_post)\\n2025-12-04T23:47:50.3412700Z      return new_post\\n2025-12-04T23:47:50.3412965Z  \\n2025-12-04T23:47:50.3413182Z  \\n2025-12-04T23:47:50.3413401Z @@ -199,11 +206,11 @@\\n2025-12-04T23:47:50.3413785Z  async def update_post(post_id: str, post_update: PostUpdate):\\n2025-12-04T23:47:50.3414263Z      \\\"\\\"\\\"Update a post\\\"\\\"\\\"\\n2025-12-04T23:47:50.3414681Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-04T23:47:50.3415154Z      if not post:\\n2025-12-04T23:47:50.3415565Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-04T23:47:50.3416052Z -    \\n2025-12-04T23:47:50.3416279Z +\\n2025-12-04T23:47:50.3416536Z      if post_update.title is not None:\\n2025-12-04T23:47:50.3416933Z          post[\\\"title\\\"] = post_update.title\\n2025-12-04T23:47:50.3417318Z      if post_update.message is not None:\\n2025-12-04T23:47:50.3417717Z          post[\\\"message\\\"] = post_update.message\\n2025-12-04T23:47:50.3418356Z      post[\\\"timestamp\\\"] = datetime.now().isoformat()\\n2025-12-04T23:47:50.3418771Z @@ -214,11 +221,11 @@\\n2025-12-04T23:47:50.3419070Z  async def delete_post(post_id: str):\\n2025-12-04T23:47:50.3419466Z      \\\"\\\"\\\"Delete a post and all its replies\\\"\\\"\\\"\\n2025-12-04T23:47:50.3419933Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-04T23:47:50.3420392Z      if not post:\\n2025-12-04T23:47:50.3420801Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-04T23:47:50.3421261Z -    \\n2025-12-04T23:47:50.3421489Z +\\n2025-12-04T23:47:50.3421727Z      posts_db.remove(post)\\n2025-12-04T23:47:50.3422067Z      # Delete all replies for this post\\n2025-12-04T23:47:50.3422539Z      replies_db[:] = [r for r in replies_db if r[\\\"post_id\\\"] != post_id]\\n2025-12-04T23:47:50.3423101Z      return {\\\"message\\\": \\\"Post deleted successfully\\\"}\\n2025-12-04T23:47:50.3423507Z  \\n2025-12-04T23:47:50.3423740Z @@ -228,18 +235,18 @@\\n2025-12-04T23:47:50.3424142Z      \\\"\\\"\\\"Create a new reply to a post (requires post_id in body)\\\"\\\"\\\"\\n2025-12-04T23:47:50.3424620Z      # Verify post exists\\n2025-12-04T23:47:50.3425070Z      post = next((p for p in posts_db if p[\\\"id\\\"] == reply.post_id), None)\\n2025-12-04T23:47:50.3425751Z      if not post:\\n2025-12-04T23:47:50.3426181Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-04T23:47:50.3426788Z -    \\n2025-12-04T23:47:50.3427023Z +\\n2025-12-04T23:47:50.3427255Z      new_reply = {\\n2025-12-04T23:47:50.3427551Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-04T23:47:50.3427914Z          \\\"post_id\\\": reply.post_id,\\n2025-12-04T23:47:50.3428455Z          \\\"user\\\": reply.user,\\n2025-12-04T23:47:50.3428770Z          \\\"role\\\": reply.role,\\n2025-12-04T23:47:50.3429080Z          \\\"message\\\": reply.message,\\n2025-12-04T23:47:50.3429445Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-04T23:47:50.3429857Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-04T23:47:50.3430216Z      }\\n2025-12-04T23:47:50.3430461Z      replies_db.append(new_reply)\\n2025-12-04T23:47:50.3430805Z      return new_reply\\n2025-12-04T23:47:50.3431063Z  \\n2025-12-04T23:47:50.3431283Z  \\n2025-12-04T23:47:50.3431499Z @@ -248,18 +255,18 @@\\n2025-12-04T23:47:50.3432019Z      \\\"\\\"\\\"Create a new reply to a post (post_id from URL, simplified body with user, role, message)\\\"\\\"\\\"\\n2025-12-04T23:47:50.3432616Z      # Verify post exists\\n2025-12-04T23:47:50.3433027Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-04T23:47:50.3433488Z      if not post:\\n2025-12-04T23:47:50.3433896Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-04T23:47:50.3434370Z -    \\n2025-12-04T23:47:50.3434596Z +\\n2025-12-04T23:47:50.3434825Z      new_reply = {\\n2025-12-04T23:47:50.3435109Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-04T23:47:50.3435455Z          \\\"post_id\\\": post_id,\\n2025-12-04T23:47:50.3435820Z          \\\"user\\\": reply.user,\\n2025-12-04T23:47:50.3436148Z          \\\"role\\\": reply.role,\\n2025-12-04T23:47:50.3436483Z          \\\"message\\\": reply.message,\\n2025-12-04T23:47:50.3436865Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-04T23:47:50.3437300Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-04T23:47:50.3437672Z      }\\n2025-12-04T23:47:50.3438079Z      replies_db.append(new_reply)\\n2025-12-04T23:47:50.3438428Z      return new_reply\\n2025-12-04T23:47:50.3438716Z  \\n2025-12-04T23:47:50.3438936Z  \\n2025-12-04T23:47:50.3439187Z @@ -267,11 +274,11 @@\\n2025-12-04T23:47:50.3439650Z  async def update_reply(reply_id: str, reply_update: ReplyUpdate):\\n2025-12-04T23:47:50.3440173Z      \\\"\\\"\\\"Update a reply\\\"\\\"\\\"\\n2025-12-04T23:47:50.3440608Z      reply = next((r for r in replies_db if r[\\\"id\\\"] == reply_id), None)\\n2025-12-04T23:47:50.3441084Z      if not reply:\\n2025-12-04T23:47:50.3441504Z          raise HTTPException(status_code=404, detail=\\\"Reply not found\\\")\\n2025-12-04T23:47:50.3441984Z -    \\n2025-12-04T23:47:50.3442224Z +\\n2025-12-04T23:47:50.3442497Z      reply[\\\"message\\\"] = reply_update.message\\n2025-12-04T23:47:50.3442957Z      reply[\\\"timestamp\\\"] = datetime.now().isoformat()\\n2025-12-04T23:47:50.3443377Z      return reply\\n2025-12-04T23:47:50.3443634Z  \\n2025-12-04T23:47:50.3443857Z  \\n2025-12-04T23:47:50.3444083Z @@ -279,13 +286,14 @@\\n2025-12-04T23:47:50.3444409Z  async def delete_reply(reply_id: str):\\n2025-12-04T23:47:50.3444792Z      \\\"\\\"\\\"Delete a reply\\\"\\\"\\\"\\n2025-12-04T23:47:50.3445223Z      reply = next((r for r in replies_db if r[\\\"id\\\"] == reply_id), None)\\n2025-12-04T23:47:50.3445692Z      if not reply:\\n2025-12-04T23:47:50.3446078Z          raise HTTPException(status_code=404, detail=\\\"Reply not found\\\")\\n2025-12-04T23:47:50.3446516Z -    \\n2025-12-04T23:47:50.3446734Z +\\n2025-12-04T23:47:50.3446969Z      replies_db.remove(reply)\\n2025-12-04T23:47:50.3447351Z      return {\\\"message\\\": \\\"Reply deleted successfully\\\"}\\n2025-12-04T23:47:50.3447739Z  \\n2025-12-04T23:47:50.3448164Z  \\n2025-12-04T23:47:50.3448423Z  if __name__ == \\\"__main__\\\":\\n2025-12-04T23:47:50.3448733Z      import uvicorn\\n2025-12-04T23:47:50.3448999Z +\\n2025-12-04T23:47:50.3449272Z      uvicorn.run(app, host=\\\"0.0.0.0\\\", port=8000)\\n2025-12-04T23:47:50.3450240Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\n2025-12-04T23:47:50.3473754Z \\n2025-12-04T23:47:50.3474436Z Oh no! 💥 💔 💥\\n2025-12-04T23:47:50.3474792Z 3 files would be reformatted.\\n2025-12-04T23:47:50.3719319Z \\n2025-12-04T23:47:50.3740756Z ##[error]Black found code formatting issues. Some files need to be reformatted.\\n2025-12-04T23:47:50.3750157Z ##[notice]Run 'black --exclude='\\\\''/(env|\\\\.git|__pycache__)/'\\\\'' .' locally to fix formatting issues.\\n2025-12-04T23:47:50.3752469Z ##[error]Process completed with exit code 1.\\n2025-12-04T23:47:50.3861443Z Post job cleanup.\\n2025-12-04T23:47:50.4809625Z [command]/usr/bin/git version\\n2025-12-04T23:47:50.4850977Z git version 2.52.0\\n2025-12-04T23:47:50.4895875Z Temporarily overriding HOME='/home/runner/work/_temp/a19031d6-a435-4283-b648-250270de83f3' before making global git config changes\\n2025-12-04T23:47:50.4898193Z Adding repository directory to the temporary git global config as a safe directory\\n2025-12-04T23:47:50.4903633Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-04T23:47:50.4945856Z [command]/usr/bin/git config --local --name-only --get-regexp core\\\\.sshCommand\\n2025-12-04T23:47:50.4980764Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'core\\\\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :\\\"\\n2025-12-04T23:47:50.5282109Z [command]/usr/bin/git config --local --name-only --get-regexp http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader\\n2025-12-04T23:47:50.5323273Z http.https://github.com/.extraheader\\n2025-12-04T23:47:50.5344876Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader\\n2025-12-04T23:47:50.5408545Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :\\\"\\n2025-12-04T23:47:50.5755391Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\\\\.gitdir:\\n2025-12-04T23:47:50.5806209Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url\\n2025-12-04T23:47:50.6291769Z Cleaning up orphan processes\\n\",\n    \"message_available\": \"true\",\n    \"deployment\": {\n      \"can_start\": \"true\",\n      \"reason\": \"M190.0.0 GVA validated.\\n\\nThere is no pending SC tickets.\\n\\nPlease start with the release.\",\n      \"component_id\": \"release_engineering_agentic_workflow\",\n      \"conversation_thread_title\": \"M190.0.0 Google Vertex AI Release\"\n    },\n    \"workflow\": {\n      \"build_id\": \"19947683678\",\n      \"status\": \"failure\",\n      \"logs_url\": \"https://api.github.com/repos/francodem/release_engineering_agentic_workflow/actions/runs/19947683678/logs\"\n    }\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        3264,
        -768
      ],
      "id": "a81096c6-6340-488f-90cf-002b5db3b2fd",
      "name": "Edit Fields2"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        5136,
        -1008
      ],
      "id": "2dadf404-0a2e-444e-bd6a-0fd0078016cf",
      "name": "When clicking ‘Execute workflow’"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={\n  \"output\": {\n    \"h1\": {{ JSON.stringify($json.hipothesis_1) }},\n    \"h2\": {{ JSON.stringify($json.hipothesis_2) }},\n    \"h3\": {{ JSON.stringify($json.hipothesis_3) }}\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4544,
        -592
      ],
      "id": "7c7f2811-13f0-467c-a487-c1b7262a2d0b",
      "name": "Edit Fields5"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": " { \"output\": {\n    \"h1\": \"The CI/CD pipeline failed because the 'black' code formatter identified formatting inconsistencies in three Python files: src/agent/re_agent.py, src/agent/re_agent_v2.py, and src/emulation/teams/app.py. The pipeline's linting step is configured to fail the job if 'black --check --diff' detects any deviations from its formatting standards, as evidenced by the log output \\\"3 files would be reformatted\\\" and the subsequent error \\\"Black found code formatting issues. Some files need to be reformatted.\\\" leading to \\\"Process completed with exit code 1.\\\"\",\n    \"h2\": \"The CI/CD pipeline failed because the 'black' code formatter check identified formatting inconsistencies in three Python files: src/agent/re_agent.py, src/agent/re_agent_v2.py, and src/emulation/teams/app.py. The 'black --check' command, configured to fail on such discrepancies, exited with status 1, as evidenced by \\\"Black found code formatting issues. Some files need to be reformatted.\\\" and the diffs showing proposed reformatting changes for these files.\",\n    \"h3\": \"The `black` code formatter check is failing because three Python files (src/agent/re_agent.py, src/agent/re_agent_v2.py, and src/emulation/teams/app.py) contain formatting inconsistencies that `black` would reformat. The CI step exits with code 1 because the `black --check --diff` command detected these deviations from the expected formatting style. This is evidenced by the log lines \\\"3 files would be reformatted.\\\" and \\\"Black found code formatting issues. Some files need to be reformatted.\\\" immediately followed by \\\"Process completed with exit code 1.\\\" after the `black` command execution.\"\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4544,
        -768
      ],
      "id": "3ea12672-21ec-462c-881a-ec821d5281a9",
      "name": "Edit Fields6"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        4704,
        -640
      ],
      "id": "4a0d0a31-b791-413e-a50b-a5872e1459be",
      "name": "Merge1"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\n  \"output\": {\n    \"logs_content\": \"2025-12-05T00:06:51.1438862Z Current runner version: '2.329.0'\\n2025-12-05T00:06:51.1508864Z ##[group]Runner Image Provisioner\\n2025-12-05T00:06:51.1510258Z Hosted Compute Agent\\n2025-12-05T00:06:51.1511248Z Version: 20251124.448\\n2025-12-05T00:06:51.1512381Z Commit: fda5086b43ec66ade217e5fcd18146c879571177\\n2025-12-05T00:06:51.1513525Z Build Date: 2025-11-24T21:16:26Z\\n2025-12-05T00:06:51.1514631Z ##[endgroup]\\n2025-12-05T00:06:51.1515507Z ##[group]Operating System\\n2025-12-05T00:06:51.1516473Z Ubuntu\\n2025-12-05T00:06:51.1517519Z 24.04.3\\n2025-12-05T00:06:51.1518548Z LTS\\n2025-12-05T00:06:51.1519301Z ##[endgroup]\\n2025-12-05T00:06:51.1520027Z ##[group]Runner Image\\n2025-12-05T00:06:51.1521079Z Image: ubuntu-24.04\\n2025-12-05T00:06:51.1521855Z Version: 20251126.144.1\\n2025-12-05T00:06:51.1523570Z Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20251126.144/images/ubuntu/Ubuntu2404-Readme.md\\n2025-12-05T00:06:51.1526558Z Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20251126.144\\n2025-12-05T00:06:51.1548851Z ##[endgroup]\\n2025-12-05T00:06:51.1550717Z ##[group]GITHUB_TOKEN Permissions\\n2025-12-05T00:06:51.1553593Z Contents: read\\n2025-12-05T00:06:51.1554443Z Metadata: read\\n2025-12-05T00:06:51.1555257Z Packages: read\\n2025-12-05T00:06:51.1555981Z ##[endgroup]\\n2025-12-05T00:06:51.1559679Z Secret source: Actions\\n2025-12-05T00:06:51.1560934Z Prepare workflow directory\\n2025-12-05T00:06:51.2556404Z Prepare all required actions\\n2025-12-05T00:06:51.2685753Z Getting action download info\\n2025-12-05T00:06:51.6255504Z Download action repository 'actions/checkout@v4' (SHA:34e114876b0b11c390a56381ad16ebd13914f8d5)\\n2025-12-05T00:06:52.8577793Z Download action repository 'actions/setup-python@v5' (SHA:a26af69be951a213d495a4c3e4e4022e16d87065)\\n2025-12-05T00:06:53.0720232Z Complete job name: lint\\n2025-12-05T00:06:53.1561300Z ##[group]Run actions/checkout@v4\\n2025-12-05T00:06:53.1562249Z with:\\n2025-12-05T00:06:53.1562824Z   repository: francodem/release_engineering_agentic_workflow\\n2025-12-05T00:06:53.1563762Z   token: ***\\n2025-12-05T00:06:53.1564216Z   ssh-strict: true\\n2025-12-05T00:06:53.1564645Z   ssh-user: git\\n2025-12-05T00:06:53.1565089Z   persist-credentials: true\\n2025-12-05T00:06:53.1565574Z   clean: true\\n2025-12-05T00:06:53.1566011Z   sparse-checkout-cone-mode: true\\n2025-12-05T00:06:53.1566536Z   fetch-depth: 1\\n2025-12-05T00:06:53.1567212Z   fetch-tags: false\\n2025-12-05T00:06:53.1567656Z   show-progress: true\\n2025-12-05T00:06:53.1568110Z   lfs: false\\n2025-12-05T00:06:53.1568523Z   submodules: false\\n2025-12-05T00:06:53.1568976Z   set-safe-directory: true\\n2025-12-05T00:06:53.1569728Z ##[endgroup]\\n2025-12-05T00:06:53.2827374Z Syncing repository: francodem/release_engineering_agentic_workflow\\n2025-12-05T00:06:53.2831240Z ##[group]Getting Git version info\\n2025-12-05T00:06:53.2835338Z Working directory is '/home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow'\\n2025-12-05T00:06:53.2839919Z [command]/usr/bin/git version\\n2025-12-05T00:06:53.2917329Z git version 2.52.0\\n2025-12-05T00:06:53.2952260Z ##[endgroup]\\n2025-12-05T00:06:53.2969452Z Temporarily overriding HOME='/home/runner/work/_temp/6ba185f3-1441-4e1e-b63e-977e8173f796' before making global git config changes\\n2025-12-05T00:06:53.2973319Z Adding repository directory to the temporary git global config as a safe directory\\n2025-12-05T00:06:53.2978753Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-05T00:06:53.3045487Z Deleting the contents of '/home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow'\\n2025-12-05T00:06:53.3049349Z ##[group]Initializing the repository\\n2025-12-05T00:06:53.3055409Z [command]/usr/bin/git init /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-05T00:06:53.3168723Z hint: Using 'master' as the name for the initial branch. This default branch name\\n2025-12-05T00:06:53.3171736Z hint: will change to \\\"main\\\" in Git 3.0. To configure the initial branch name\\n2025-12-05T00:06:53.3176781Z hint: to use in all of your new repositories, which will suppress this warning,\\n2025-12-05T00:06:53.3178540Z hint: call:\\n2025-12-05T00:06:53.3179292Z hint:\\n2025-12-05T00:06:53.3180257Z hint: \\tgit config --global init.defaultBranch <name>\\n2025-12-05T00:06:53.3181444Z hint:\\n2025-12-05T00:06:53.3182496Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\\n2025-12-05T00:06:53.3184231Z hint: 'development'. The just-created branch can be renamed via this command:\\n2025-12-05T00:06:53.3185604Z hint:\\n2025-12-05T00:06:53.3186356Z hint: \\tgit branch -m <name>\\n2025-12-05T00:06:53.3187538Z hint:\\n2025-12-05T00:06:53.3188640Z hint: Disable this message with \\\"git config set advice.defaultBranchName false\\\"\\n2025-12-05T00:06:53.3191794Z Initialized empty Git repository in /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/.git/\\n2025-12-05T00:06:53.3196783Z [command]/usr/bin/git remote add origin https://github.com/francodem/release_engineering_agentic_workflow\\n2025-12-05T00:06:53.3242762Z ##[endgroup]\\n2025-12-05T00:06:53.3244291Z ##[group]Disabling automatic garbage collection\\n2025-12-05T00:06:53.3247581Z [command]/usr/bin/git config --local gc.auto 0\\n2025-12-05T00:06:53.3291811Z ##[endgroup]\\n2025-12-05T00:06:53.3298846Z ##[group]Setting up auth\\n2025-12-05T00:06:53.3302472Z [command]/usr/bin/git config --local --name-only --get-regexp core\\\\.sshCommand\\n2025-12-05T00:06:53.3358677Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'core\\\\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :\\\"\\n2025-12-05T00:06:53.3765183Z [command]/usr/bin/git config --local --name-only --get-regexp http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader\\n2025-12-05T00:06:53.3808253Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :\\\"\\n2025-12-05T00:06:53.4083367Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\\\\.gitdir:\\n2025-12-05T00:06:53.4127566Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url\\n2025-12-05T00:06:53.4406490Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***\\n2025-12-05T00:06:53.4454120Z ##[endgroup]\\n2025-12-05T00:06:53.4456063Z ##[group]Fetching the repository\\n2025-12-05T00:06:53.4464669Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +2161c4070034b2d4f93236804983b19c602fffb0:refs/remotes/origin/main\\n2025-12-05T00:06:53.6916087Z From https://github.com/francodem/release_engineering_agentic_workflow\\n2025-12-05T00:06:53.6931826Z  * [new ref]         2161c4070034b2d4f93236804983b19c602fffb0 -> origin/main\\n2025-12-05T00:06:53.6971371Z ##[endgroup]\\n2025-12-05T00:06:53.6973221Z ##[group]Determining the checkout info\\n2025-12-05T00:06:53.6975208Z ##[endgroup]\\n2025-12-05T00:06:53.6976466Z [command]/usr/bin/git sparse-checkout disable\\n2025-12-05T00:06:53.7027501Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig\\n2025-12-05T00:06:53.7058732Z ##[group]Checking out the ref\\n2025-12-05T00:06:53.7064482Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main\\n2025-12-05T00:06:53.7136682Z Switched to a new branch 'main'\\n2025-12-05T00:06:53.7141479Z branch 'main' set up to track 'origin/main'.\\n2025-12-05T00:06:53.7154810Z ##[endgroup]\\n2025-12-05T00:06:53.7198164Z [command]/usr/bin/git log -1 --format=%H\\n2025-12-05T00:06:53.7227403Z 2161c4070034b2d4f93236804983b19c602fffb0\\n2025-12-05T00:06:53.7574714Z ##[group]Run actions/setup-python@v5\\n2025-12-05T00:06:53.7575922Z with:\\n2025-12-05T00:06:53.7576760Z   python-version: 3.13\\n2025-12-05T00:06:53.7577862Z   cache: pip\\n2025-12-05T00:06:53.7578713Z   check-latest: false\\n2025-12-05T00:06:53.7579978Z   token: ***\\n2025-12-05T00:06:53.7581199Z   update-environment: true\\n2025-12-05T00:06:53.7582254Z   allow-prereleases: false\\n2025-12-05T00:06:53.7583279Z   freethreaded: false\\n2025-12-05T00:06:53.7584205Z ##[endgroup]\\n2025-12-05T00:06:53.9704599Z ##[group]Installed versions\\n2025-12-05T00:06:54.0292650Z Successfully set up CPython (3.13.9)\\n2025-12-05T00:06:54.0296157Z ##[endgroup]\\n2025-12-05T00:06:54.1026697Z [command]/opt/hostedtoolcache/Python/3.13.9/x64/bin/pip cache dir\\n2025-12-05T00:06:56.3020229Z /home/runner/.cache/pip\\n2025-12-05T00:06:56.4780769Z pip cache is not found\\n2025-12-05T00:06:56.4924751Z ##[group]Run pip install -r src/emulation/teams/requirements.txt\\n2025-12-05T00:06:56.4925252Z \\u001b[36;1mpip install -r src/emulation/teams/requirements.txt\\u001b[0m\\n2025-12-05T00:06:56.4964904Z shell: /usr/bin/bash -e {0}\\n2025-12-05T00:06:56.4965173Z env:\\n2025-12-05T00:06:56.4965424Z   pythonLocation: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:06:56.4965828Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib/pkgconfig\\n2025-12-05T00:06:56.4966244Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:06:56.4966581Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:06:56.4967277Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:06:56.4967672Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib\\n2025-12-05T00:06:56.4967961Z ##[endgroup]\\n2025-12-05T00:06:58.1928690Z Collecting fastapi==0.104.1 (from -r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:58.2657581Z   Downloading fastapi-0.104.1-py3-none-any.whl.metadata (24 kB)\\n2025-12-05T00:06:58.3062004Z Collecting uvicorn==0.24.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:58.3101169Z   Downloading uvicorn-0.24.0-py3-none-any.whl.metadata (6.4 kB)\\n2025-12-05T00:06:58.3492967Z Collecting jinja2==3.1.2 (from -r src/emulation/teams/requirements.txt (line 3))\\n2025-12-05T00:06:58.3584501Z   Downloading Jinja2-3.1.2-py3-none-any.whl.metadata (3.5 kB)\\n2025-12-05T00:06:58.3787072Z Collecting python-multipart==0.0.6 (from -r src/emulation/teams/requirements.txt (line 4))\\n2025-12-05T00:06:58.3835969Z   Downloading python_multipart-0.0.6-py3-none-any.whl.metadata (2.5 kB)\\n2025-12-05T00:06:58.4377693Z Collecting black==23.10.1 (from -r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:06:58.4515667Z   Downloading black-23.10.1-py3-none-any.whl.metadata (66 kB)\\n2025-12-05T00:06:58.4869731Z Collecting anyio<4.0.0,>=3.7.1 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:58.4923839Z   Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\\n2025-12-05T00:06:58.6465186Z Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:58.6518596Z   Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\\n2025-12-05T00:06:58.6968558Z Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:58.7008401Z   Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\\n2025-12-05T00:06:58.7231478Z Collecting typing-extensions>=4.8.0 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:58.7294282Z   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\\n2025-12-05T00:06:58.7513337Z Collecting click>=7.0 (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:58.7564014Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\\n2025-12-05T00:06:58.7727781Z Collecting h11>=0.8 (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:58.7769776Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\\n2025-12-05T00:06:58.8445078Z Collecting MarkupSafe>=2.0 (from jinja2==3.1.2->-r src/emulation/teams/requirements.txt (line 3))\\n2025-12-05T00:06:58.8516465Z   Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\\n2025-12-05T00:06:58.8725356Z Collecting mypy-extensions>=0.4.3 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:06:58.8784382Z   Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\\n2025-12-05T00:06:58.8972369Z Collecting packaging>=22.0 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:06:58.9013622Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\\n2025-12-05T00:06:58.9172386Z Collecting pathspec>=0.9.0 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:06:58.9216389Z   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\\n2025-12-05T00:06:58.9459837Z Collecting platformdirs>=2 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:06:58.9504150Z   Downloading platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\\n2025-12-05T00:06:58.9872455Z Collecting httptools>=0.5.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:59.0020630Z   Downloading httptools-0.7.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\\n2025-12-05T00:06:59.0229747Z Collecting python-dotenv>=0.13 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:59.0282208Z   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\\n2025-12-05T00:06:59.0744913Z Collecting pyyaml>=5.1 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:59.0824881Z   Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\\n2025-12-05T00:06:59.1345110Z Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:59.1446390Z   Downloading uvloop-0.22.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\\n2025-12-05T00:06:59.2326287Z Collecting watchfiles>=0.13 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:59.2395151Z   Downloading watchfiles-1.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\\n2025-12-05T00:06:59.3317337Z Collecting websockets>=10.4 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:06:59.3364826Z   Downloading websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\\n2025-12-05T00:06:59.3611912Z Collecting idna>=2.8 (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:59.3658970Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\\n2025-12-05T00:06:59.3831124Z Collecting sniffio>=1.1 (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:59.3892240Z   Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\\n2025-12-05T00:06:59.4045353Z Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:06:59.4109307Z   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\\n2025-12-05T00:07:00.0977614Z Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:07:00.1027375Z   Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\\n2025-12-05T00:07:00.1274490Z Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:07:00.1350854Z   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\\n2025-12-05T00:07:00.1761585Z Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\\n2025-12-05T00:07:00.1848457Z Downloading uvicorn-0.24.0-py3-none-any.whl (59 kB)\\n2025-12-05T00:07:00.1910461Z Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\\n2025-12-05T00:07:00.1981913Z Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\\n2025-12-05T00:07:00.2073273Z Downloading black-23.10.1-py3-none-any.whl (184 kB)\\n2025-12-05T00:07:00.2200610Z Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\\n2025-12-05T00:07:00.2287362Z Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\\n2025-12-05T00:07:00.2419304Z Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\\n2025-12-05T00:07:00.2580222Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 154.3 MB/s  0:00:00\\n2025-12-05T00:07:00.2627723Z Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\\n2025-12-05T00:07:00.2808624Z Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\\n2025-12-05T00:07:00.2872168Z Downloading click-8.3.1-py3-none-any.whl (108 kB)\\n2025-12-05T00:07:00.2946052Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)\\n2025-12-05T00:07:00.3012021Z Downloading httptools-0.7.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (478 kB)\\n2025-12-05T00:07:00.3138885Z Downloading idna-3.11-py3-none-any.whl (71 kB)\\n2025-12-05T00:07:00.3211134Z Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\\n2025-12-05T00:07:00.3284464Z Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\\n2025-12-05T00:07:00.3355299Z Downloading packaging-25.0-py3-none-any.whl (66 kB)\\n2025-12-05T00:07:00.3423287Z Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\\n2025-12-05T00:07:00.3507470Z Downloading platformdirs-4.5.0-py3-none-any.whl (18 kB)\\n2025-12-05T00:07:00.3587861Z Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\\n2025-12-05T00:07:00.3659952Z Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\\n2025-12-05T00:07:00.3741780Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 801.6/801.6 kB 112.0 MB/s  0:00:00\\n2025-12-05T00:07:00.3780925Z Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\\n2025-12-05T00:07:00.3860111Z Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\\n2025-12-05T00:07:00.3981115Z Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\\n2025-12-05T00:07:00.4050466Z Downloading uvloop-0.22.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\\n2025-12-05T00:07:00.4387503Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 136.3 MB/s  0:00:00\\n2025-12-05T00:07:00.4468034Z Downloading watchfiles-1.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\\n2025-12-05T00:07:00.4607463Z Downloading websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\\n2025-12-05T00:07:00.5586570Z Installing collected packages: websockets, uvloop, typing-extensions, sniffio, pyyaml, python-multipart, python-dotenv, platformdirs, pathspec, packaging, mypy-extensions, MarkupSafe, idna, httptools, h11, click, annotated-types, uvicorn, typing-inspection, pydantic-core, jinja2, black, anyio, watchfiles, starlette, pydantic, fastapi\\n2025-12-05T00:07:02.1470583Z \\n2025-12-05T00:07:02.1509943Z Successfully installed MarkupSafe-3.0.3 annotated-types-0.7.0 anyio-3.7.1 black-23.10.1 click-8.3.1 fastapi-0.104.1 h11-0.16.0 httptools-0.7.1 idna-3.11 jinja2-3.1.2 mypy-extensions-1.1.0 packaging-25.0 pathspec-0.12.1 platformdirs-4.5.0 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 python-multipart-0.0.6 pyyaml-6.0.3 sniffio-1.3.1 starlette-0.27.0 typing-extensions-4.15.0 typing-inspection-0.4.2 uvicorn-0.24.0 uvloop-0.22.1 watchfiles-1.1.1 websockets-15.0.1\\n2025-12-05T00:07:02.5043690Z ##[group]Run # black src/emulation/teams\\n2025-12-05T00:07:02.5044049Z \\u001b[36;1m# black src/emulation/teams\\u001b[0m\\n2025-12-05T00:07:02.5044578Z \\u001b[36;1mif ! black --check --diff --exclude='/(env|\\\\.git|__pycache__)/' .; then\\u001b[0m\\n2025-12-05T00:07:02.5044910Z \\u001b[36;1m  echo \\\"\\\" >&2\\u001b[0m\\n2025-12-05T00:07:02.5045278Z \\u001b[36;1m  echo \\\"::error::Black found code formatting issues. Some files need to be reformatted.\\\" >&2\\u001b[0m\\n2025-12-05T00:07:02.5045865Z \\u001b[36;1m  echo \\\"::notice::Run 'black --exclude='\\\\''/(env|\\\\.git|__pycache__)/'\\\\'' .' locally to fix formatting issues.\\\" >&2\\u001b[0m\\n2025-12-05T00:07:02.5046278Z \\u001b[36;1m  exit 1\\u001b[0m\\n2025-12-05T00:07:02.5046450Z \\u001b[36;1mfi\\u001b[0m\\n2025-12-05T00:07:02.5046682Z \\u001b[36;1mecho \\\"✓ All Python files are properly formatted!\\\"\\u001b[0m\\n2025-12-05T00:07:02.5079742Z shell: /usr/bin/bash -e {0}\\n2025-12-05T00:07:02.5079960Z env:\\n2025-12-05T00:07:02.5080193Z   pythonLocation: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:07:02.5080629Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib/pkgconfig\\n2025-12-05T00:07:02.5081021Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:07:02.5081353Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:07:02.5081687Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:07:02.5082013Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib\\n2025-12-05T00:07:02.5082295Z ##[endgroup]\\n2025-12-05T00:07:03.6144432Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\t2025-12-05 00:06:53.708885+00:00\\n2025-12-05T00:07:03.6152878Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\t2025-12-05 00:07:03.542873+00:00\\n2025-12-05T00:07:03.6168902Z @@ -12,10 +12,11 @@\\n2025-12-05T00:07:03.6171341Z      max_tokens=2000,\\n2025-12-05T00:07:03.6174469Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\n2025-12-05T00:07:03.6175791Z      max_retries=6,\\n2025-12-05T00:07:03.6283909Z      stop=None,\\n2025-12-05T00:07:03.6306138Z      # other params...\\n2025-12-05T00:07:03.6306798Z  )\\n2025-12-05T00:07:03.6307799Z +\\n2025-12-05T00:07:03.6308294Z  \\n2025-12-05T00:07:03.6308765Z  # Graph state\\n2025-12-05T00:07:03.6309319Z  class State(TypedDict):\\n2025-12-05T00:07:03.6309882Z      topic: str\\n2025-12-05T00:07:03.6310392Z      joke: str\\n2025-12-05T00:07:03.6310874Z @@ -71,11 +72,13 @@\\n2025-12-05T00:07:03.6318455Z  workflow.add_node(\\\"polish_joke\\\", polish_joke)\\n2025-12-05T00:07:03.6318916Z  \\n2025-12-05T00:07:03.6319204Z  # Add edges to connect nodes\\n2025-12-05T00:07:03.6319622Z  workflow.add_edge(START, \\\"generate_joke\\\")\\n2025-12-05T00:07:03.6320091Z  workflow.add_conditional_edges(\\n2025-12-05T00:07:03.6320741Z -    \\\"generate_joke\\\", check_punchline, {\\\"Fail\\\": \\\"improve_joke\\\", \\\"Pass\\\": \\\"ask_for_applause\\\"}\\n2025-12-05T00:07:03.6321408Z +    \\\"generate_joke\\\",\\n2025-12-05T00:07:03.6321738Z +    check_punchline,\\n2025-12-05T00:07:03.6322169Z +    {\\\"Fail\\\": \\\"improve_joke\\\", \\\"Pass\\\": \\\"ask_for_applause\\\"},\\n2025-12-05T00:07:03.6322633Z  )\\n2025-12-05T00:07:03.6322985Z  workflow.add_edge(\\\"improve_joke\\\", \\\"polish_joke\\\")\\n2025-12-05T00:07:03.6323574Z  workflow.add_edge(\\\"polish_joke\\\", \\\"ask_for_applause\\\")\\n2025-12-05T00:07:03.6324114Z  workflow.add_edge(\\\"ask_for_applause\\\", END)\\n2025-12-05T00:07:03.6324538Z  \\n2025-12-05T00:07:03.6324795Z @@ -102,6 +105,6 @@\\n2025-12-05T00:07:03.6325130Z      print(state[\\\"final_joke\\\"])\\n2025-12-05T00:07:03.6325536Z  elif \\\"ask_for_applause\\\" in state:\\n2025-12-05T00:07:03.6325961Z      print(\\\"Ask for applause:\\\")\\n2025-12-05T00:07:03.6326379Z      print(state[\\\"ask_for_applause\\\"])\\n2025-12-05T00:07:03.6326778Z  else:\\n2025-12-05T00:07:03.6327376Z -    print(\\\"Joke failed quality gate - no punchline detected!\\\")\\n2025-12-05T00:07:03.6327932Z \\\\ No newline at end of file\\n2025-12-05T00:07:03.6328424Z +    print(\\\"Joke failed quality gate - no punchline detected!\\\")\\n2025-12-05T00:07:03.9725214Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\t2025-12-05 00:06:53.709885+00:00\\n2025-12-05T00:07:03.9729981Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\n2025-12-05T00:07:03.9736072Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\t2025-12-05 00:07:03.965737+00:00\\n2025-12-05T00:07:03.9753688Z @@ -30,11 +30,16 @@\\n2025-12-05T00:07:03.9754124Z  AZURE_DEVOPS_ORG = os.getenv(\\\"AZURE_DEVOPS_ORG\\\")\\n2025-12-05T00:07:03.9754739Z  AZURE_DEVOPS_PROJECT = os.getenv(\\\"AZURE_DEVOPS_PROJECT\\\")\\n2025-12-05T00:07:03.9755410Z  AZURE_DEVOPS_PIPELINE_ID = os.getenv(\\\"AZURE_DEVOPS_PIPELINE_ID\\\")\\n2025-12-05T00:07:03.9755969Z  \\n2025-12-05T00:07:03.9756381Z  # Azure DevOps requires Base64 encoded token (format: :token)\\n2025-12-05T00:07:03.9757717Z -AZURE_DEVOPS_TOKEN = base64.b64encode(f\\\":{AZURE_DEVOPS_PAT}\\\".encode()).decode() if AZURE_DEVOPS_PAT else None\\n2025-12-05T00:07:03.9758530Z +AZURE_DEVOPS_TOKEN = (\\n2025-12-05T00:07:03.9758970Z +    base64.b64encode(f\\\":{AZURE_DEVOPS_PAT}\\\".encode()).decode()\\n2025-12-05T00:07:03.9759502Z +    if AZURE_DEVOPS_PAT\\n2025-12-05T00:07:03.9759831Z +    else None\\n2025-12-05T00:07:03.9760122Z +)\\n2025-12-05T00:07:03.9760360Z +\\n2025-12-05T00:07:03.9760609Z  \\n2025-12-05T00:07:03.9760858Z  # Graph state\\n2025-12-05T00:07:03.9761158Z  class State(TypedDict):\\n2025-12-05T00:07:03.9761553Z      channel: str  # Slack channel name or ID\\n2025-12-05T00:07:03.9762103Z      slack_messages: NotRequired[list]  # Messages from Slack\\n2025-12-05T00:07:03.9762602Z @@ -49,39 +54,42 @@\\n2025-12-05T00:07:03.9762936Z  # Helper functions for Slack API\\n2025-12-05T00:07:03.9763485Z  def get_slack_channel_id(channel_name: str) -> Optional[str]:\\n2025-12-05T00:07:03.9764052Z      \\\"\\\"\\\"Get Slack channel ID from channel name\\\"\\\"\\\"\\n2025-12-05T00:07:03.9764491Z      headers = {\\n2025-12-05T00:07:03.9765292Z          \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-05T00:07:03.9765754Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:07:03.9766252Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:07:03.9766687Z      }\\n2025-12-05T00:07:03.9767281Z      response = requests.get(\\n2025-12-05T00:07:03.9767709Z          f\\\"{SLACK_API_BASE}/conversations.list\\\",\\n2025-12-05T00:07:03.9768179Z          headers=headers,\\n2025-12-05T00:07:03.9768630Z -        params={\\\"types\\\": \\\"public_channel,private_channel\\\"}\\n2025-12-05T00:07:03.9769224Z +        params={\\\"types\\\": \\\"public_channel,private_channel\\\"},\\n2025-12-05T00:07:03.9769723Z      )\\n2025-12-05T00:07:03.9769984Z -    \\n2025-12-05T00:07:03.9770257Z +\\n2025-12-05T00:07:03.9770551Z      if response.status_code == 200:\\n2025-12-05T00:07:03.9770987Z          data = response.json()\\n2025-12-05T00:07:03.9771364Z          if data.get(\\\"ok\\\"):\\n2025-12-05T00:07:03.9771772Z              for channel in data.get(\\\"channels\\\", []):\\n2025-12-05T00:07:03.9772527Z -                if channel.get(\\\"name\\\") == channel_name or channel.get(\\\"id\\\") == channel_name:\\n2025-12-05T00:07:03.9773138Z +                if (\\n2025-12-05T00:07:03.9773515Z +                    channel.get(\\\"name\\\") == channel_name\\n2025-12-05T00:07:03.9774013Z +                    or channel.get(\\\"id\\\") == channel_name\\n2025-12-05T00:07:03.9774445Z +                ):\\n2025-12-05T00:07:03.9774789Z                      return channel.get(\\\"id\\\")\\n2025-12-05T00:07:03.9775209Z      return None\\n2025-12-05T00:07:03.9775498Z  \\n2025-12-05T00:07:03.9775750Z  \\n2025-12-05T00:07:03.9776168Z  def get_slack_messages(channel_id: str, limit: int = 100) -> list:\\n2025-12-05T00:07:03.9776755Z      \\\"\\\"\\\"Get messages from Slack channel\\\"\\\"\\\"\\n2025-12-05T00:07:03.9777374Z      headers = {\\n2025-12-05T00:07:03.9777891Z          \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-05T00:07:03.9778337Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:07:03.9778808Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:07:03.9779227Z      }\\n2025-12-05T00:07:03.9779519Z      response = requests.get(\\n2025-12-05T00:07:03.9780454Z          f\\\"{SLACK_API_BASE}/conversations.history\\\",\\n2025-12-05T00:07:03.9780988Z          headers=headers,\\n2025-12-05T00:07:03.9781411Z -        params={\\\"channel\\\": channel_id, \\\"limit\\\": limit}\\n2025-12-05T00:07:03.9782222Z +        params={\\\"channel\\\": channel_id, \\\"limit\\\": limit},\\n2025-12-05T00:07:03.9782666Z      )\\n2025-12-05T00:07:03.9782927Z -    \\n2025-12-05T00:07:03.9783216Z +\\n2025-12-05T00:07:03.9783588Z      if response.status_code == 200:\\n2025-12-05T00:07:03.9784034Z          data = response.json()\\n2025-12-05T00:07:03.9784421Z          if data.get(\\\"ok\\\"):\\n2025-12-05T00:07:03.9784817Z              return data.get(\\\"messages\\\", [])\\n2025-12-05T00:07:03.9785221Z      return []\\n2025-12-05T00:07:03.9785525Z @@ -90,165 +98,158 @@\\n2025-12-05T00:07:03.9785884Z  # Helper functions for Azure DevOps API\\n2025-12-05T00:07:03.9786584Z  def trigger_azure_pipeline(pipeline_id: int, branch: str = \\\"main\\\") -> Optional[dict]:\\n2025-12-05T00:07:03.9787503Z      \\\"\\\"\\\"Trigger Azure DevOps pipeline\\\"\\\"\\\"\\n2025-12-05T00:07:03.9787963Z      if not AZURE_DEVOPS_TOKEN:\\n2025-12-05T00:07:03.9788350Z          return None\\n2025-12-05T00:07:03.9788649Z -    \\n2025-12-05T00:07:03.9788906Z +\\n2025-12-05T00:07:03.9789170Z      headers = {\\n2025-12-05T00:07:03.9789579Z          \\\"Authorization\\\": f\\\"Basic {AZURE_DEVOPS_TOKEN}\\\",\\n2025-12-05T00:07:03.9790094Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:07:03.9790522Z -    }\\n2025-12-05T00:07:03.9790787Z -    \\n2025-12-05T00:07:03.9791119Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:07:03.9791538Z +    }\\n2025-12-05T00:07:03.9791786Z +\\n2025-12-05T00:07:03.9792043Z      url = (\\n2025-12-05T00:07:03.9792517Z          f\\\"https://dev.azure.com/{AZURE_DEVOPS_ORG}/{AZURE_DEVOPS_PROJECT}/\\\"\\n2025-12-05T00:07:03.9793228Z          f\\\"_apis/pipelines/{pipeline_id}/runs?api-version=7.1\\\"\\n2025-12-05T00:07:03.9793711Z      )\\n2025-12-05T00:07:03.9793972Z -    \\n2025-12-05T00:07:03.9794225Z +\\n2025-12-05T00:07:03.9794490Z      payload = {\\n2025-12-05T00:07:03.9794804Z -        \\\"resources\\\": {\\n2025-12-05T00:07:03.9795175Z -            \\\"repositories\\\": {\\n2025-12-05T00:07:03.9795557Z -                \\\"self\\\": {\\n2025-12-05T00:07:03.9795939Z -                    \\\"refName\\\": f\\\"refs/heads/{branch}\\\"\\n2025-12-05T00:07:03.9796391Z -                }\\n2025-12-05T00:07:03.9796686Z -            }\\n2025-12-05T00:07:03.9797154Z -        }\\n2025-12-05T00:07:03.9797426Z -    }\\n2025-12-05T00:07:03.9797694Z -    \\n2025-12-05T00:07:03.9798171Z +        \\\"resources\\\": {\\\"repositories\\\": {\\\"self\\\": {\\\"refName\\\": f\\\"refs/heads/{branch}\\\"}}}\\n2025-12-05T00:07:03.9798776Z +    }\\n2025-12-05T00:07:03.9799031Z +\\n2025-12-05T00:07:03.9799291Z      try:\\n2025-12-05T00:07:03.9799738Z          response = requests.post(url, headers=headers, json=payload)\\n2025-12-05T00:07:03.9800276Z -        \\n2025-12-05T00:07:03.9800546Z +\\n2025-12-05T00:07:03.9800846Z          if response.status_code == 200:\\n2025-12-05T00:07:03.9801305Z              return response.json()\\n2025-12-05T00:07:03.9801687Z          else:\\n2025-12-05T00:07:03.9802273Z -            print(f\\\"Error triggering pipeline: {response.status_code} - {response.text}\\\")\\n2025-12-05T00:07:03.9802914Z +            print(\\n2025-12-05T00:07:03.9803439Z +                f\\\"Error triggering pipeline: {response.status_code} - {response.text}\\\"\\n2025-12-05T00:07:03.9804054Z +            )\\n2025-12-05T00:07:03.9804350Z              return None\\n2025-12-05T00:07:03.9804715Z      except Exception as e:\\n2025-12-05T00:07:03.9805169Z          print(f\\\"Exception triggering pipeline: {str(e)}\\\")\\n2025-12-05T00:07:03.9805658Z          return None\\n2025-12-05T00:07:03.9805959Z  \\n2025-12-05T00:07:03.9806210Z  \\n2025-12-05T00:07:03.9806679Z  def get_pipeline_status(pipeline_id: int, run_id: int) -> Optional[dict]:\\n2025-12-05T00:07:03.9807531Z      \\\"\\\"\\\"Get Azure DevOps pipeline run status\\\"\\\"\\\"\\n2025-12-05T00:07:03.9808002Z      if not AZURE_DEVOPS_TOKEN:\\n2025-12-05T00:07:03.9808387Z          return None\\n2025-12-05T00:07:03.9808693Z -    \\n2025-12-05T00:07:03.9808944Z +\\n2025-12-05T00:07:03.9809204Z      headers = {\\n2025-12-05T00:07:03.9809954Z          \\\"Authorization\\\": f\\\"Basic {AZURE_DEVOPS_TOKEN}\\\",\\n2025-12-05T00:07:03.9810514Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:07:03.9810939Z -    }\\n2025-12-05T00:07:03.9811442Z -    \\n2025-12-05T00:07:03.9811772Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:07:03.9812195Z +    }\\n2025-12-05T00:07:03.9812443Z +\\n2025-12-05T00:07:03.9812698Z      url = (\\n2025-12-05T00:07:03.9813175Z          f\\\"https://dev.azure.com/{AZURE_DEVOPS_ORG}/{AZURE_DEVOPS_PROJECT}/\\\"\\n2025-12-05T00:07:03.9813927Z          f\\\"_apis/pipelines/{pipeline_id}/runs/{run_id}?api-version=7.1\\\"\\n2025-12-05T00:07:03.9814487Z      )\\n2025-12-05T00:07:03.9814740Z -    \\n2025-12-05T00:07:03.9815000Z +\\n2025-12-05T00:07:03.9815240Z      try:\\n2025-12-05T00:07:03.9815600Z          response = requests.get(url, headers=headers)\\n2025-12-05T00:07:03.9816050Z -        \\n2025-12-05T00:07:03.9816320Z +\\n2025-12-05T00:07:03.9816620Z          if response.status_code == 200:\\n2025-12-05T00:07:03.9817313Z              return response.json()\\n2025-12-05T00:07:03.9817715Z          else:\\n2025-12-05T00:07:03.9818309Z -            print(f\\\"Error getting pipeline status: {response.status_code} - {response.text}\\\")\\n2025-12-05T00:07:03.9818991Z +            print(\\n2025-12-05T00:07:03.9819537Z +                f\\\"Error getting pipeline status: {response.status_code} - {response.text}\\\"\\n2025-12-05T00:07:03.9820174Z +            )\\n2025-12-05T00:07:03.9820485Z              return None\\n2025-12-05T00:07:03.9820864Z      except Exception as e:\\n2025-12-05T00:07:03.9821338Z          print(f\\\"Exception getting pipeline status: {str(e)}\\\")\\n2025-12-05T00:07:03.9821914Z          return None\\n2025-12-05T00:07:03.9822241Z  \\n2025-12-05T00:07:03.9822490Z  \\n2025-12-05T00:07:03.9822753Z  # Nodes\\n2025-12-05T00:07:03.9823086Z  def consult_slack_messages(state: State):\\n2025-12-05T00:07:03.9823657Z      \\\"\\\"\\\"Node 1: Consult Slack messages from a specific channel\\\"\\\"\\\"\\n2025-12-05T00:07:03.9824186Z      channel = state[\\\"channel\\\"]\\n2025-12-05T00:07:03.9824545Z -    \\n2025-12-05T00:07:03.9824796Z +\\n2025-12-05T00:07:03.9825049Z      try:\\n2025-12-05T00:07:03.9825344Z          # Get channel ID\\n2025-12-05T00:07:03.9825751Z          channel_id = get_slack_channel_id(channel)\\n2025-12-05T00:07:03.9826221Z          if not channel_id:\\n2025-12-05T00:07:03.9826564Z -            return {\\n2025-12-05T00:07:03.9827192Z -                \\\"error\\\": f\\\"Channel '{channel}' not found or not accessible\\\"\\n2025-12-05T00:07:03.9827717Z -            }\\n2025-12-05T00:07:03.9828011Z -        \\n2025-12-05T00:07:03.9828459Z +            return {\\\"error\\\": f\\\"Channel '{channel}' not found or not accessible\\\"}\\n2025-12-05T00:07:03.9829010Z +\\n2025-12-05T00:07:03.9829275Z          # Get messages\\n2025-12-05T00:07:03.9829669Z          messages = get_slack_messages(channel_id)\\n2025-12-05T00:07:03.9830109Z -        \\n2025-12-05T00:07:03.9830382Z -        return {\\n2025-12-05T00:07:03.9830731Z -            \\\"slack_messages\\\": messages\\n2025-12-05T00:07:03.9831132Z -        }\\n2025-12-05T00:07:03.9831404Z +\\n2025-12-05T00:07:03.9831700Z +        return {\\\"slack_messages\\\": messages}\\n2025-12-05T00:07:03.9832165Z      except Exception as e:\\n2025-12-05T00:07:03.9832515Z -        return {\\n2025-12-05T00:07:03.9832913Z -            \\\"error\\\": f\\\"Error fetching Slack messages: {str(e)}\\\"\\n2025-12-05T00:07:03.9833339Z -        }\\n2025-12-05T00:07:03.9833670Z +        return {\\\"error\\\": f\\\"Error fetching Slack messages: {str(e)}\\\"}\\n2025-12-05T00:07:03.9834088Z  \\n2025-12-05T00:07:03.9834288Z  \\n2025-12-05T00:07:03.9834544Z  def check_albert_message(state: State):\\n2025-12-05T00:07:03.9834983Z      \\\"\\\"\\\"Node 1a: Check for Albert H. message and evaluate with LLM\\\"\\\"\\\"\\n2025-12-05T00:07:03.9835483Z      messages = state.get(\\\"slack_messages\\\", [])\\n2025-12-05T00:07:03.9835864Z      albert_message = None\\n2025-12-05T00:07:03.9836143Z -    \\n2025-12-05T00:07:03.9836355Z +\\n2025-12-05T00:07:03.9836585Z      # Find message from Albert H.\\n2025-12-05T00:07:03.9837110Z      for message in messages:\\n2025-12-05T00:07:03.9837456Z          user_id = message.get(\\\"user\\\", \\\"\\\")\\n2025-12-05T00:07:03.9837823Z          # Get user info to check name\\n2025-12-05T00:07:03.9838407Z          try:\\n2025-12-05T00:07:03.9838669Z              headers = {\\n2025-12-05T00:07:03.9839280Z                  \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-05T00:07:03.9839929Z -                \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:07:03.9840441Z +                \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:07:03.9840893Z              }\\n2025-12-05T00:07:03.9841234Z              user_response = requests.get(\\n2025-12-05T00:07:03.9841719Z                  f\\\"{SLACK_API_BASE}/users.info\\\",\\n2025-12-05T00:07:03.9842177Z                  headers=headers,\\n2025-12-05T00:07:03.9842597Z -                params={\\\"user\\\": user_id}\\n2025-12-05T00:07:03.9843030Z +                params={\\\"user\\\": user_id},\\n2025-12-05T00:07:03.9843428Z              )\\n2025-12-05T00:07:03.9843765Z              if user_response.status_code == 200:\\n2025-12-05T00:07:03.9844251Z                  user_data = user_response.json()\\n2025-12-05T00:07:03.9844720Z                  if user_data.get(\\\"ok\\\"):\\n2025-12-05T00:07:03.9845270Z                      user_name = user_data.get(\\\"user\\\", {}).get(\\\"real_name\\\", \\\"\\\")\\n2025-12-05T00:07:03.9846037Z -                    display_name = user_data.get(\\\"user\\\", {}).get(\\\"profile\\\", {}).get(\\\"display_name\\\", \\\"\\\")\\n2025-12-05T00:07:03.9846699Z +                    display_name = (\\n2025-12-05T00:07:03.9847330Z +                        user_data.get(\\\"user\\\", {})\\n2025-12-05T00:07:03.9847788Z +                        .get(\\\"profile\\\", {})\\n2025-12-05T00:07:03.9848234Z +                        .get(\\\"display_name\\\", \\\"\\\")\\n2025-12-05T00:07:03.9848664Z +                    )\\n2025-12-05T00:07:03.9849014Z                      # Check if user is Albert H.\\n2025-12-05T00:07:03.9849566Z                      if \\\"Albert H.\\\" in user_name or \\\"Albert H.\\\" in display_name:\\n2025-12-05T00:07:03.9850146Z                          albert_message = message.get(\\\"text\\\", \\\"\\\")\\n2025-12-05T00:07:03.9850624Z                          break\\n2025-12-05T00:07:03.9850981Z          except:\\n2025-12-05T00:07:03.9851447Z              # If we can't check user name, check if user field contains albert\\n2025-12-05T00:07:03.9852150Z              # This is a fallback - in production you'd want to store user mapping\\n2025-12-05T00:07:03.9852714Z              pass\\n2025-12-05T00:07:03.9853009Z -    \\n2025-12-05T00:07:03.9853267Z +\\n2025-12-05T00:07:03.9853552Z      if not albert_message:\\n2025-12-05T00:07:03.9853898Z          return {\\n2025-12-05T00:07:03.9854222Z              \\\"albert_message\\\": \\\"\\\",\\n2025-12-05T00:07:03.9854640Z              \\\"llm_approval\\\": \\\"Rejected\\\",\\n2025-12-05T00:07:03.9855154Z -            \\\"error\\\": \\\"No message from Albert H. found in channel\\\"\\n2025-12-05T00:07:03.9855737Z +            \\\"error\\\": \\\"No message from Albert H. found in channel\\\",\\n2025-12-05T00:07:03.9856217Z          }\\n2025-12-05T00:07:03.9856486Z -    \\n2025-12-05T00:07:03.9856740Z +\\n2025-12-05T00:07:03.9857193Z      # Evaluate with LLM\\n2025-12-05T00:07:03.9857527Z      try:\\n2025-12-05T00:07:03.9857813Z          prompt = (\\n2025-12-05T00:07:03.9858265Z              f\\\"Review the following Slack message from Albert H.:\\\\n\\\\n\\\"\\n2025-12-05T00:07:03.9858819Z              f\\\"{albert_message}\\\\n\\\\n\\\"\\n2025-12-05T00:07:03.9859445Z              f\\\"Determine if we should proceed with triggering the Azure DevOps pipeline. \\\"\\n2025-12-05T00:07:03.9860301Z              f\\\"Respond with 'Approved' if we should proceed, or 'Rejected' if we should not. \\\"\\n2025-12-05T00:07:03.9861000Z              f\\\"Only respond with one word: 'Approved' or 'Rejected'.\\\"\\n2025-12-05T00:07:03.9861480Z          )\\n2025-12-05T00:07:03.9861752Z -        \\n2025-12-05T00:07:03.9862003Z +\\n2025-12-05T00:07:03.9862279Z          msg = llm.invoke(prompt)\\n2025-12-05T00:07:03.9862692Z          approval = msg.content.strip()\\n2025-12-05T00:07:03.9863080Z -        \\n2025-12-05T00:07:03.9863332Z +\\n2025-12-05T00:07:03.9863649Z          # Ensure it's either Approved or Rejected\\n2025-12-05T00:07:03.9864118Z          if \\\"Approved\\\" in approval:\\n2025-12-05T00:07:03.9864529Z              approval = \\\"Approved\\\"\\n2025-12-05T00:07:03.9864901Z          else:\\n2025-12-05T00:07:03.9865551Z              approval = \\\"Rejected\\\"\\n2025-12-05T00:07:03.9865949Z -        \\n2025-12-05T00:07:03.9866226Z -        return {\\n2025-12-05T00:07:03.9866569Z -            \\\"albert_message\\\": albert_message,\\n2025-12-05T00:07:03.9867502Z -            \\\"llm_approval\\\": approval\\n2025-12-05T00:07:03.9867901Z -        }\\n2025-12-05T00:07:03.9868162Z +\\n2025-12-05T00:07:03.9868608Z +        return {\\\"albert_message\\\": albert_message, \\\"llm_approval\\\": approval}\\n2025-12-05T00:07:03.9869198Z      except Exception as e:\\n2025-12-05T00:07:03.9869560Z          return {\\n2025-12-05T00:07:03.9869917Z              \\\"albert_message\\\": albert_message,\\n2025-12-05T00:07:03.9870387Z              \\\"llm_approval\\\": \\\"Rejected\\\",\\n2025-12-05T00:07:03.9870927Z -            \\\"error\\\": f\\\"Error evaluating message with LLM: {str(e)}\\\"\\n2025-12-05T00:07:03.9871543Z +            \\\"error\\\": f\\\"Error evaluating message with LLM: {str(e)}\\\",\\n2025-12-05T00:07:03.9872102Z          }\\n2025-12-05T00:07:03.9872370Z  \\n2025-12-05T00:07:03.9872622Z  \\n2025-12-05T00:07:03.9872925Z  def validate_approval(state: State):\\n2025-12-05T00:07:03.9873394Z      \\\"\\\"\\\"Gate function: Validate LLM approval\\\"\\\"\\\"\\n2025-12-05T00:07:03.9873828Z @@ -260,17 +261,15 @@\\n2025-12-05T00:07:03.9874147Z  \\n2025-12-05T00:07:03.9874459Z  def trigger_pipeline(state: State):\\n2025-12-05T00:07:03.9874917Z      \\\"\\\"\\\"Node 2: Trigger Azure DevOps pipeline\\\"\\\"\\\"\\n2025-12-05T00:07:03.9875354Z      try:\\n2025-12-05T00:07:03.9875674Z          if not AZURE_DEVOPS_PIPELINE_ID:\\n2025-12-05T00:07:03.9876115Z -            return {\\n2025-12-05T00:07:03.9876548Z -                \\\"error\\\": \\\"Azure DevOps pipeline ID not configured\\\"\\n2025-12-05T00:07:03.9877214Z -            }\\n2025-12-05T00:07:03.9877511Z -        \\n2025-12-05T00:07:03.9877930Z +            return {\\\"error\\\": \\\"Azure DevOps pipeline ID not configured\\\"}\\n2025-12-05T00:07:03.9878458Z +\\n2025-12-05T00:07:03.9878796Z          pipeline_id = int(AZURE_DEVOPS_PIPELINE_ID)\\n2025-12-05T00:07:03.9879338Z          result = trigger_azure_pipeline(pipeline_id)\\n2025-12-05T00:07:03.9879780Z -        \\n2025-12-05T00:07:03.9880055Z +\\n2025-12-05T00:07:03.9880307Z          if result:\\n2025-12-05T00:07:03.9880670Z              # Extract build/run ID from response\\n2025-12-05T00:07:03.9881129Z              build_id = result.get(\\\"id\\\")\\n2025-12-05T00:07:03.9881556Z              if not build_id:\\n2025-12-05T00:07:03.9881946Z                  # Try to extract from _links\\n2025-12-05T00:07:03.9882373Z @@ -280,95 +279,97 @@\\n2025-12-05T00:07:03.9882716Z                      parts = href.split(\\\"/\\\")\\n2025-12-05T00:07:03.9883183Z                      for i, part in enumerate(parts):\\n2025-12-05T00:07:03.9883702Z                          if part == \\\"runs\\\" and i + 1 < len(parts):\\n2025-12-05T00:07:03.9884200Z                              build_id = parts[i + 1]\\n2025-12-05T00:07:03.9884632Z                              break\\n2025-12-05T00:07:03.9884985Z -            \\n2025-12-05T00:07:03.9885264Z +\\n2025-12-05T00:07:03.9885521Z              if build_id:\\n2025-12-05T00:07:03.9885863Z                  return {\\n2025-12-05T00:07:03.9886257Z                      \\\"pipeline_id\\\": pipeline_id,\\n2025-12-05T00:07:03.9887076Z -                    \\\"build_id\\\": int(build_id) if isinstance(build_id, (str, int)) else pipeline_id,\\n2025-12-05T00:07:03.9887782Z -                    \\\"build_status\\\": \\\"InProgress\\\"\\n2025-12-05T00:07:03.9888248Z +                    \\\"build_id\\\": int(build_id)\\n2025-12-05T00:07:03.9888725Z +                    if isinstance(build_id, (str, int))\\n2025-12-05T00:07:03.9889194Z +                    else pipeline_id,\\n2025-12-05T00:07:03.9889643Z +                    \\\"build_status\\\": \\\"InProgress\\\",\\n2025-12-05T00:07:03.9890068Z                  }\\n2025-12-05T00:07:03.9890360Z              else:\\n2025-12-05T00:07:03.9890662Z                  return {\\n2025-12-05T00:07:03.9891184Z                      \\\"error\\\": \\\"Failed to extract build ID from pipeline trigger response\\\",\\n2025-12-05T00:07:03.9891813Z -                    \\\"pipeline_id\\\": pipeline_id\\n2025-12-05T00:07:03.9892289Z +                    \\\"pipeline_id\\\": pipeline_id,\\n2025-12-05T00:07:03.9892969Z                  }\\n2025-12-05T00:07:03.9893284Z          else:\\n2025-12-05T00:07:03.9893581Z              return {\\n2025-12-05T00:07:03.9894111Z                  \\\"error\\\": \\\"Failed to trigger Azure DevOps pipeline - check logs for details\\\"\\n2025-12-05T00:07:03.9894927Z              }\\n2025-12-05T00:07:03.9895249Z      except ValueError as e:\\n2025-12-05T00:07:03.9895609Z -        return {\\n2025-12-05T00:07:03.9896007Z -            \\\"error\\\": f\\\"Invalid pipeline ID format: {str(e)}\\\"\\n2025-12-05T00:07:03.9896481Z -        }\\n2025-12-05T00:07:03.9897067Z +        return {\\\"error\\\": f\\\"Invalid pipeline ID format: {str(e)}\\\"}\\n2025-12-05T00:07:03.9897616Z      except Exception as e:\\n2025-12-05T00:07:03.9897977Z -        return {\\n2025-12-05T00:07:03.9898373Z -            \\\"error\\\": f\\\"Error triggering pipeline: {str(e)}\\\"\\n2025-12-05T00:07:03.9898849Z -        }\\n2025-12-05T00:07:03.9899259Z +        return {\\\"error\\\": f\\\"Error triggering pipeline: {str(e)}\\\"}\\n2025-12-05T00:07:03.9899754Z  \\n2025-12-05T00:07:03.9900002Z  \\n2025-12-05T00:07:03.9900321Z  def check_pipeline_status(state: State):\\n2025-12-05T00:07:03.9900821Z      \\\"\\\"\\\"Node 2a: Check pipeline status with polling\\\"\\\"\\\"\\n2025-12-05T00:07:03.9901322Z      pipeline_id = state.get(\\\"pipeline_id\\\")\\n2025-12-05T00:07:03.9901940Z      build_id = state.get(\\\"build_id\\\")  # This is the run_id from pipeline trigger\\n2025-12-05T00:07:03.9902505Z -    \\n2025-12-05T00:07:03.9902762Z +\\n2025-12-05T00:07:03.9903060Z      if not pipeline_id or not build_id:\\n2025-12-05T00:07:03.9903459Z -        return {\\n2025-12-05T00:07:03.9903851Z -            \\\"error\\\": \\\"No pipeline ID or build ID available\\\"\\n2025-12-05T00:07:03.9904301Z -        }\\n2025-12-05T00:07:03.9904565Z -    \\n2025-12-05T00:07:03.9904938Z +        return {\\\"error\\\": \\\"No pipeline ID or build ID available\\\"}\\n2025-12-05T00:07:03.9905419Z +\\n2025-12-05T00:07:03.9905710Z      # Wait 3 seconds before first check\\n2025-12-05T00:07:03.9906237Z      print(\\\"Waiting 3 seconds before first status check...\\\")\\n2025-12-05T00:07:03.9906729Z      time.sleep(3)\\n2025-12-05T00:07:03.9907240Z -    \\n2025-12-05T00:07:03.9907514Z +\\n2025-12-05T00:07:03.9907980Z      max_attempts = 100  # Maximum polling attempts (5 minutes with 3s intervals)\\n2025-12-05T00:07:03.9908600Z      attempt = 0\\n2025-12-05T00:07:03.9908891Z -    \\n2025-12-05T00:07:03.9909150Z +\\n2025-12-05T00:07:03.9909651Z      print(f\\\"Starting status polling for pipeline {pipeline_id}, run {build_id}...\\\")\\n2025-12-05T00:07:03.9910282Z -    \\n2025-12-05T00:07:03.9910537Z +\\n2025-12-05T00:07:03.9910830Z      while attempt < max_attempts:\\n2025-12-05T00:07:03.9911209Z          try:\\n2025-12-05T00:07:03.9911603Z              run_info = get_pipeline_status(pipeline_id, build_id)\\n2025-12-05T00:07:03.9912094Z -            \\n2025-12-05T00:07:03.9912363Z +\\n2025-12-05T00:07:03.9912627Z              if run_info:\\n2025-12-05T00:07:03.9913040Z                  state_value = run_info.get(\\\"state\\\", \\\"\\\").lower()\\n2025-12-05T00:07:03.9913771Z -                result_value = run_info.get(\\\"result\\\", \\\"\\\").lower() if run_info.get(\\\"result\\\") else None\\n2025-12-05T00:07:03.9914421Z -                \\n2025-12-05T00:07:03.9914757Z +                result_value = (\\n2025-12-05T00:07:03.9915177Z +                    run_info.get(\\\"result\\\", \\\"\\\").lower()\\n2025-12-05T00:07:03.9915661Z +                    if run_info.get(\\\"result\\\")\\n2025-12-05T00:07:03.9916096Z +                    else None\\n2025-12-05T00:07:03.9916440Z +                )\\n2025-12-05T00:07:03.9916728Z +\\n2025-12-05T00:07:03.9917177Z                  # Check if completed\\n2025-12-05T00:07:03.9917628Z                  if state_value == \\\"completed\\\":\\n2025-12-05T00:07:03.9918076Z                      if result_value:\\n2025-12-05T00:07:03.9918605Z                          status_msg = f\\\"Completed - {result_value.capitalize()}\\\"\\n2025-12-05T00:07:03.9919134Z                      else:\\n2025-12-05T00:07:03.9919521Z                          status_msg = \\\"Completed\\\"\\n2025-12-05T00:07:03.9920151Z -                    print(f\\\"Pipeline run {build_id} completed with status: {status_msg}\\\")\\n2025-12-05T00:07:03.9920755Z -                    return {\\n2025-12-05T00:07:03.9921406Z -                        \\\"build_status\\\": status_msg\\n2025-12-05T00:07:03.9921861Z -                    }\\n2025-12-05T00:07:03.9922397Z +                    print(\\n2025-12-05T00:07:03.9922907Z +                        f\\\"Pipeline run {build_id} completed with status: {status_msg}\\\"\\n2025-12-05T00:07:03.9923462Z +                    )\\n2025-12-05T00:07:03.9923832Z +                    return {\\\"build_status\\\": status_msg}\\n2025-12-05T00:07:03.9924283Z                  else:\\n2025-12-05T00:07:03.9924650Z                      # Still in progress, log and wait\\n2025-12-05T00:07:03.9925194Z                      current_status = run_info.get(\\\"state\\\", \\\"Unknown\\\")\\n2025-12-05T00:07:03.9926017Z -                    print(f\\\"Pipeline run {build_id} status: {current_status} (attempt {attempt + 1}/{max_attempts})\\\")\\n2025-12-05T00:07:03.9926752Z +                    print(\\n2025-12-05T00:07:03.9927575Z +                        f\\\"Pipeline run {build_id} status: {current_status} (attempt {attempt + 1}/{max_attempts})\\\"\\n2025-12-05T00:07:03.9928264Z +                    )\\n2025-12-05T00:07:03.9928602Z                      time.sleep(3)\\n2025-12-05T00:07:03.9929005Z                      attempt += 1\\n2025-12-05T00:07:03.9929380Z              else:\\n2025-12-05T00:07:03.9929743Z                  # If we can't get status, wait and retry\\n2025-12-05T00:07:03.9930514Z -                print(f\\\"Unable to get status for run {build_id}, retrying... (attempt {attempt + 1}/{max_attempts})\\\")\\n2025-12-05T00:07:03.9931251Z +                print(\\n2025-12-05T00:07:03.9931874Z +                    f\\\"Unable to get status for run {build_id}, retrying... (attempt {attempt + 1}/{max_attempts})\\\"\\n2025-12-05T00:07:03.9932546Z +                )\\n2025-12-05T00:07:03.9932872Z                  time.sleep(3)\\n2025-12-05T00:07:03.9933246Z                  attempt += 1\\n2025-12-05T00:07:03.9933601Z -                \\n2025-12-05T00:07:03.9933891Z +\\n2025-12-05T00:07:03.9934182Z          except Exception as e:\\n2025-12-05T00:07:03.9934553Z -            return {\\n2025-12-05T00:07:03.9935001Z -                \\\"error\\\": f\\\"Error checking pipeline status: {str(e)}\\\"\\n2025-12-05T00:07:03.9935493Z -            }\\n2025-12-05T00:07:03.9935789Z -    \\n2025-12-05T00:07:03.9936204Z +            return {\\\"error\\\": f\\\"Error checking pipeline status: {str(e)}\\\"}\\n2025-12-05T00:07:03.9936774Z +\\n2025-12-05T00:07:03.9937382Z      # If we exhausted attempts\\n2025-12-05T00:07:03.9937988Z      print(f\\\"Pipeline status check timed out after {max_attempts} attempts\\\")\\n2025-12-05T00:07:03.9938603Z      return {\\n2025-12-05T00:07:03.9939068Z          \\\"build_status\\\": \\\"Timeout - Status check exceeded maximum attempts\\\",\\n2025-12-05T00:07:03.9939701Z -        \\\"error\\\": \\\"Pipeline status check timed out\\\"\\n2025-12-05T00:07:03.9940219Z +        \\\"error\\\": \\\"Pipeline status check timed out\\\",\\n2025-12-05T00:07:03.9940665Z      }\\n2025-12-05T00:07:03.9940922Z  \\n2025-12-05T00:07:03.9941178Z  \\n2025-12-05T00:07:03.9941442Z  # Build workflow\\n2025-12-05T00:07:03.9941785Z  workflow = StateGraph(State)\\n2025-12-05T00:07:03.9942175Z @@ -383,14 +384,11 @@\\n2025-12-05T00:07:03.9942593Z  workflow.add_edge(START, \\\"consult_slack_messages\\\")\\n2025-12-05T00:07:03.9943260Z  workflow.add_edge(\\\"consult_slack_messages\\\", \\\"check_albert_message\\\")\\n2025-12-05T00:07:03.9943876Z  workflow.add_conditional_edges(\\n2025-12-05T00:07:03.9944300Z      \\\"check_albert_message\\\",\\n2025-12-05T00:07:03.9944673Z      validate_approval,\\n2025-12-05T00:07:03.9944996Z -    {\\n2025-12-05T00:07:03.9945310Z -        \\\"Approved\\\": \\\"trigger_pipeline\\\",\\n2025-12-05T00:07:03.9945738Z -        \\\"Rejected\\\": END\\n2025-12-05T00:07:03.9946072Z -    }\\n2025-12-05T00:07:03.9946433Z +    {\\\"Approved\\\": \\\"trigger_pipeline\\\", \\\"Rejected\\\": END},\\n2025-12-05T00:07:03.9947187Z  )\\n2025-12-05T00:07:03.9947635Z  workflow.add_edge(\\\"trigger_pipeline\\\", \\\"check_pipeline_status\\\")\\n2025-12-05T00:07:03.9948269Z  workflow.add_edge(\\\"check_pipeline_status\\\", END)\\n2025-12-05T00:07:03.9948725Z  \\n2025-12-05T00:07:03.9948987Z  # Compile\\n2025-12-05T00:07:03.9949270Z @@ -400,36 +398,35 @@\\n2025-12-05T00:07:03.9949918Z  if __name__ == \\\"__main__\\\":\\n2025-12-05T00:07:03.9950348Z      # Show workflow graph BEFORE execution\\n2025-12-05T00:07:03.9950779Z      print(\\\"=\\\" * 60)\\n2025-12-05T00:07:03.9951368Z      print(\\\"Generating workflow graph...\\\")\\n2025-12-05T00:07:03.9951799Z      print(\\\"=\\\" * 60)\\n2025-12-05T00:07:03.9952113Z -    \\n2025-12-05T00:07:03.9952372Z +\\n2025-12-05T00:07:03.9952740Z      graph_image = chain.get_graph().draw_mermaid_png()\\n2025-12-05T00:07:03.9953202Z -    \\n2025-12-05T00:07:03.9953466Z +\\n2025-12-05T00:07:03.9953750Z      # Save the graph image to file\\n2025-12-05T00:07:03.9954193Z      graph_file = \\\"workflow_graph_v2.png\\\"\\n2025-12-05T00:07:03.9954662Z      with open(graph_file, \\\"wb\\\") as f:\\n2025-12-05T00:07:03.9955093Z          f.write(graph_image)\\n2025-12-05T00:07:03.9955888Z      print(f\\\"✓ Workflow graph saved to: {graph_file}\\\")\\n2025-12-05T00:07:03.9956354Z -    \\n2025-12-05T00:07:03.9956625Z +\\n2025-12-05T00:07:03.9957094Z      # Display the graph image\\n2025-12-05T00:07:03.9957548Z      img = PILImage.open(io.BytesIO(graph_image))\\n2025-12-05T00:07:03.9958335Z      img.show()  # Abrirá la imagen con el visor predeterminado\\n2025-12-05T00:07:03.9959004Z      print(\\\"✓ Workflow graph displayed\\\")\\n2025-12-05T00:07:03.9959452Z      print(\\\"=\\\" * 60)\\n2025-12-05T00:07:03.9959852Z      print(\\\"\\\\nStarting workflow execution...\\\\n\\\")\\n2025-12-05T00:07:03.9960300Z -    \\n2025-12-05T00:07:03.9960550Z +\\n2025-12-05T00:07:03.9960906Z      # Example usage - replace with actual channel name\\n2025-12-05T00:07:03.9961446Z      state = chain.invoke({\\\"channel\\\": \\\"general\\\"})\\n2025-12-05T00:07:03.9961877Z -    \\n2025-12-05T00:07:03.9962125Z +\\n2025-12-05T00:07:03.9962462Z      print(\\\"\\\\n=== Workflow Execution Result ===\\\\n\\\")\\n2025-12-05T00:07:03.9962956Z      print(f\\\"Channel: {state.get('channel')}\\\")\\n2025-12-05T00:07:03.9963520Z      print(f\\\"Messages found: {len(state.get('slack_messages', []))}\\\")\\n2025-12-05T00:07:03.9964214Z      print(f\\\"Albert H. message: {state.get('albert_message', 'Not found')}\\\")\\n2025-12-05T00:07:03.9964891Z      print(f\\\"LLM Approval: {state.get('llm_approval', 'N/A')}\\\")\\n2025-12-05T00:07:03.9965498Z      print(f\\\"Pipeline ID: {state.get('pipeline_id', 'N/A')}\\\")\\n2025-12-05T00:07:03.9966055Z      print(f\\\"Build ID: {state.get('build_id', 'N/A')}\\\")\\n2025-12-05T00:07:03.9966621Z      print(f\\\"Build Status: {state.get('build_status', 'N/A')}\\\")\\n2025-12-05T00:07:03.9967271Z -    \\n2025-12-05T00:07:03.9967556Z -    if state.get('error'):\\n2025-12-05T00:07:03.9967879Z +\\n2025-12-05T00:07:03.9968147Z +    if state.get(\\\"error\\\"):\\n2025-12-05T00:07:03.9968535Z          print(f\\\"Error: {state.get('error')}\\\")\\n2025-12-05T00:07:03.9968935Z -\\n2025-12-05T00:07:03.9987325Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\t2025-12-05 00:06:53.709885+00:00\\n2025-12-05T00:07:03.9989196Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\t2025-12-05 00:07:03.997244+00:00\\n2025-12-05T00:07:03.9992137Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\n2025-12-05T00:07:03.9993067Z @@ -28,10 +28,11 @@\\n2025-12-05T00:07:03.9993966Z  app.mount(\\\"/static\\\", StaticFiles(directory=STATIC_DIR), name=\\\"static\\\")\\n2025-12-05T00:07:04.0001649Z  \\n2025-12-05T00:07:04.0001964Z  # In-memory database\\n2025-12-05T00:07:04.0002341Z  posts_db = []\\n2025-12-05T00:07:04.0002648Z  replies_db = []\\n2025-12-05T00:07:04.0002947Z +\\n2025-12-05T00:07:04.0003343Z  \\n2025-12-05T00:07:04.0003642Z  # Initialize with sample data\\n2025-12-05T00:07:04.0004030Z  def init_sample_data():\\n2025-12-05T00:07:04.0004427Z      \\\"\\\"\\\"Initialize with sample post data\\\"\\\"\\\"\\n2025-12-05T00:07:04.0005050Z      if not posts_db:  # Only add if database is empty\\n2025-12-05T00:07:04.0005522Z @@ -39,25 +40,26 @@\\n2025-12-05T00:07:04.0007074Z              \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:07:04.0007982Z              \\\"title\\\": \\\"M190.0.0 Google Vertex AI Release\\\",\\n2025-12-05T00:07:04.0008458Z              \\\"user\\\": \\\"Cristina M.\\\",\\n2025-12-05T00:07:04.0009141Z              \\\"role\\\": \\\"Program Manager\\\",\\n2025-12-05T00:07:04.0010069Z              \\\"message\\\": \\\"Hello everyone, this is the deployment plan to start today with it. Please check the component ID here: vertex-ai-re-agent.\\\",\\n2025-12-05T00:07:04.0011330Z -            \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:07:04.0012083Z +            \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:07:04.0012656Z          }\\n2025-12-05T00:07:04.0012989Z          posts_db.append(sample_post)\\n2025-12-05T00:07:04.0013380Z -        \\n2025-12-05T00:07:04.0013653Z +\\n2025-12-05T00:07:04.0015065Z          # Add sample reply to the post\\n2025-12-05T00:07:04.0015525Z          sample_reply = {\\n2025-12-05T00:07:04.0015898Z              \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:07:04.0016350Z              \\\"post_id\\\": sample_post[\\\"id\\\"],\\n2025-12-05T00:07:04.0016782Z              \\\"user\\\": \\\"Alexa A.\\\",\\n2025-12-05T00:07:04.0017460Z              \\\"role\\\": \\\"SCRUM Master\\\",\\n2025-12-05T00:07:04.0018234Z              \\\"message\\\": \\\"M190.0.0 GVA validated.\\\\n\\\\nThere is no pending SC tickets.\\\\n\\\\nPlease start with the release.\\\",\\n2025-12-05T00:07:04.0019047Z -            \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:07:04.0019642Z +            \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:07:04.0020300Z          }\\n2025-12-05T00:07:04.0020634Z          replies_db.append(sample_reply)\\n2025-12-05T00:07:04.0021113Z  \\n2025-12-05T00:07:04.0025223Z +\\n2025-12-05T00:07:04.0025535Z  # Initialize sample data on startup\\n2025-12-05T00:07:04.0025922Z  init_sample_data()\\n2025-12-05T00:07:04.0026186Z  \\n2025-12-05T00:07:04.0026406Z  \\n2025-12-05T00:07:04.0026611Z  # Models\\n2025-12-05T00:07:04.0027056Z @@ -80,10 +82,11 @@\\n2025-12-05T00:07:04.0027323Z      message: str\\n2025-12-05T00:07:04.0027566Z  \\n2025-12-05T00:07:04.0027771Z  \\n2025-12-05T00:07:04.0028039Z  class ReplyCreateSimple(BaseModel):\\n2025-12-05T00:07:04.0028567Z      \\\"\\\"\\\"Simplified reply creation without post_id (post_id comes from URL)\\\"\\\"\\\"\\n2025-12-05T00:07:04.0029044Z +\\n2025-12-05T00:07:04.0029280Z      user: str\\n2025-12-05T00:07:04.0029536Z      role: str\\n2025-12-05T00:07:04.0029790Z      message: str\\n2025-12-05T00:07:04.0030027Z  \\n2025-12-05T00:07:04.0030245Z  \\n2025-12-05T00:07:04.0030461Z @@ -110,10 +113,11 @@\\n2025-12-05T00:07:04.0030739Z      timestamp: str\\n2025-12-05T00:07:04.0030990Z  \\n2025-12-05T00:07:04.0031200Z  \\n2025-12-05T00:07:04.0031449Z  class PostSummary(BaseModel):\\n2025-12-05T00:07:04.0031878Z      \\\"\\\"\\\"Simplified post model for list view (no replies)\\\"\\\"\\\"\\n2025-12-05T00:07:04.0032276Z +\\n2025-12-05T00:07:04.0032485Z      id: str\\n2025-12-05T00:07:04.0032772Z      title: Optional[str] = None\\n2025-12-05T00:07:04.0033094Z      message: str\\n2025-12-05T00:07:04.0033354Z  \\n2025-12-05T00:07:04.0033563Z  \\n2025-12-05T00:07:04.0033790Z @@ -139,36 +143,39 @@\\n2025-12-05T00:07:04.0034064Z  async def get_posts_full():\\n2025-12-05T00:07:04.0034457Z      \\\"\\\"\\\"Get all posts with their replies - for frontend use\\\"\\\"\\\"\\n2025-12-05T00:07:04.0034858Z      try:\\n2025-12-05T00:07:04.0035114Z          posts_with_replies = []\\n2025-12-05T00:07:04.0035441Z          for post in posts_db:\\n2025-12-05T00:07:04.0035937Z -            post_replies = [reply for reply in replies_db if reply[\\\"post_id\\\"] == post[\\\"id\\\"]]\\n2025-12-05T00:07:04.0036530Z +            post_replies = [\\n2025-12-05T00:07:04.0037317Z +                reply for reply in replies_db if reply[\\\"post_id\\\"] == post[\\\"id\\\"]\\n2025-12-05T00:07:04.0037816Z +            ]\\n2025-12-05T00:07:04.0038092Z              post_dict = {\\n2025-12-05T00:07:04.0038431Z                  \\\"id\\\": post[\\\"id\\\"],\\n2025-12-05T00:07:04.0038796Z                  \\\"title\\\": post.get(\\\"title\\\"),\\n2025-12-05T00:07:04.0039171Z                  \\\"user\\\": post[\\\"user\\\"],\\n2025-12-05T00:07:04.0039506Z                  \\\"role\\\": post[\\\"role\\\"],\\n2025-12-05T00:07:04.0039844Z                  \\\"message\\\": post[\\\"message\\\"],\\n2025-12-05T00:07:04.0040221Z                  \\\"timestamp\\\": post[\\\"timestamp\\\"],\\n2025-12-05T00:07:04.0040596Z -                \\\"replies\\\": post_replies\\n2025-12-05T00:07:04.0040975Z +                \\\"replies\\\": post_replies,\\n2025-12-05T00:07:04.0041624Z              }\\n2025-12-05T00:07:04.0041988Z              posts_with_replies.append(post_dict)\\n2025-12-05T00:07:04.0042553Z          return posts_with_replies\\n2025-12-05T00:07:04.0042913Z      except Exception as e:\\n2025-12-05T00:07:04.0043290Z          print(f\\\"Error in get_posts_full: {str(e)}\\\")\\n2025-12-05T00:07:04.0043690Z          import traceback\\n2025-12-05T00:07:04.0043987Z +\\n2025-12-05T00:07:04.0044238Z          traceback.print_exc()\\n2025-12-05T00:07:04.0044774Z          raise HTTPException(status_code=500, detail=f\\\"Internal server error: {str(e)}\\\")\\n2025-12-05T00:07:04.0045314Z  \\n2025-12-05T00:07:04.0045533Z  \\n2025-12-05T00:07:04.0045854Z  @app.get(\\\"/api/posts/{post_id}\\\", response_model=Post)\\n2025-12-05T00:07:04.0046307Z  async def get_post(post_id: str):\\n2025-12-05T00:07:04.0046688Z      \\\"\\\"\\\"Get a specific post with its replies\\\"\\\"\\\"\\n2025-12-05T00:07:04.0047389Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:07:04.0047840Z      if not post:\\n2025-12-05T00:07:04.0048241Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:07:04.0048729Z -    \\n2025-12-05T00:07:04.0048973Z +\\n2025-12-05T00:07:04.0049405Z      post_replies = [reply for reply in replies_db if reply[\\\"post_id\\\"] == post_id]\\n2025-12-05T00:07:04.0049974Z      post_dict = post.copy()\\n2025-12-05T00:07:04.0050345Z      post_dict[\\\"replies\\\"] = post_replies\\n2025-12-05T00:07:04.0050742Z      return post_dict\\n2025-12-05T00:07:04.0051040Z  \\n2025-12-05T00:07:04.0051280Z @@ -187,11 +194,11 @@\\n2025-12-05T00:07:04.0051584Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:07:04.0051949Z          \\\"title\\\": post.title,\\n2025-12-05T00:07:04.0052285Z          \\\"user\\\": post.user,\\n2025-12-05T00:07:04.0052626Z          \\\"role\\\": post.role,\\n2025-12-05T00:07:04.0052955Z          \\\"message\\\": post.message,\\n2025-12-05T00:07:04.0053379Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:07:04.0053871Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:07:04.0054308Z      }\\n2025-12-05T00:07:04.0054602Z      posts_db.append(new_post)\\n2025-12-05T00:07:04.0054970Z      return new_post\\n2025-12-05T00:07:04.0055261Z  \\n2025-12-05T00:07:04.0055510Z  \\n2025-12-05T00:07:04.0055753Z @@ -199,11 +206,11 @@\\n2025-12-05T00:07:04.0056186Z  async def update_post(post_id: str, post_update: PostUpdate):\\n2025-12-05T00:07:04.0056689Z      \\\"\\\"\\\"Update a post\\\"\\\"\\\"\\n2025-12-05T00:07:04.0057407Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:07:04.0057945Z      if not post:\\n2025-12-05T00:07:04.0058401Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:07:04.0058913Z -    \\n2025-12-05T00:07:04.0059171Z +\\n2025-12-05T00:07:04.0059457Z      if post_update.title is not None:\\n2025-12-05T00:07:04.0059867Z          post[\\\"title\\\"] = post_update.title\\n2025-12-05T00:07:04.0060264Z      if post_update.message is not None:\\n2025-12-05T00:07:04.0060684Z          post[\\\"message\\\"] = post_update.message\\n2025-12-05T00:07:04.0061145Z      post[\\\"timestamp\\\"] = datetime.now().isoformat()\\n2025-12-05T00:07:04.0061561Z @@ -214,11 +221,11 @@\\n2025-12-05T00:07:04.0061885Z  async def delete_post(post_id: str):\\n2025-12-05T00:07:04.0062310Z      \\\"\\\"\\\"Delete a post and all its replies\\\"\\\"\\\"\\n2025-12-05T00:07:04.0062827Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:07:04.0063276Z      if not post:\\n2025-12-05T00:07:04.0063683Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:07:04.0064141Z -    \\n2025-12-05T00:07:04.0064369Z +\\n2025-12-05T00:07:04.0064610Z      posts_db.remove(post)\\n2025-12-05T00:07:04.0064946Z      # Delete all replies for this post\\n2025-12-05T00:07:04.0065410Z      replies_db[:] = [r for r in replies_db if r[\\\"post_id\\\"] != post_id]\\n2025-12-05T00:07:04.0065933Z      return {\\\"message\\\": \\\"Post deleted successfully\\\"}\\n2025-12-05T00:07:04.0066330Z  \\n2025-12-05T00:07:04.0066552Z @@ -228,18 +235,18 @@\\n2025-12-05T00:07:04.0067215Z      \\\"\\\"\\\"Create a new reply to a post (requires post_id in body)\\\"\\\"\\\"\\n2025-12-05T00:07:04.0067946Z      # Verify post exists\\n2025-12-05T00:07:04.0068441Z      post = next((p for p in posts_db if p[\\\"id\\\"] == reply.post_id), None)\\n2025-12-05T00:07:04.0069171Z      if not post:\\n2025-12-05T00:07:04.0069606Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:07:04.0070079Z -    \\n2025-12-05T00:07:04.0070331Z +\\n2025-12-05T00:07:04.0070554Z      new_reply = {\\n2025-12-05T00:07:04.0070858Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:07:04.0071214Z          \\\"post_id\\\": reply.post_id,\\n2025-12-05T00:07:04.0071563Z          \\\"user\\\": reply.user,\\n2025-12-05T00:07:04.0071883Z          \\\"role\\\": reply.role,\\n2025-12-05T00:07:04.0072324Z          \\\"message\\\": reply.message,\\n2025-12-05T00:07:04.0072714Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:07:04.0073134Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:07:04.0073502Z      }\\n2025-12-05T00:07:04.0073762Z      replies_db.append(new_reply)\\n2025-12-05T00:07:04.0074107Z      return new_reply\\n2025-12-05T00:07:04.0074383Z  \\n2025-12-05T00:07:04.0074605Z  \\n2025-12-05T00:07:04.0074837Z @@ -248,18 +255,18 @@\\n2025-12-05T00:07:04.0075347Z      \\\"\\\"\\\"Create a new reply to a post (post_id from URL, simplified body with user, role, message)\\\"\\\"\\\"\\n2025-12-05T00:07:04.0075946Z      # Verify post exists\\n2025-12-05T00:07:04.0076348Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:07:04.0077122Z      if not post:\\n2025-12-05T00:07:04.0077554Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:07:04.0078005Z -    \\n2025-12-05T00:07:04.0078243Z +\\n2025-12-05T00:07:04.0078466Z      new_reply = {\\n2025-12-05T00:07:04.0078750Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:07:04.0079079Z          \\\"post_id\\\": post_id,\\n2025-12-05T00:07:04.0079397Z          \\\"user\\\": reply.user,\\n2025-12-05T00:07:04.0079717Z          \\\"role\\\": reply.role,\\n2025-12-05T00:07:04.0080042Z          \\\"message\\\": reply.message,\\n2025-12-05T00:07:04.0080422Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:07:04.0080844Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:07:04.0081210Z      }\\n2025-12-05T00:07:04.0081472Z      replies_db.append(new_reply)\\n2025-12-05T00:07:04.0081808Z      return new_reply\\n2025-12-05T00:07:04.0082073Z  \\n2025-12-05T00:07:04.0082286Z  \\n2025-12-05T00:07:04.0082503Z @@ -267,11 +274,11 @@\\n2025-12-05T00:07:04.0082926Z  async def update_reply(reply_id: str, reply_update: ReplyUpdate):\\n2025-12-05T00:07:04.0083426Z      \\\"\\\"\\\"Update a reply\\\"\\\"\\\"\\n2025-12-05T00:07:04.0083851Z      reply = next((r for r in replies_db if r[\\\"id\\\"] == reply_id), None)\\n2025-12-05T00:07:04.0084319Z      if not reply:\\n2025-12-05T00:07:04.0084739Z          raise HTTPException(status_code=404, detail=\\\"Reply not found\\\")\\n2025-12-05T00:07:04.0085224Z -    \\n2025-12-05T00:07:04.0085455Z +\\n2025-12-05T00:07:04.0085737Z      reply[\\\"message\\\"] = reply_update.message\\n2025-12-05T00:07:04.0086195Z      reply[\\\"timestamp\\\"] = datetime.now().isoformat()\\n2025-12-05T00:07:04.0086617Z      return reply\\n2025-12-05T00:07:04.0087030Z  \\n2025-12-05T00:07:04.0087260Z  \\n2025-12-05T00:07:04.0087494Z @@ -279,13 +286,14 @@\\n2025-12-05T00:07:04.0087825Z  async def delete_reply(reply_id: str):\\n2025-12-05T00:07:04.0088222Z      \\\"\\\"\\\"Delete a reply\\\"\\\"\\\"\\n2025-12-05T00:07:04.0088639Z      reply = next((r for r in replies_db if r[\\\"id\\\"] == reply_id), None)\\n2025-12-05T00:07:04.0089094Z      if not reply:\\n2025-12-05T00:07:04.0089478Z          raise HTTPException(status_code=404, detail=\\\"Reply not found\\\")\\n2025-12-05T00:07:04.0089940Z -    \\n2025-12-05T00:07:04.0090161Z +\\n2025-12-05T00:07:04.0090414Z      replies_db.remove(reply)\\n2025-12-05T00:07:04.0090797Z      return {\\\"message\\\": \\\"Reply deleted successfully\\\"}\\n2025-12-05T00:07:04.0091190Z  \\n2025-12-05T00:07:04.0091405Z  \\n2025-12-05T00:07:04.0091648Z  if __name__ == \\\"__main__\\\":\\n2025-12-05T00:07:04.0091952Z      import uvicorn\\n2025-12-05T00:07:04.0092224Z +\\n2025-12-05T00:07:04.0092509Z      uvicorn.run(app, host=\\\"0.0.0.0\\\", port=8000)\\n2025-12-05T00:07:04.0126517Z \\n2025-12-05T00:07:04.0127651Z Oh no! 💥 💔 💥\\n2025-12-05T00:07:04.0128032Z 3 files would be reformatted.\\n2025-12-05T00:07:04.0421692Z \\n2025-12-05T00:07:04.0446091Z ##[error]Black found code formatting issues. Some files need to be reformatted.\\n2025-12-05T00:07:04.0455962Z ##[notice]Run 'black --exclude='\\\\''/(env|\\\\.git|__pycache__)/'\\\\'' .' locally to fix formatting issues.\\n2025-12-05T00:07:04.0458685Z ##[error]Process completed with exit code 1.\\n2025-12-05T00:07:04.0582046Z Post job cleanup.\\n2025-12-05T00:07:04.1605982Z [command]/usr/bin/git version\\n2025-12-05T00:07:04.1651464Z git version 2.52.0\\n2025-12-05T00:07:04.1701704Z Temporarily overriding HOME='/home/runner/work/_temp/b163f9c7-7ec4-4fd5-ae6b-11a4fd5bd6b6' before making global git config changes\\n2025-12-05T00:07:04.1704963Z Adding repository directory to the temporary git global config as a safe directory\\n2025-12-05T00:07:04.1710306Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-05T00:07:04.1762713Z [command]/usr/bin/git config --local --name-only --get-regexp core\\\\.sshCommand\\n2025-12-05T00:07:04.1803834Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'core\\\\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :\\\"\\n2025-12-05T00:07:04.2070281Z [command]/usr/bin/git config --local --name-only --get-regexp http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader\\n2025-12-05T00:07:04.2095835Z http.https://github.com/.extraheader\\n2025-12-05T00:07:04.2111957Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader\\n2025-12-05T00:07:04.2146550Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :\\\"\\n2025-12-05T00:07:04.2392610Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\\\\.gitdir:\\n2025-12-05T00:07:04.2430214Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url\\n2025-12-05T00:07:04.2811425Z Cleaning up orphan processes\\n\",\n    \"message_available\": \"true\",\n    \"deployment\": {\n      \"can_start\": \"true\",\n      \"reason\": \"M190.0.0 GVA validated.\\n\\nThere is no pending SC tickets.\\n\\nPlease start with the release.\",\n      \"component_id\": \"release_engineering_agentic_workflow\",\n      \"conversation_thread_title\": \"M190.0.0 Google Vertex AI Release\"\n    },\n    \"workflow\": {\n      \"build_id\": \"19948029580\",\n      \"status\": \"failure\",\n      \"logs_url\": \"https://api.github.com/repos/francodem/release_engineering_agentic_workflow/actions/runs/19948029580/logs\"\n    }\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        3136,
        -944
      ],
      "id": "fd8d50ad-5367-4cca-a380-cb20f7bc4a36",
      "name": "Edit Fields7"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        5504,
        -784
      ],
      "id": "4d1342e5-cf85-42a3-8271-46c112fe320d",
      "name": "Merge2"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\n  \"output\": {\n    \"ranking\": [\n      {\n        \"hypothesis_key\": \"h1\",\n        \"probability\": \"1.00\"\n      },\n      {\n        \"hypothesis_key\": \"h3\",\n        \"probability\": \"1.00\"\n      },\n      {\n        \"hypothesis_key\": \"h2\",\n        \"probability\": \"0.98\"\n      }\n    ],\n    \"winner\": {\n      \"hypothesis_key\": \"h1\",\n      \"probability\": \"1.00\",\n      \"justification\": \"Hypothesis h1 is fully supported by the provided logs. The logs explicitly show `black --check --diff` being executed, identifying \\\"3 files would be reformatted,\\\" outputting the error \\\"Black found code formatting issues. Some files need to be reformatted,\\\" and finally exiting with \\\"Process completed with exit code 1.\\\" This directly confirms all aspects of h1.\"\n    },\n    \"jira\": {\n      \"summary\": \"CI/CD Failure: Python Linting Issues Detected by Black Formatter\",\n      \"description\": \"The CI/CD pipeline failed during the linting step. The `black` code formatter, executed with `black --check --diff`, identified formatting inconsistencies in the following three Python files:\\n- `src/agent/re_agent.py`\\n- `src/agent/re_agent_v2.py`\\n- `src/emulation/teams/app.py`\\n\\nThe log output clearly indicates:\\n- \\\"3 files would be reformatted.\\\"\\n- \\\"Black found code formatting issues. Some files need to be reformatted.\\\"\\n- \\\"Process completed with exit code 1.\\\"\\n\\nThis confirms that the pipeline failed because the `black` check detected deviations from the defined code style, causing the job to terminate with a non-zero exit code. To resolve this, the identified files need to be reformatted using `black`.\"\n    }\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        5280,
        -624
      ],
      "id": "84743214-dfb6-42cd-bea6-14267ef9f3f4",
      "name": "Edit Fields8"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\n  \"output\": {\n    \"logs_content\": \"2025-12-05T00:53:24.3720108Z Current runner version: '2.329.0'\\n2025-12-05T00:53:24.3775324Z ##[group]Runner Image Provisioner\\n2025-12-05T00:53:24.3776560Z Hosted Compute Agent\\n2025-12-05T00:53:24.3786020Z Version: 20251124.448\\n2025-12-05T00:53:24.3787131Z Commit: fda5086b43ec66ade217e5fcd18146c879571177\\n2025-12-05T00:53:24.3788603Z Build Date: 2025-11-24T21:16:26Z\\n2025-12-05T00:53:24.3789703Z ##[endgroup]\\n2025-12-05T00:53:24.3790562Z ##[group]Operating System\\n2025-12-05T00:53:24.3791517Z Ubuntu\\n2025-12-05T00:53:24.3792316Z 24.04.3\\n2025-12-05T00:53:24.3793269Z LTS\\n2025-12-05T00:53:24.3793993Z ##[endgroup]\\n2025-12-05T00:53:24.3794823Z ##[group]Runner Image\\n2025-12-05T00:53:24.3795837Z Image: ubuntu-24.04\\n2025-12-05T00:53:24.3796672Z Version: 20251126.144.1\\n2025-12-05T00:53:24.3802442Z Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20251126.144/images/ubuntu/Ubuntu2404-Readme.md\\n2025-12-05T00:53:24.3805376Z Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20251126.144\\n2025-12-05T00:53:24.3807029Z ##[endgroup]\\n2025-12-05T00:53:24.3809234Z ##[group]GITHUB_TOKEN Permissions\\n2025-12-05T00:53:24.3812302Z Contents: read\\n2025-12-05T00:53:24.3813316Z Metadata: read\\n2025-12-05T00:53:24.3814095Z Packages: read\\n2025-12-05T00:53:24.3814897Z ##[endgroup]\\n2025-12-05T00:53:24.3818393Z Secret source: Actions\\n2025-12-05T00:53:24.3819987Z Prepare workflow directory\\n2025-12-05T00:53:24.4673689Z Prepare all required actions\\n2025-12-05T00:53:24.4793778Z Getting action download info\\n2025-12-05T00:53:24.9120046Z Download action repository 'actions/checkout@v4' (SHA:34e114876b0b11c390a56381ad16ebd13914f8d5)\\n2025-12-05T00:53:25.4347795Z Download action repository 'actions/setup-python@v5' (SHA:a26af69be951a213d495a4c3e4e4022e16d87065)\\n2025-12-05T00:53:25.5957083Z Complete job name: lint\\n2025-12-05T00:53:25.6705096Z ##[group]Run actions/checkout@v4\\n2025-12-05T00:53:25.6705923Z with:\\n2025-12-05T00:53:25.6706428Z   repository: francodem/release_engineering_agentic_workflow\\n2025-12-05T00:53:25.6707227Z   token: ***\\n2025-12-05T00:53:25.6708028Z   ssh-strict: true\\n2025-12-05T00:53:25.6708627Z   ssh-user: git\\n2025-12-05T00:53:25.6709242Z   persist-credentials: true\\n2025-12-05T00:53:25.6709875Z   clean: true\\n2025-12-05T00:53:25.6710272Z   sparse-checkout-cone-mode: true\\n2025-12-05T00:53:25.6710736Z   fetch-depth: 1\\n2025-12-05T00:53:25.6711129Z   fetch-tags: false\\n2025-12-05T00:53:25.6711514Z   show-progress: true\\n2025-12-05T00:53:25.6711911Z   lfs: false\\n2025-12-05T00:53:25.6712267Z   submodules: false\\n2025-12-05T00:53:25.6712665Z   set-safe-directory: true\\n2025-12-05T00:53:25.6713568Z ##[endgroup]\\n2025-12-05T00:53:25.7925490Z Syncing repository: francodem/release_engineering_agentic_workflow\\n2025-12-05T00:53:25.7928408Z ##[group]Getting Git version info\\n2025-12-05T00:53:25.7930187Z Working directory is '/home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow'\\n2025-12-05T00:53:25.7982705Z [command]/usr/bin/git version\\n2025-12-05T00:53:25.8360028Z git version 2.52.0\\n2025-12-05T00:53:25.8442044Z ##[endgroup]\\n2025-12-05T00:53:25.8451953Z Temporarily overriding HOME='/home/runner/work/_temp/ff476b20-9bde-42d9-af6e-2b1cb1dfb24a' before making global git config changes\\n2025-12-05T00:53:25.8454126Z Adding repository directory to the temporary git global config as a safe directory\\n2025-12-05T00:53:25.8474633Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-05T00:53:26.7323712Z Deleting the contents of '/home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow'\\n2025-12-05T00:53:26.7326360Z ##[group]Initializing the repository\\n2025-12-05T00:53:26.7328537Z [command]/usr/bin/git init /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-05T00:53:26.9877939Z hint: Using 'master' as the name for the initial branch. This default branch name\\n2025-12-05T00:53:26.9880078Z hint: will change to \\\"main\\\" in Git 3.0. To configure the initial branch name\\n2025-12-05T00:53:26.9882446Z hint: to use in all of your new repositories, which will suppress this warning,\\n2025-12-05T00:53:26.9884094Z hint: call:\\n2025-12-05T00:53:26.9885125Z hint:\\n2025-12-05T00:53:26.9886444Z hint: \\tgit config --global init.defaultBranch <name>\\n2025-12-05T00:53:26.9887954Z hint:\\n2025-12-05T00:53:26.9889439Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\\n2025-12-05T00:53:26.9891700Z hint: 'development'. The just-created branch can be renamed via this command:\\n2025-12-05T00:53:26.9893413Z hint:\\n2025-12-05T00:53:26.9894491Z hint: \\tgit branch -m <name>\\n2025-12-05T00:53:26.9895670Z hint:\\n2025-12-05T00:53:26.9897642Z hint: Disable this message with \\\"git config set advice.defaultBranchName false\\\"\\n2025-12-05T00:53:26.9900903Z Initialized empty Git repository in /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/.git/\\n2025-12-05T00:53:26.9906653Z [command]/usr/bin/git remote add origin https://github.com/francodem/release_engineering_agentic_workflow\\n2025-12-05T00:53:27.0203420Z ##[endgroup]\\n2025-12-05T00:53:27.0232112Z ##[group]Disabling automatic garbage collection\\n2025-12-05T00:53:27.0238437Z [command]/usr/bin/git config --local gc.auto 0\\n2025-12-05T00:53:27.0296581Z ##[endgroup]\\n2025-12-05T00:53:27.0299110Z ##[group]Setting up auth\\n2025-12-05T00:53:27.0309309Z [command]/usr/bin/git config --local --name-only --get-regexp core\\\\.sshCommand\\n2025-12-05T00:53:27.0379570Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'core\\\\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :\\\"\\n2025-12-05T00:53:27.5403509Z [command]/usr/bin/git config --local --name-only --get-regexp http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader\\n2025-12-05T00:53:27.5456932Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :\\\"\\n2025-12-05T00:53:27.5703534Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\\\\.gitdir:\\n2025-12-05T00:53:27.5771582Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url\\n2025-12-05T00:53:27.6059783Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***\\n2025-12-05T00:53:27.6242533Z ##[endgroup]\\n2025-12-05T00:53:27.6248966Z ##[group]Fetching the repository\\n2025-12-05T00:53:27.6260433Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +2161c4070034b2d4f93236804983b19c602fffb0:refs/remotes/origin/main\\n2025-12-05T00:53:28.1746768Z From https://github.com/francodem/release_engineering_agentic_workflow\\n2025-12-05T00:53:28.1748738Z  * [new ref]         2161c4070034b2d4f93236804983b19c602fffb0 -> origin/main\\n2025-12-05T00:53:28.1786018Z ##[endgroup]\\n2025-12-05T00:53:28.1788664Z ##[group]Determining the checkout info\\n2025-12-05T00:53:28.1789468Z ##[endgroup]\\n2025-12-05T00:53:28.1792990Z [command]/usr/bin/git sparse-checkout disable\\n2025-12-05T00:53:28.1840406Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig\\n2025-12-05T00:53:28.1870036Z ##[group]Checking out the ref\\n2025-12-05T00:53:28.1874196Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main\\n2025-12-05T00:53:28.1934504Z Switched to a new branch 'main'\\n2025-12-05T00:53:28.1938203Z branch 'main' set up to track 'origin/main'.\\n2025-12-05T00:53:28.1969998Z ##[endgroup]\\n2025-12-05T00:53:28.1993501Z [command]/usr/bin/git log -1 --format=%H\\n2025-12-05T00:53:28.2018883Z 2161c4070034b2d4f93236804983b19c602fffb0\\n2025-12-05T00:53:28.2258012Z ##[group]Run actions/setup-python@v5\\n2025-12-05T00:53:28.2258399Z with:\\n2025-12-05T00:53:28.2258622Z   python-version: 3.13\\n2025-12-05T00:53:28.2258867Z   cache: pip\\n2025-12-05T00:53:28.2259086Z   check-latest: false\\n2025-12-05T00:53:28.2259472Z   token: ***\\n2025-12-05T00:53:28.2259912Z   update-environment: true\\n2025-12-05T00:53:28.2260170Z   allow-prereleases: false\\n2025-12-05T00:53:28.2260416Z   freethreaded: false\\n2025-12-05T00:53:28.2260635Z ##[endgroup]\\n2025-12-05T00:53:28.4137917Z ##[group]Installed versions\\n2025-12-05T00:53:28.4295648Z Successfully set up CPython (3.13.9)\\n2025-12-05T00:53:28.4308861Z ##[endgroup]\\n2025-12-05T00:53:28.5014870Z [command]/opt/hostedtoolcache/Python/3.13.9/x64/bin/pip cache dir\\n2025-12-05T00:53:30.2615666Z /home/runner/.cache/pip\\n2025-12-05T00:53:30.4626852Z pip cache is not found\\n2025-12-05T00:53:30.4753816Z ##[group]Run pip install -r src/emulation/teams/requirements.txt\\n2025-12-05T00:53:30.4754383Z \\u001b[36;1mpip install -r src/emulation/teams/requirements.txt\\u001b[0m\\n2025-12-05T00:53:30.4794257Z shell: /usr/bin/bash -e {0}\\n2025-12-05T00:53:30.4794509Z env:\\n2025-12-05T00:53:30.4794763Z   pythonLocation: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:30.4795180Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib/pkgconfig\\n2025-12-05T00:53:30.4795605Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:30.4795946Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:30.4796295Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:30.4796632Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib\\n2025-12-05T00:53:30.4796914Z ##[endgroup]\\n2025-12-05T00:53:31.8075838Z Collecting fastapi==0.104.1 (from -r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:31.9181387Z   Downloading fastapi-0.104.1-py3-none-any.whl.metadata (24 kB)\\n2025-12-05T00:53:31.9801994Z Collecting uvicorn==0.24.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:31.9978324Z   Downloading uvicorn-0.24.0-py3-none-any.whl.metadata (6.4 kB)\\n2025-12-05T00:53:32.0303456Z Collecting jinja2==3.1.2 (from -r src/emulation/teams/requirements.txt (line 3))\\n2025-12-05T00:53:32.0474445Z   Downloading Jinja2-3.1.2-py3-none-any.whl.metadata (3.5 kB)\\n2025-12-05T00:53:32.0744972Z Collecting python-multipart==0.0.6 (from -r src/emulation/teams/requirements.txt (line 4))\\n2025-12-05T00:53:32.0920992Z   Downloading python_multipart-0.0.6-py3-none-any.whl.metadata (2.5 kB)\\n2025-12-05T00:53:32.1686614Z Collecting black==23.10.1 (from -r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:53:32.1953090Z   Downloading black-23.10.1-py3-none-any.whl.metadata (66 kB)\\n2025-12-05T00:53:32.2533329Z Collecting anyio<4.0.0,>=3.7.1 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:32.2702696Z   Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\\n2025-12-05T00:53:32.4902484Z Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:32.5090576Z   Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\\n2025-12-05T00:53:32.5656637Z Collecting starlette<0.28.0,>=0.27.0 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:32.5825729Z   Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\\n2025-12-05T00:53:32.6167872Z Collecting typing-extensions>=4.8.0 (from fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:32.6343808Z   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\\n2025-12-05T00:53:32.6711822Z Collecting click>=7.0 (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:32.6948945Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\\n2025-12-05T00:53:32.7322935Z Collecting h11>=0.8 (from uvicorn==0.24.0->uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:32.7534935Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\\n2025-12-05T00:53:32.8426418Z Collecting MarkupSafe>=2.0 (from jinja2==3.1.2->-r src/emulation/teams/requirements.txt (line 3))\\n2025-12-05T00:53:32.8681569Z   Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\\n2025-12-05T00:53:32.9054246Z Collecting mypy-extensions>=0.4.3 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:53:32.9225517Z   Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\\n2025-12-05T00:53:32.9566881Z Collecting packaging>=22.0 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:53:32.9760166Z   Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\\n2025-12-05T00:53:33.0090709Z Collecting pathspec>=0.9.0 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:53:33.0270341Z   Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\\n2025-12-05T00:53:33.0638488Z Collecting platformdirs>=2 (from black==23.10.1->-r src/emulation/teams/requirements.txt (line 5))\\n2025-12-05T00:53:33.0811558Z   Downloading platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)\\n2025-12-05T00:53:33.1385182Z Collecting httptools>=0.5.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:33.1555381Z   Downloading httptools-0.7.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\\n2025-12-05T00:53:33.1894719Z Collecting python-dotenv>=0.13 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:33.2073369Z   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\\n2025-12-05T00:53:33.2750733Z Collecting pyyaml>=5.1 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:33.2924013Z   Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\\n2025-12-05T00:53:33.3616571Z Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:33.3791426Z   Downloading uvloop-0.22.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\\n2025-12-05T00:53:33.4902366Z Collecting watchfiles>=0.13 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:33.5078769Z   Downloading watchfiles-1.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\\n2025-12-05T00:53:33.6346994Z Collecting websockets>=10.4 (from uvicorn[standard]==0.24.0->-r src/emulation/teams/requirements.txt (line 2))\\n2025-12-05T00:53:33.6534341Z   Downloading websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\\n2025-12-05T00:53:33.6830408Z Collecting idna>=2.8 (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:33.6999933Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\\n2025-12-05T00:53:33.7257205Z Collecting sniffio>=1.1 (from anyio<4.0.0,>=3.7.1->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:33.7449160Z   Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\\n2025-12-05T00:53:33.7717075Z Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:33.7891690Z   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\\n2025-12-05T00:53:34.5724300Z Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:34.5910395Z   Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\\n2025-12-05T00:53:34.6187167Z Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.104.1->-r src/emulation/teams/requirements.txt (line 1))\\n2025-12-05T00:53:34.6353703Z   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\\n2025-12-05T00:53:34.6859783Z Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\\n2025-12-05T00:53:34.7112326Z Downloading uvicorn-0.24.0-py3-none-any.whl (59 kB)\\n2025-12-05T00:53:34.7311530Z Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\\n2025-12-05T00:53:34.7587671Z Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\\n2025-12-05T00:53:34.7940322Z Downloading black-23.10.1-py3-none-any.whl (184 kB)\\n2025-12-05T00:53:34.8230398Z Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\\n2025-12-05T00:53:34.8427681Z Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\\n2025-12-05T00:53:34.8778882Z Downloading pydantic_core-2.41.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\\n2025-12-05T00:53:34.9062835Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 72.2 MB/s  0:00:00\\n2025-12-05T00:53:34.9242933Z Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\\n2025-12-05T00:53:34.9463346Z Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\\n2025-12-05T00:53:34.9653115Z Downloading click-8.3.1-py3-none-any.whl (108 kB)\\n2025-12-05T00:53:34.9845538Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)\\n2025-12-05T00:53:35.0078683Z Downloading httptools-0.7.1-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (478 kB)\\n2025-12-05T00:53:35.0288815Z Downloading idna-3.11-py3-none-any.whl (71 kB)\\n2025-12-05T00:53:35.0498461Z Downloading markupsafe-3.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\\n2025-12-05T00:53:35.0718149Z Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\\n2025-12-05T00:53:35.0904380Z Downloading packaging-25.0-py3-none-any.whl (66 kB)\\n2025-12-05T00:53:35.1136555Z Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\\n2025-12-05T00:53:35.1331760Z Downloading platformdirs-4.5.0-py3-none-any.whl (18 kB)\\n2025-12-05T00:53:35.1530870Z Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\\n2025-12-05T00:53:35.1725585Z Downloading pyyaml-6.0.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\\n2025-12-05T00:53:35.1810712Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 801.6/801.6 kB 103.9 MB/s  0:00:00\\n2025-12-05T00:53:35.1981850Z Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\\n2025-12-05T00:53:35.2168816Z Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\\n2025-12-05T00:53:35.2363258Z Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\\n2025-12-05T00:53:35.2559908Z Downloading uvloop-0.22.1-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\\n2025-12-05T00:53:35.2884845Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 137.9 MB/s  0:00:00\\n2025-12-05T00:53:35.3056680Z Downloading watchfiles-1.1.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\\n2025-12-05T00:53:35.4830516Z Downloading websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\\n2025-12-05T00:53:35.5773116Z Installing collected packages: websockets, uvloop, typing-extensions, sniffio, pyyaml, python-multipart, python-dotenv, platformdirs, pathspec, packaging, mypy-extensions, MarkupSafe, idna, httptools, h11, click, annotated-types, uvicorn, typing-inspection, pydantic-core, jinja2, black, anyio, watchfiles, starlette, pydantic, fastapi\\n2025-12-05T00:53:37.0639184Z \\n2025-12-05T00:53:37.0678693Z Successfully installed MarkupSafe-3.0.3 annotated-types-0.7.0 anyio-3.7.1 black-23.10.1 click-8.3.1 fastapi-0.104.1 h11-0.16.0 httptools-0.7.1 idna-3.11 jinja2-3.1.2 mypy-extensions-1.1.0 packaging-25.0 pathspec-0.12.1 platformdirs-4.5.0 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 python-multipart-0.0.6 pyyaml-6.0.3 sniffio-1.3.1 starlette-0.27.0 typing-extensions-4.15.0 typing-inspection-0.4.2 uvicorn-0.24.0 uvloop-0.22.1 watchfiles-1.1.1 websockets-15.0.1\\n2025-12-05T00:53:37.4484723Z ##[group]Run # black src/emulation/teams\\n2025-12-05T00:53:37.4485080Z \\u001b[36;1m# black src/emulation/teams\\u001b[0m\\n2025-12-05T00:53:37.4485610Z \\u001b[36;1mif ! black --check --diff --exclude='/(env|\\\\.git|__pycache__)/' .; then\\u001b[0m\\n2025-12-05T00:53:37.4485945Z \\u001b[36;1m  echo \\\"\\\" >&2\\u001b[0m\\n2025-12-05T00:53:37.4486312Z \\u001b[36;1m  echo \\\"::error::Black found code formatting issues. Some files need to be reformatted.\\\" >&2\\u001b[0m\\n2025-12-05T00:53:37.4486892Z \\u001b[36;1m  echo \\\"::notice::Run 'black --exclude='\\\\''/(env|\\\\.git|__pycache__)/'\\\\'' .' locally to fix formatting issues.\\\" >&2\\u001b[0m\\n2025-12-05T00:53:37.4487297Z \\u001b[36;1m  exit 1\\u001b[0m\\n2025-12-05T00:53:37.4487832Z \\u001b[36;1mfi\\u001b[0m\\n2025-12-05T00:53:37.4488074Z \\u001b[36;1mecho \\\"✓ All Python files are properly formatted!\\\"\\u001b[0m\\n2025-12-05T00:53:37.4522635Z shell: /usr/bin/bash -e {0}\\n2025-12-05T00:53:37.4522857Z env:\\n2025-12-05T00:53:37.4523095Z   pythonLocation: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:37.4523539Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib/pkgconfig\\n2025-12-05T00:53:37.4523930Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:37.4524272Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:37.4524626Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.13.9/x64\\n2025-12-05T00:53:37.4524961Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.13.9/x64/lib\\n2025-12-05T00:53:37.4525247Z ##[endgroup]\\n2025-12-05T00:53:38.3987972Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\n2025-12-05T00:53:38.3989746Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\t2025-12-05 00:53:28.190680+00:00\\n2025-12-05T00:53:38.3992904Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent.py\\t2025-12-05 00:53:38.360618+00:00\\n2025-12-05T00:53:38.3994009Z @@ -12,10 +12,11 @@\\n2025-12-05T00:53:38.3994383Z      max_tokens=2000,\\n2025-12-05T00:53:38.3994723Z      max_retries=6,\\n2025-12-05T00:53:38.3995049Z      stop=None,\\n2025-12-05T00:53:38.3995365Z      # other params...\\n2025-12-05T00:53:38.3995717Z  )\\n2025-12-05T00:53:38.3995968Z +\\n2025-12-05T00:53:38.3996220Z  \\n2025-12-05T00:53:38.3996477Z  # Graph state\\n2025-12-05T00:53:38.3996814Z  class State(TypedDict):\\n2025-12-05T00:53:38.3997162Z      topic: str\\n2025-12-05T00:53:38.3997743Z      joke: str\\n2025-12-05T00:53:38.3998037Z @@ -71,11 +72,13 @@\\n2025-12-05T00:53:38.3998442Z  workflow.add_node(\\\"polish_joke\\\", polish_joke)\\n2025-12-05T00:53:38.3998898Z  \\n2025-12-05T00:53:38.3999179Z  # Add edges to connect nodes\\n2025-12-05T00:53:38.3999611Z  workflow.add_edge(START, \\\"generate_joke\\\")\\n2025-12-05T00:53:38.4000080Z  workflow.add_conditional_edges(\\n2025-12-05T00:53:38.4000761Z -    \\\"generate_joke\\\", check_punchline, {\\\"Fail\\\": \\\"improve_joke\\\", \\\"Pass\\\": \\\"ask_for_applause\\\"}\\n2025-12-05T00:53:38.4001433Z +    \\\"generate_joke\\\",\\n2025-12-05T00:53:38.4001778Z +    check_punchline,\\n2025-12-05T00:53:38.4002194Z +    {\\\"Fail\\\": \\\"improve_joke\\\", \\\"Pass\\\": \\\"ask_for_applause\\\"},\\n2025-12-05T00:53:38.4002628Z  )\\n2025-12-05T00:53:38.4002973Z  workflow.add_edge(\\\"improve_joke\\\", \\\"polish_joke\\\")\\n2025-12-05T00:53:38.4003542Z  workflow.add_edge(\\\"polish_joke\\\", \\\"ask_for_applause\\\")\\n2025-12-05T00:53:38.4004082Z  workflow.add_edge(\\\"ask_for_applause\\\", END)\\n2025-12-05T00:53:38.4004498Z  \\n2025-12-05T00:53:38.4004762Z @@ -102,6 +105,6 @@\\n2025-12-05T00:53:38.4005089Z      print(state[\\\"final_joke\\\"])\\n2025-12-05T00:53:38.4005499Z  elif \\\"ask_for_applause\\\" in state:\\n2025-12-05T00:53:38.4005947Z      print(\\\"Ask for applause:\\\")\\n2025-12-05T00:53:38.4006424Z      print(state[\\\"ask_for_applause\\\"])\\n2025-12-05T00:53:38.4006824Z  else:\\n2025-12-05T00:53:38.4007227Z -    print(\\\"Joke failed quality gate - no punchline detected!\\\")\\n2025-12-05T00:53:38.4007951Z \\\\ No newline at end of file\\n2025-12-05T00:53:38.4008434Z +    print(\\\"Joke failed quality gate - no punchline detected!\\\")\\n2025-12-05T00:53:38.7133023Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\t2025-12-05 00:53:28.190680+00:00\\n2025-12-05T00:53:38.7135327Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\t2025-12-05 00:53:38.707019+00:00\\n2025-12-05T00:53:38.7137011Z @@ -30,11 +30,16 @@\\n2025-12-05T00:53:38.7138085Z  AZURE_DEVOPS_ORG = os.getenv(\\\"AZURE_DEVOPS_ORG\\\")\\n2025-12-05T00:53:38.7140463Z  AZURE_DEVOPS_PROJECT = os.getenv(\\\"AZURE_DEVOPS_PROJECT\\\")\\n2025-12-05T00:53:38.7148198Z  AZURE_DEVOPS_PIPELINE_ID = os.getenv(\\\"AZURE_DEVOPS_PIPELINE_ID\\\")\\n2025-12-05T00:53:38.7149155Z  \\n2025-12-05T00:53:38.7149808Z  # Azure DevOps requires Base64 encoded token (format: :token)\\n2025-12-05T00:53:38.7150912Z -AZURE_DEVOPS_TOKEN = base64.b64encode(f\\\":{AZURE_DEVOPS_PAT}\\\".encode()).decode() if AZURE_DEVOPS_PAT else None\\n2025-12-05T00:53:38.7153631Z +AZURE_DEVOPS_TOKEN = (\\n2025-12-05T00:53:38.7154138Z +    base64.b64encode(f\\\":{AZURE_DEVOPS_PAT}\\\".encode()).decode()\\n2025-12-05T00:53:38.7154697Z +    if AZURE_DEVOPS_PAT\\n2025-12-05T00:53:38.7155048Z +    else None\\n2025-12-05T00:53:38.7155394Z +)\\n2025-12-05T00:53:38.7155655Z +\\n2025-12-05T00:53:38.7155901Z  \\n2025-12-05T00:53:38.7156151Z  # Graph state\\n2025-12-05T00:53:38.7156480Z  class State(TypedDict):\\n2025-12-05T00:53:38.7156883Z      channel: str  # Slack channel name or ID\\n2025-12-05T00:53:38.7157674Z      slack_messages: NotRequired[list]  # Messages from Slack\\n2025-12-05T00:53:38.7158200Z @@ -49,39 +54,42 @@\\n2025-12-05T00:53:38.7158555Z  # Helper functions for Slack API\\n2025-12-05T00:53:38.7159119Z  def get_slack_channel_id(channel_name: str) -> Optional[str]:\\n2025-12-05T00:53:38.7159720Z      \\\"\\\"\\\"Get Slack channel ID from channel name\\\"\\\"\\\"\\n2025-12-05T00:53:38.7160138Z      headers = {\\n2025-12-05T00:53:38.7160719Z          \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-05T00:53:38.7161144Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:53:38.7161604Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:53:38.7162031Z      }\\n2025-12-05T00:53:38.7162328Z      response = requests.get(\\n2025-12-05T00:53:38.7162764Z          f\\\"{SLACK_API_BASE}/conversations.list\\\",\\n2025-12-05T00:53:38.7163239Z          headers=headers,\\n2025-12-05T00:53:38.7163668Z -        params={\\\"types\\\": \\\"public_channel,private_channel\\\"}\\n2025-12-05T00:53:38.7164250Z +        params={\\\"types\\\": \\\"public_channel,private_channel\\\"},\\n2025-12-05T00:53:38.7164716Z      )\\n2025-12-05T00:53:38.7164972Z -    \\n2025-12-05T00:53:38.7165211Z +\\n2025-12-05T00:53:38.7165489Z      if response.status_code == 200:\\n2025-12-05T00:53:38.7165901Z          data = response.json()\\n2025-12-05T00:53:38.7166262Z          if data.get(\\\"ok\\\"):\\n2025-12-05T00:53:38.7166645Z              for channel in data.get(\\\"channels\\\", []):\\n2025-12-05T00:53:38.7167269Z -                if channel.get(\\\"name\\\") == channel_name or channel.get(\\\"id\\\") == channel_name:\\n2025-12-05T00:53:38.7176645Z +                if (\\n2025-12-05T00:53:38.7177014Z +                    channel.get(\\\"name\\\") == channel_name\\n2025-12-05T00:53:38.7177709Z +                    or channel.get(\\\"id\\\") == channel_name\\n2025-12-05T00:53:38.7178135Z +                ):\\n2025-12-05T00:53:38.7178479Z                      return channel.get(\\\"id\\\")\\n2025-12-05T00:53:38.7178906Z      return None\\n2025-12-05T00:53:38.7179202Z  \\n2025-12-05T00:53:38.7179442Z  \\n2025-12-05T00:53:38.7179879Z  def get_slack_messages(channel_id: str, limit: int = 100) -> list:\\n2025-12-05T00:53:38.7180475Z      \\\"\\\"\\\"Get messages from Slack channel\\\"\\\"\\\"\\n2025-12-05T00:53:38.7180889Z      headers = {\\n2025-12-05T00:53:38.7181364Z          \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-05T00:53:38.7181801Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:53:38.7182294Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:53:38.7182708Z      }\\n2025-12-05T00:53:38.7183019Z      response = requests.get(\\n2025-12-05T00:53:38.7183461Z          f\\\"{SLACK_API_BASE}/conversations.history\\\",\\n2025-12-05T00:53:38.7183920Z          headers=headers,\\n2025-12-05T00:53:38.7184630Z -        params={\\\"channel\\\": channel_id, \\\"limit\\\": limit}\\n2025-12-05T00:53:38.7185205Z +        params={\\\"channel\\\": channel_id, \\\"limit\\\": limit},\\n2025-12-05T00:53:38.7185669Z      )\\n2025-12-05T00:53:38.7186140Z -    \\n2025-12-05T00:53:38.7186403Z +\\n2025-12-05T00:53:38.7186715Z      if response.status_code == 200:\\n2025-12-05T00:53:38.7187156Z          data = response.json()\\n2025-12-05T00:53:38.7187859Z          if data.get(\\\"ok\\\"):\\n2025-12-05T00:53:38.7188257Z              return data.get(\\\"messages\\\", [])\\n2025-12-05T00:53:38.7188679Z      return []\\n2025-12-05T00:53:38.7188974Z @@ -90,165 +98,158 @@\\n2025-12-05T00:53:38.7189347Z  # Helper functions for Azure DevOps API\\n2025-12-05T00:53:38.7190059Z  def trigger_azure_pipeline(pipeline_id: int, branch: str = \\\"main\\\") -> Optional[dict]:\\n2025-12-05T00:53:38.7190772Z      \\\"\\\"\\\"Trigger Azure DevOps pipeline\\\"\\\"\\\"\\n2025-12-05T00:53:38.7191242Z      if not AZURE_DEVOPS_TOKEN:\\n2025-12-05T00:53:38.7191613Z          return None\\n2025-12-05T00:53:38.7191921Z -    \\n2025-12-05T00:53:38.7192177Z +\\n2025-12-05T00:53:38.7192451Z      headers = {\\n2025-12-05T00:53:38.7192834Z          \\\"Authorization\\\": f\\\"Basic {AZURE_DEVOPS_TOKEN}\\\",\\n2025-12-05T00:53:38.7193361Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:53:38.7193787Z -    }\\n2025-12-05T00:53:38.7194071Z -    \\n2025-12-05T00:53:38.7194389Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:53:38.7194797Z +    }\\n2025-12-05T00:53:38.7195045Z +\\n2025-12-05T00:53:38.7195285Z      url = (\\n2025-12-05T00:53:38.7195777Z          f\\\"https://dev.azure.com/{AZURE_DEVOPS_ORG}/{AZURE_DEVOPS_PROJECT}/\\\"\\n2025-12-05T00:53:38.7196504Z          f\\\"_apis/pipelines/{pipeline_id}/runs?api-version=7.1\\\"\\n2025-12-05T00:53:38.7197051Z      )\\n2025-12-05T00:53:38.7197299Z -    \\n2025-12-05T00:53:38.7197795Z +\\n2025-12-05T00:53:38.7198055Z      payload = {\\n2025-12-05T00:53:38.7198373Z -        \\\"resources\\\": {\\n2025-12-05T00:53:38.7198722Z -            \\\"repositories\\\": {\\n2025-12-05T00:53:38.7199078Z -                \\\"self\\\": {\\n2025-12-05T00:53:38.7199458Z -                    \\\"refName\\\": f\\\"refs/heads/{branch}\\\"\\n2025-12-05T00:53:38.7199885Z -                }\\n2025-12-05T00:53:38.7200174Z -            }\\n2025-12-05T00:53:38.7200483Z -        }\\n2025-12-05T00:53:38.7200761Z -    }\\n2025-12-05T00:53:38.7201021Z -    \\n2025-12-05T00:53:38.7201514Z +        \\\"resources\\\": {\\\"repositories\\\": {\\\"self\\\": {\\\"refName\\\": f\\\"refs/heads/{branch}\\\"}}}\\n2025-12-05T00:53:38.7202109Z +    }\\n2025-12-05T00:53:38.7202377Z +\\n2025-12-05T00:53:38.7202622Z      try:\\n2025-12-05T00:53:38.7203067Z          response = requests.post(url, headers=headers, json=payload)\\n2025-12-05T00:53:38.7203618Z -        \\n2025-12-05T00:53:38.7203881Z +\\n2025-12-05T00:53:38.7204190Z          if response.status_code == 200:\\n2025-12-05T00:53:38.7204637Z              return response.json()\\n2025-12-05T00:53:38.7205016Z          else:\\n2025-12-05T00:53:38.7205568Z -            print(f\\\"Error triggering pipeline: {response.status_code} - {response.text}\\\")\\n2025-12-05T00:53:38.7206205Z +            print(\\n2025-12-05T00:53:38.7206714Z +                f\\\"Error triggering pipeline: {response.status_code} - {response.text}\\\"\\n2025-12-05T00:53:38.7207510Z +            )\\n2025-12-05T00:53:38.7207949Z              return None\\n2025-12-05T00:53:38.7208300Z      except Exception as e:\\n2025-12-05T00:53:38.7208738Z          print(f\\\"Exception triggering pipeline: {str(e)}\\\")\\n2025-12-05T00:53:38.7209218Z          return None\\n2025-12-05T00:53:38.7209522Z  \\n2025-12-05T00:53:38.7209759Z  \\n2025-12-05T00:53:38.7210238Z  def get_pipeline_status(pipeline_id: int, run_id: int) -> Optional[dict]:\\n2025-12-05T00:53:38.7210916Z      \\\"\\\"\\\"Get Azure DevOps pipeline run status\\\"\\\"\\\"\\n2025-12-05T00:53:38.7211374Z      if not AZURE_DEVOPS_TOKEN:\\n2025-12-05T00:53:38.7211739Z          return None\\n2025-12-05T00:53:38.7212033Z -    \\n2025-12-05T00:53:38.7212302Z +\\n2025-12-05T00:53:38.7212558Z      headers = {\\n2025-12-05T00:53:38.7212950Z          \\\"Authorization\\\": f\\\"Basic {AZURE_DEVOPS_TOKEN}\\\",\\n2025-12-05T00:53:38.7213462Z -        \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:53:38.7213882Z -    }\\n2025-12-05T00:53:38.7214197Z -    \\n2025-12-05T00:53:38.7214813Z +        \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:53:38.7215326Z +    }\\n2025-12-05T00:53:38.7215623Z +\\n2025-12-05T00:53:38.7216116Z      url = (\\n2025-12-05T00:53:38.7216615Z          f\\\"https://dev.azure.com/{AZURE_DEVOPS_ORG}/{AZURE_DEVOPS_PROJECT}/\\\"\\n2025-12-05T00:53:38.7217565Z          f\\\"_apis/pipelines/{pipeline_id}/runs/{run_id}?api-version=7.1\\\"\\n2025-12-05T00:53:38.7218129Z      )\\n2025-12-05T00:53:38.7218394Z -    \\n2025-12-05T00:53:38.7218662Z +\\n2025-12-05T00:53:38.7218914Z      try:\\n2025-12-05T00:53:38.7219263Z          response = requests.get(url, headers=headers)\\n2025-12-05T00:53:38.7219722Z -        \\n2025-12-05T00:53:38.7220007Z +\\n2025-12-05T00:53:38.7220310Z          if response.status_code == 200:\\n2025-12-05T00:53:38.7220779Z              return response.json()\\n2025-12-05T00:53:38.7221164Z          else:\\n2025-12-05T00:53:38.7221742Z -            print(f\\\"Error getting pipeline status: {response.status_code} - {response.text}\\\")\\n2025-12-05T00:53:38.7222412Z +            print(\\n2025-12-05T00:53:38.7222961Z +                f\\\"Error getting pipeline status: {response.status_code} - {response.text}\\\"\\n2025-12-05T00:53:38.7223597Z +            )\\n2025-12-05T00:53:38.7223889Z              return None\\n2025-12-05T00:53:38.7224246Z      except Exception as e:\\n2025-12-05T00:53:38.7224714Z          print(f\\\"Exception getting pipeline status: {str(e)}\\\")\\n2025-12-05T00:53:38.7225215Z          return None\\n2025-12-05T00:53:38.7225505Z  \\n2025-12-05T00:53:38.7225750Z  \\n2025-12-05T00:53:38.7225992Z  # Nodes\\n2025-12-05T00:53:38.7226315Z  def consult_slack_messages(state: State):\\n2025-12-05T00:53:38.7226868Z      \\\"\\\"\\\"Node 1: Consult Slack messages from a specific channel\\\"\\\"\\\"\\n2025-12-05T00:53:38.7227708Z      channel = state[\\\"channel\\\"]\\n2025-12-05T00:53:38.7228083Z -    \\n2025-12-05T00:53:38.7228326Z +\\n2025-12-05T00:53:38.7228572Z      try:\\n2025-12-05T00:53:38.7228848Z          # Get channel ID\\n2025-12-05T00:53:38.7229253Z          channel_id = get_slack_channel_id(channel)\\n2025-12-05T00:53:38.7229715Z          if not channel_id:\\n2025-12-05T00:53:38.7230069Z -            return {\\n2025-12-05T00:53:38.7230516Z -                \\\"error\\\": f\\\"Channel '{channel}' not found or not accessible\\\"\\n2025-12-05T00:53:38.7231047Z -            }\\n2025-12-05T00:53:38.7231336Z -        \\n2025-12-05T00:53:38.7231780Z +            return {\\\"error\\\": f\\\"Channel '{channel}' not found or not accessible\\\"}\\n2025-12-05T00:53:38.7232332Z +\\n2025-12-05T00:53:38.7232595Z          # Get messages\\n2025-12-05T00:53:38.7232983Z          messages = get_slack_messages(channel_id)\\n2025-12-05T00:53:38.7233408Z -        \\n2025-12-05T00:53:38.7233678Z -        return {\\n2025-12-05T00:53:38.7234003Z -            \\\"slack_messages\\\": messages\\n2025-12-05T00:53:38.7234409Z -        }\\n2025-12-05T00:53:38.7234669Z +\\n2025-12-05T00:53:38.7234972Z +        return {\\\"slack_messages\\\": messages}\\n2025-12-05T00:53:38.7235414Z      except Exception as e:\\n2025-12-05T00:53:38.7235767Z -        return {\\n2025-12-05T00:53:38.7236171Z -            \\\"error\\\": f\\\"Error fetching Slack messages: {str(e)}\\\"\\n2025-12-05T00:53:38.7236649Z -        }\\n2025-12-05T00:53:38.7237056Z +        return {\\\"error\\\": f\\\"Error fetching Slack messages: {str(e)}\\\"}\\n2025-12-05T00:53:38.7237743Z  \\n2025-12-05T00:53:38.7238011Z  \\n2025-12-05T00:53:38.7238309Z  def check_albert_message(state: State):\\n2025-12-05T00:53:38.7238867Z      \\\"\\\"\\\"Node 1a: Check for Albert H. message and evaluate with LLM\\\"\\\"\\\"\\n2025-12-05T00:53:38.7239429Z      messages = state.get(\\\"slack_messages\\\", [])\\n2025-12-05T00:53:38.7239927Z      albert_message = None\\n2025-12-05T00:53:38.7240255Z -    \\n2025-12-05T00:53:38.7240517Z +\\n2025-12-05T00:53:38.7240796Z      # Find message from Albert H.\\n2025-12-05T00:53:38.7241226Z      for message in messages:\\n2025-12-05T00:53:38.7241628Z          user_id = message.get(\\\"user\\\", \\\"\\\")\\n2025-12-05T00:53:38.7242080Z          # Get user info to check name\\n2025-12-05T00:53:38.7242470Z          try:\\n2025-12-05T00:53:38.7242772Z              headers = {\\n2025-12-05T00:53:38.7243336Z                  \\\"Authorization\\\": f\\\"***\\\",\\n2025-12-05T00:53:38.7244049Z -                \\\"Content-Type\\\": \\\"application/json\\\"\\n2025-12-05T00:53:38.7244590Z +                \\\"Content-Type\\\": \\\"application/json\\\",\\n2025-12-05T00:53:38.7245246Z              }\\n2025-12-05T00:53:38.7245584Z              user_response = requests.get(\\n2025-12-05T00:53:38.7246042Z                  f\\\"{SLACK_API_BASE}/users.info\\\",\\n2025-12-05T00:53:38.7246490Z                  headers=headers,\\n2025-12-05T00:53:38.7246902Z -                params={\\\"user\\\": user_id}\\n2025-12-05T00:53:38.7247534Z +                params={\\\"user\\\": user_id},\\n2025-12-05T00:53:38.7248106Z              )\\n2025-12-05T00:53:38.7248460Z              if user_response.status_code == 200:\\n2025-12-05T00:53:38.7248939Z                  user_data = user_response.json()\\n2025-12-05T00:53:38.7249399Z                  if user_data.get(\\\"ok\\\"):\\n2025-12-05T00:53:38.7249937Z                      user_name = user_data.get(\\\"user\\\", {}).get(\\\"real_name\\\", \\\"\\\")\\n2025-12-05T00:53:38.7250702Z -                    display_name = user_data.get(\\\"user\\\", {}).get(\\\"profile\\\", {}).get(\\\"display_name\\\", \\\"\\\")\\n2025-12-05T00:53:38.7251369Z +                    display_name = (\\n2025-12-05T00:53:38.7251804Z +                        user_data.get(\\\"user\\\", {})\\n2025-12-05T00:53:38.7252265Z +                        .get(\\\"profile\\\", {})\\n2025-12-05T00:53:38.7252706Z +                        .get(\\\"display_name\\\", \\\"\\\")\\n2025-12-05T00:53:38.7253116Z +                    )\\n2025-12-05T00:53:38.7253464Z                      # Check if user is Albert H.\\n2025-12-05T00:53:38.7253988Z                      if \\\"Albert H.\\\" in user_name or \\\"Albert H.\\\" in display_name:\\n2025-12-05T00:53:38.7254568Z                          albert_message = message.get(\\\"text\\\", \\\"\\\")\\n2025-12-05T00:53:38.7255028Z                          break\\n2025-12-05T00:53:38.7255441Z          except:\\n2025-12-05T00:53:38.7255883Z              # If we can't check user name, check if user field contains albert\\n2025-12-05T00:53:38.7256588Z              # This is a fallback - in production you'd want to store user mapping\\n2025-12-05T00:53:38.7257173Z              pass\\n2025-12-05T00:53:38.7257658Z -    \\n2025-12-05T00:53:38.7257932Z +\\n2025-12-05T00:53:38.7258211Z      if not albert_message:\\n2025-12-05T00:53:38.7258577Z          return {\\n2025-12-05T00:53:38.7258901Z              \\\"albert_message\\\": \\\"\\\",\\n2025-12-05T00:53:38.7259315Z              \\\"llm_approval\\\": \\\"Rejected\\\",\\n2025-12-05T00:53:38.7259821Z -            \\\"error\\\": \\\"No message from Albert H. found in channel\\\"\\n2025-12-05T00:53:38.7260407Z +            \\\"error\\\": \\\"No message from Albert H. found in channel\\\",\\n2025-12-05T00:53:38.7260886Z          }\\n2025-12-05T00:53:38.7261147Z -    \\n2025-12-05T00:53:38.7261404Z +\\n2025-12-05T00:53:38.7261671Z      # Evaluate with LLM\\n2025-12-05T00:53:38.7262008Z      try:\\n2025-12-05T00:53:38.7262274Z          prompt = (\\n2025-12-05T00:53:38.7262719Z              f\\\"Review the following Slack message from Albert H.:\\\\n\\\\n\\\"\\n2025-12-05T00:53:38.7263265Z              f\\\"{albert_message}\\\\n\\\\n\\\"\\n2025-12-05T00:53:38.7263909Z              f\\\"Determine if we should proceed with triggering the Azure DevOps pipeline. \\\"\\n2025-12-05T00:53:38.7264800Z              f\\\"Respond with 'Approved' if we should proceed, or 'Rejected' if we should not. \\\"\\n2025-12-05T00:53:38.7265564Z              f\\\"Only respond with one word: 'Approved' or 'Rejected'.\\\"\\n2025-12-05T00:53:38.7266073Z          )\\n2025-12-05T00:53:38.7266337Z -        \\n2025-12-05T00:53:38.7266601Z +\\n2025-12-05T00:53:38.7266876Z          msg = llm.invoke(prompt)\\n2025-12-05T00:53:38.7267501Z          approval = msg.content.strip()\\n2025-12-05T00:53:38.7268043Z -        \\n2025-12-05T00:53:38.7268303Z +\\n2025-12-05T00:53:38.7268625Z          # Ensure it's either Approved or Rejected\\n2025-12-05T00:53:38.7269096Z          if \\\"Approved\\\" in approval:\\n2025-12-05T00:53:38.7269523Z              approval = \\\"Approved\\\"\\n2025-12-05T00:53:38.7269898Z          else:\\n2025-12-05T00:53:38.7270211Z              approval = \\\"Rejected\\\"\\n2025-12-05T00:53:38.7270578Z -        \\n2025-12-05T00:53:38.7270855Z -        return {\\n2025-12-05T00:53:38.7271433Z -            \\\"albert_message\\\": albert_message,\\n2025-12-05T00:53:38.7271878Z -            \\\"llm_approval\\\": approval\\n2025-12-05T00:53:38.7272218Z -        }\\n2025-12-05T00:53:38.7272635Z +\\n2025-12-05T00:53:38.7273021Z +        return {\\\"albert_message\\\": albert_message, \\\"llm_approval\\\": approval}\\n2025-12-05T00:53:38.7273579Z      except Exception as e:\\n2025-12-05T00:53:38.7273917Z          return {\\n2025-12-05T00:53:38.7274221Z              \\\"albert_message\\\": albert_message,\\n2025-12-05T00:53:38.7274694Z              \\\"llm_approval\\\": \\\"Rejected\\\",\\n2025-12-05T00:53:38.7275218Z -            \\\"error\\\": f\\\"Error evaluating message with LLM: {str(e)}\\\"\\n2025-12-05T00:53:38.7275842Z +            \\\"error\\\": f\\\"Error evaluating message with LLM: {str(e)}\\\",\\n2025-12-05T00:53:38.7276328Z          }\\n2025-12-05T00:53:38.7276583Z  \\n2025-12-05T00:53:38.7276824Z  \\n2025-12-05T00:53:38.7277108Z  def validate_approval(state: State):\\n2025-12-05T00:53:38.7277760Z      \\\"\\\"\\\"Gate function: Validate LLM approval\\\"\\\"\\\"\\n2025-12-05T00:53:38.7278202Z @@ -260,17 +261,15 @@\\n2025-12-05T00:53:38.7278514Z  \\n2025-12-05T00:53:38.7278808Z  def trigger_pipeline(state: State):\\n2025-12-05T00:53:38.7279275Z      \\\"\\\"\\\"Node 2: Trigger Azure DevOps pipeline\\\"\\\"\\\"\\n2025-12-05T00:53:38.7279706Z      try:\\n2025-12-05T00:53:38.7280023Z          if not AZURE_DEVOPS_PIPELINE_ID:\\n2025-12-05T00:53:38.7280447Z -            return {\\n2025-12-05T00:53:38.7280857Z -                \\\"error\\\": \\\"Azure DevOps pipeline ID not configured\\\"\\n2025-12-05T00:53:38.7281346Z -            }\\n2025-12-05T00:53:38.7281627Z -        \\n2025-12-05T00:53:38.7282031Z +            return {\\\"error\\\": \\\"Azure DevOps pipeline ID not configured\\\"}\\n2025-12-05T00:53:38.7282538Z +\\n2025-12-05T00:53:38.7282865Z          pipeline_id = int(AZURE_DEVOPS_PIPELINE_ID)\\n2025-12-05T00:53:38.7283389Z          result = trigger_azure_pipeline(pipeline_id)\\n2025-12-05T00:53:38.7283845Z -        \\n2025-12-05T00:53:38.7284105Z +\\n2025-12-05T00:53:38.7284355Z          if result:\\n2025-12-05T00:53:38.7284707Z              # Extract build/run ID from response\\n2025-12-05T00:53:38.7285170Z              build_id = result.get(\\\"id\\\")\\n2025-12-05T00:53:38.7285597Z              if not build_id:\\n2025-12-05T00:53:38.7285988Z                  # Try to extract from _links\\n2025-12-05T00:53:38.7286418Z @@ -280,95 +279,97 @@\\n2025-12-05T00:53:38.7286768Z                      parts = href.split(\\\"/\\\")\\n2025-12-05T00:53:38.7287240Z                      for i, part in enumerate(parts):\\n2025-12-05T00:53:38.7287903Z                          if part == \\\"runs\\\" and i + 1 < len(parts):\\n2025-12-05T00:53:38.7288405Z                              build_id = parts[i + 1]\\n2025-12-05T00:53:38.7288841Z                              break\\n2025-12-05T00:53:38.7289189Z -            \\n2025-12-05T00:53:38.7289469Z +\\n2025-12-05T00:53:38.7289739Z              if build_id:\\n2025-12-05T00:53:38.7290083Z                  return {\\n2025-12-05T00:53:38.7290454Z                      \\\"pipeline_id\\\": pipeline_id,\\n2025-12-05T00:53:38.7291115Z -                    \\\"build_id\\\": int(build_id) if isinstance(build_id, (str, int)) else pipeline_id,\\n2025-12-05T00:53:38.7291779Z -                    \\\"build_status\\\": \\\"InProgress\\\"\\n2025-12-05T00:53:38.7292254Z +                    \\\"build_id\\\": int(build_id)\\n2025-12-05T00:53:38.7292727Z +                    if isinstance(build_id, (str, int))\\n2025-12-05T00:53:38.7293192Z +                    else pipeline_id,\\n2025-12-05T00:53:38.7293633Z +                    \\\"build_status\\\": \\\"InProgress\\\",\\n2025-12-05T00:53:38.7294042Z                  }\\n2025-12-05T00:53:38.7294333Z              else:\\n2025-12-05T00:53:38.7294624Z                  return {\\n2025-12-05T00:53:38.7295140Z                      \\\"error\\\": \\\"Failed to extract build ID from pipeline trigger response\\\",\\n2025-12-05T00:53:38.7295785Z -                    \\\"pipeline_id\\\": pipeline_id\\n2025-12-05T00:53:38.7296251Z +                    \\\"pipeline_id\\\": pipeline_id,\\n2025-12-05T00:53:38.7296669Z                  }\\n2025-12-05T00:53:38.7296955Z          else:\\n2025-12-05T00:53:38.7297242Z              return {\\n2025-12-05T00:53:38.7298172Z                  \\\"error\\\": \\\"Failed to trigger Azure DevOps pipeline - check logs for details\\\"\\n2025-12-05T00:53:38.7298826Z              }\\n2025-12-05T00:53:38.7299145Z      except ValueError as e:\\n2025-12-05T00:53:38.7299755Z -        return {\\n2025-12-05T00:53:38.7300160Z -            \\\"error\\\": f\\\"Invalid pipeline ID format: {str(e)}\\\"\\n2025-12-05T00:53:38.7300633Z -        }\\n2025-12-05T00:53:38.7301044Z +        return {\\\"error\\\": f\\\"Invalid pipeline ID format: {str(e)}\\\"}\\n2025-12-05T00:53:38.7301577Z      except Exception as e:\\n2025-12-05T00:53:38.7301943Z -        return {\\n2025-12-05T00:53:38.7302331Z -            \\\"error\\\": f\\\"Error triggering pipeline: {str(e)}\\\"\\n2025-12-05T00:53:38.7302801Z -        }\\n2025-12-05T00:53:38.7303179Z +        return {\\\"error\\\": f\\\"Error triggering pipeline: {str(e)}\\\"}\\n2025-12-05T00:53:38.7303686Z  \\n2025-12-05T00:53:38.7303929Z  \\n2025-12-05T00:53:38.7304247Z  def check_pipeline_status(state: State):\\n2025-12-05T00:53:38.7304777Z      \\\"\\\"\\\"Node 2a: Check pipeline status with polling\\\"\\\"\\\"\\n2025-12-05T00:53:38.7305300Z      pipeline_id = state.get(\\\"pipeline_id\\\")\\n2025-12-05T00:53:38.7305923Z      build_id = state.get(\\\"build_id\\\")  # This is the run_id from pipeline trigger\\n2025-12-05T00:53:38.7306495Z -    \\n2025-12-05T00:53:38.7306745Z +\\n2025-12-05T00:53:38.7307033Z      if not pipeline_id or not build_id:\\n2025-12-05T00:53:38.7307684Z -        return {\\n2025-12-05T00:53:38.7308060Z -            \\\"error\\\": \\\"No pipeline ID or build ID available\\\"\\n2025-12-05T00:53:38.7308518Z -        }\\n2025-12-05T00:53:38.7308778Z -    \\n2025-12-05T00:53:38.7309149Z +        return {\\\"error\\\": \\\"No pipeline ID or build ID available\\\"}\\n2025-12-05T00:53:38.7309627Z +\\n2025-12-05T00:53:38.7309927Z      # Wait 3 seconds before first check\\n2025-12-05T00:53:38.7310443Z      print(\\\"Waiting 3 seconds before first status check...\\\")\\n2025-12-05T00:53:38.7310953Z      time.sleep(3)\\n2025-12-05T00:53:38.7311262Z -    \\n2025-12-05T00:53:38.7311525Z +\\n2025-12-05T00:53:38.7311968Z      max_attempts = 100  # Maximum polling attempts (5 minutes with 3s intervals)\\n2025-12-05T00:53:38.7312528Z      attempt = 0\\n2025-12-05T00:53:38.7312805Z -    \\n2025-12-05T00:53:38.7313051Z +\\n2025-12-05T00:53:38.7313547Z      print(f\\\"Starting status polling for pipeline {pipeline_id}, run {build_id}...\\\")\\n2025-12-05T00:53:38.7314164Z -    \\n2025-12-05T00:53:38.7314410Z +\\n2025-12-05T00:53:38.7314689Z      while attempt < max_attempts:\\n2025-12-05T00:53:38.7315076Z          try:\\n2025-12-05T00:53:38.7315479Z              run_info = get_pipeline_status(pipeline_id, build_id)\\n2025-12-05T00:53:38.7315945Z -            \\n2025-12-05T00:53:38.7316217Z +\\n2025-12-05T00:53:38.7316481Z              if run_info:\\n2025-12-05T00:53:38.7316881Z                  state_value = run_info.get(\\\"state\\\", \\\"\\\").lower()\\n2025-12-05T00:53:38.7317822Z -                result_value = run_info.get(\\\"result\\\", \\\"\\\").lower() if run_info.get(\\\"result\\\") else None\\n2025-12-05T00:53:38.7318414Z -                \\n2025-12-05T00:53:38.7318707Z +                result_value = (\\n2025-12-05T00:53:38.7319118Z +                    run_info.get(\\\"result\\\", \\\"\\\").lower()\\n2025-12-05T00:53:38.7319618Z +                    if run_info.get(\\\"result\\\")\\n2025-12-05T00:53:38.7320017Z +                    else None\\n2025-12-05T00:53:38.7320355Z +                )\\n2025-12-05T00:53:38.7320625Z +\\n2025-12-05T00:53:38.7320911Z                  # Check if completed\\n2025-12-05T00:53:38.7321315Z                  if state_value == \\\"completed\\\":\\n2025-12-05T00:53:38.7321753Z                      if result_value:\\n2025-12-05T00:53:38.7322259Z                          status_msg = f\\\"Completed - {result_value.capitalize()}\\\"\\n2025-12-05T00:53:38.7322785Z                      else:\\n2025-12-05T00:53:38.7323158Z                          status_msg = \\\"Completed\\\"\\n2025-12-05T00:53:38.7323747Z -                    print(f\\\"Pipeline run {build_id} completed with status: {status_msg}\\\")\\n2025-12-05T00:53:38.7324352Z -                    return {\\n2025-12-05T00:53:38.7324726Z -                        \\\"build_status\\\": status_msg\\n2025-12-05T00:53:38.7325142Z -                    }\\n2025-12-05T00:53:38.7325694Z +                    print(\\n2025-12-05T00:53:38.7326234Z +                        f\\\"Pipeline run {build_id} completed with status: {status_msg}\\\"\\n2025-12-05T00:53:38.7327007Z +                    )\\n2025-12-05T00:53:38.7327578Z +                    return {\\\"build_status\\\": status_msg}\\n2025-12-05T00:53:38.7328031Z                  else:\\n2025-12-05T00:53:38.7328384Z                      # Still in progress, log and wait\\n2025-12-05T00:53:38.7328883Z                      current_status = run_info.get(\\\"state\\\", \\\"Unknown\\\")\\n2025-12-05T00:53:38.7329705Z -                    print(f\\\"Pipeline run {build_id} status: {current_status} (attempt {attempt + 1}/{max_attempts})\\\")\\n2025-12-05T00:53:38.7330432Z +                    print(\\n2025-12-05T00:53:38.7331057Z +                        f\\\"Pipeline run {build_id} status: {current_status} (attempt {attempt + 1}/{max_attempts})\\\"\\n2025-12-05T00:53:38.7331705Z +                    )\\n2025-12-05T00:53:38.7332030Z                      time.sleep(3)\\n2025-12-05T00:53:38.7332427Z                      attempt += 1\\n2025-12-05T00:53:38.7332792Z              else:\\n2025-12-05T00:53:38.7333145Z                  # If we can't get status, wait and retry\\n2025-12-05T00:53:38.7333896Z -                print(f\\\"Unable to get status for run {build_id}, retrying... (attempt {attempt + 1}/{max_attempts})\\\")\\n2025-12-05T00:53:38.7334625Z +                print(\\n2025-12-05T00:53:38.7335238Z +                    f\\\"Unable to get status for run {build_id}, retrying... (attempt {attempt + 1}/{max_attempts})\\\"\\n2025-12-05T00:53:38.7335917Z +                )\\n2025-12-05T00:53:38.7336238Z                  time.sleep(3)\\n2025-12-05T00:53:38.7336612Z                  attempt += 1\\n2025-12-05T00:53:38.7336963Z -                \\n2025-12-05T00:53:38.7337267Z +\\n2025-12-05T00:53:38.7337889Z          except Exception as e:\\n2025-12-05T00:53:38.7338264Z -            return {\\n2025-12-05T00:53:38.7338690Z -                \\\"error\\\": f\\\"Error checking pipeline status: {str(e)}\\\"\\n2025-12-05T00:53:38.7339187Z -            }\\n2025-12-05T00:53:38.7339486Z -    \\n2025-12-05T00:53:38.7339892Z +            return {\\\"error\\\": f\\\"Error checking pipeline status: {str(e)}\\\"}\\n2025-12-05T00:53:38.7340418Z +\\n2025-12-05T00:53:38.7340705Z      # If we exhausted attempts\\n2025-12-05T00:53:38.7341291Z      print(f\\\"Pipeline status check timed out after {max_attempts} attempts\\\")\\n2025-12-05T00:53:38.7341883Z      return {\\n2025-12-05T00:53:38.7342357Z          \\\"build_status\\\": \\\"Timeout - Status check exceeded maximum attempts\\\",\\n2025-12-05T00:53:38.7342982Z -        \\\"error\\\": \\\"Pipeline status check timed out\\\"\\n2025-12-05T00:53:38.7343502Z +        \\\"error\\\": \\\"Pipeline status check timed out\\\",\\n2025-12-05T00:53:38.7343946Z      }\\n2025-12-05T00:53:38.7344198Z  \\n2025-12-05T00:53:38.7344442Z  \\n2025-12-05T00:53:38.7344692Z  # Build workflow\\n2025-12-05T00:53:38.7345041Z  workflow = StateGraph(State)\\n2025-12-05T00:53:38.7345412Z @@ -383,14 +384,11 @@\\n2025-12-05T00:53:38.7345824Z  workflow.add_edge(START, \\\"consult_slack_messages\\\")\\n2025-12-05T00:53:38.7346483Z  workflow.add_edge(\\\"consult_slack_messages\\\", \\\"check_albert_message\\\")\\n2025-12-05T00:53:38.7347089Z  workflow.add_conditional_edges(\\n2025-12-05T00:53:38.7347662Z      \\\"check_albert_message\\\",\\n2025-12-05T00:53:38.7348053Z      validate_approval,\\n2025-12-05T00:53:38.7348367Z -    {\\n2025-12-05T00:53:38.7348682Z -        \\\"Approved\\\": \\\"trigger_pipeline\\\",\\n2025-12-05T00:53:38.7349117Z -        \\\"Rejected\\\": END\\n2025-12-05T00:53:38.7349433Z -    }\\n2025-12-05T00:53:38.7349788Z +    {\\\"Approved\\\": \\\"trigger_pipeline\\\", \\\"Rejected\\\": END},\\n2025-12-05T00:53:38.7350244Z  )\\n2025-12-05T00:53:38.7350660Z  workflow.add_edge(\\\"trigger_pipeline\\\", \\\"check_pipeline_status\\\")\\n2025-12-05T00:53:38.7351282Z  workflow.add_edge(\\\"check_pipeline_status\\\", END)\\n2025-12-05T00:53:38.7351741Z  \\n2025-12-05T00:53:38.7351986Z  # Compile\\n2025-12-05T00:53:38.7352268Z @@ -400,36 +398,35 @@\\n2025-12-05T00:53:38.7352601Z  if __name__ == \\\"__main__\\\":\\n2025-12-05T00:53:38.7353042Z      # Show workflow graph BEFORE execution\\n2025-12-05T00:53:38.7353473Z      print(\\\"=\\\" * 60)\\n2025-12-05T00:53:38.7354077Z      print(\\\"Generating workflow graph...\\\")\\n2025-12-05T00:53:38.7354534Z      print(\\\"=\\\" * 60)\\n2025-12-05T00:53:38.7354835Z -    \\n2025-12-05T00:53:38.7355352Z +\\n2025-12-05T00:53:38.7355707Z      graph_image = chain.get_graph().draw_mermaid_png()\\n2025-12-05T00:53:38.7356174Z -    \\n2025-12-05T00:53:38.7356425Z +\\n2025-12-05T00:53:38.7356710Z      # Save the graph image to file\\n2025-12-05T00:53:38.7357155Z      graph_file = \\\"workflow_graph_v2.png\\\"\\n2025-12-05T00:53:38.7357890Z      with open(graph_file, \\\"wb\\\") as f:\\n2025-12-05T00:53:38.7358328Z          f.write(graph_image)\\n2025-12-05T00:53:38.7359084Z      print(f\\\"✓ Workflow graph saved to: {graph_file}\\\")\\n2025-12-05T00:53:38.7359561Z -    \\n2025-12-05T00:53:38.7359821Z +\\n2025-12-05T00:53:38.7360105Z      # Display the graph image\\n2025-12-05T00:53:38.7360530Z      img = PILImage.open(io.BytesIO(graph_image))\\n2025-12-05T00:53:38.7361301Z      img.show()  # Abrirá la imagen con el visor predeterminado\\n2025-12-05T00:53:38.7361961Z      print(\\\"✓ Workflow graph displayed\\\")\\n2025-12-05T00:53:38.7362407Z      print(\\\"=\\\" * 60)\\n2025-12-05T00:53:38.7362795Z      print(\\\"\\\\nStarting workflow execution...\\\\n\\\")\\n2025-12-05T00:53:38.7363242Z -    \\n2025-12-05T00:53:38.7363503Z +\\n2025-12-05T00:53:38.7363845Z      # Example usage - replace with actual channel name\\n2025-12-05T00:53:38.7364382Z      state = chain.invoke({\\\"channel\\\": \\\"general\\\"})\\n2025-12-05T00:53:38.7364812Z -    \\n2025-12-05T00:53:38.7365064Z +\\n2025-12-05T00:53:38.7365396Z      print(\\\"\\\\n=== Workflow Execution Result ===\\\\n\\\")\\n2025-12-05T00:53:38.7365920Z      print(f\\\"Channel: {state.get('channel')}\\\")\\n2025-12-05T00:53:38.7366527Z      print(f\\\"Messages found: {len(state.get('slack_messages', []))}\\\")\\n2025-12-05T00:53:38.7367260Z      print(f\\\"Albert H. message: {state.get('albert_message', 'Not found')}\\\")\\n2025-12-05T00:53:38.7368140Z      print(f\\\"LLM Approval: {state.get('llm_approval', 'N/A')}\\\")\\n2025-12-05T00:53:38.7368785Z      print(f\\\"Pipeline ID: {state.get('pipeline_id', 'N/A')}\\\")\\n2025-12-05T00:53:38.7369392Z      print(f\\\"Build ID: {state.get('build_id', 'N/A')}\\\")\\n2025-12-05T00:53:38.7369984Z      print(f\\\"Build Status: {state.get('build_status', 'N/A')}\\\")\\n2025-12-05T00:53:38.7370493Z -    \\n2025-12-05T00:53:38.7370793Z -    if state.get('error'):\\n2025-12-05T00:53:38.7371137Z +\\n2025-12-05T00:53:38.7371414Z +    if state.get(\\\"error\\\"):\\n2025-12-05T00:53:38.7371806Z          print(f\\\"Error: {state.get('error')}\\\")\\n2025-12-05T00:53:38.7372230Z -\\n2025-12-05T00:53:38.7373241Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/agent/re_agent_v2.py\\n2025-12-05T00:53:38.8028590Z --- /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\t2025-12-05 00:53:28.190680+00:00\\n2025-12-05T00:53:38.8031345Z +++ /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\t2025-12-05 00:53:38.801441+00:00\\n2025-12-05T00:53:38.8035782Z @@ -28,10 +28,11 @@\\n2025-12-05T00:53:38.8041631Z would reformat /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow/src/emulation/teams/app.py\\n2025-12-05T00:53:38.8042771Z  app.mount(\\\"/static\\\", StaticFiles(directory=STATIC_DIR), name=\\\"static\\\")\\n2025-12-05T00:53:38.8043294Z  \\n2025-12-05T00:53:38.8043549Z  # In-memory database\\n2025-12-05T00:53:38.8043859Z  posts_db = []\\n2025-12-05T00:53:38.8044151Z  replies_db = []\\n2025-12-05T00:53:38.8044426Z +\\n2025-12-05T00:53:38.8044656Z  \\n2025-12-05T00:53:38.8044914Z  # Initialize with sample data\\n2025-12-05T00:53:38.8045281Z  def init_sample_data():\\n2025-12-05T00:53:38.8045657Z      \\\"\\\"\\\"Initialize with sample post data\\\"\\\"\\\"\\n2025-12-05T00:53:38.8046158Z      if not posts_db:  # Only add if database is empty\\n2025-12-05T00:53:38.8046618Z @@ -39,25 +40,26 @@\\n2025-12-05T00:53:38.8046941Z              \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:53:38.8047603Z              \\\"title\\\": \\\"M190.0.0 Google Vertex AI Release\\\",\\n2025-12-05T00:53:38.8048076Z              \\\"user\\\": \\\"Cristina M.\\\",\\n2025-12-05T00:53:38.8048786Z              \\\"role\\\": \\\"Program Manager\\\",\\n2025-12-05T00:53:38.8049694Z              \\\"message\\\": \\\"Hello everyone, this is the deployment plan to start today with it. Please check the component ID here: vertex-ai-re-agent.\\\",\\n2025-12-05T00:53:38.8050927Z -            \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:53:38.8051462Z +            \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:53:38.8051892Z          }\\n2025-12-05T00:53:38.8052212Z          posts_db.append(sample_post)\\n2025-12-05T00:53:38.8052607Z -        \\n2025-12-05T00:53:38.8052877Z +\\n2025-12-05T00:53:38.8053173Z          # Add sample reply to the post\\n2025-12-05T00:53:38.8053606Z          sample_reply = {\\n2025-12-05T00:53:38.8053983Z              \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:53:38.8054411Z              \\\"post_id\\\": sample_post[\\\"id\\\"],\\n2025-12-05T00:53:38.8054831Z              \\\"user\\\": \\\"Alexa A.\\\",\\n2025-12-05T00:53:38.8055198Z              \\\"role\\\": \\\"SCRUM Master\\\",\\n2025-12-05T00:53:38.8055948Z              \\\"message\\\": \\\"M190.0.0 GVA validated.\\\\n\\\\nThere is no pending SC tickets.\\\\n\\\\nPlease start with the release.\\\",\\n2025-12-05T00:53:38.8056684Z -            \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:53:38.8057177Z +            \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:53:38.8057778Z          }\\n2025-12-05T00:53:38.8058076Z          replies_db.append(sample_reply)\\n2025-12-05T00:53:38.8058464Z  \\n2025-12-05T00:53:38.8058692Z +\\n2025-12-05T00:53:38.8058970Z  # Initialize sample data on startup\\n2025-12-05T00:53:38.8059621Z  init_sample_data()\\n2025-12-05T00:53:38.8059922Z  \\n2025-12-05T00:53:38.8060127Z  \\n2025-12-05T00:53:38.8060339Z  # Models\\n2025-12-05T00:53:38.8060564Z @@ -80,10 +82,11 @@\\n2025-12-05T00:53:38.8060816Z      message: str\\n2025-12-05T00:53:38.8061055Z  \\n2025-12-05T00:53:38.8061263Z  \\n2025-12-05T00:53:38.8061524Z  class ReplyCreateSimple(BaseModel):\\n2025-12-05T00:53:38.8062083Z      \\\"\\\"\\\"Simplified reply creation without post_id (post_id comes from URL)\\\"\\\"\\\"\\n2025-12-05T00:53:38.8062599Z +\\n2025-12-05T00:53:38.8062825Z      user: str\\n2025-12-05T00:53:38.8063078Z      role: str\\n2025-12-05T00:53:38.8063320Z      message: str\\n2025-12-05T00:53:38.8063557Z  \\n2025-12-05T00:53:38.8063761Z  \\n2025-12-05T00:53:38.8063979Z @@ -110,10 +113,11 @@\\n2025-12-05T00:53:38.8064245Z      timestamp: str\\n2025-12-05T00:53:38.8064506Z  \\n2025-12-05T00:53:38.8064709Z  \\n2025-12-05T00:53:38.8064956Z  class PostSummary(BaseModel):\\n2025-12-05T00:53:38.8065366Z      \\\"\\\"\\\"Simplified post model for list view (no replies)\\\"\\\"\\\"\\n2025-12-05T00:53:38.8065761Z +\\n2025-12-05T00:53:38.8065977Z      id: str\\n2025-12-05T00:53:38.8066239Z      title: Optional[str] = None\\n2025-12-05T00:53:38.8066559Z      message: str\\n2025-12-05T00:53:38.8066800Z  \\n2025-12-05T00:53:38.8067006Z  \\n2025-12-05T00:53:38.8067211Z @@ -139,36 +143,39 @@\\n2025-12-05T00:53:38.8067730Z  async def get_posts_full():\\n2025-12-05T00:53:38.8068123Z      \\\"\\\"\\\"Get all posts with their replies - for frontend use\\\"\\\"\\\"\\n2025-12-05T00:53:38.8068534Z      try:\\n2025-12-05T00:53:38.8068795Z          posts_with_replies = []\\n2025-12-05T00:53:38.8069128Z          for post in posts_db:\\n2025-12-05T00:53:38.8069675Z -            post_replies = [reply for reply in replies_db if reply[\\\"post_id\\\"] == post[\\\"id\\\"]]\\n2025-12-05T00:53:38.8070232Z +            post_replies = [\\n2025-12-05T00:53:38.8070676Z +                reply for reply in replies_db if reply[\\\"post_id\\\"] == post[\\\"id\\\"]\\n2025-12-05T00:53:38.8071135Z +            ]\\n2025-12-05T00:53:38.8071396Z              post_dict = {\\n2025-12-05T00:53:38.8071708Z                  \\\"id\\\": post[\\\"id\\\"],\\n2025-12-05T00:53:38.8072059Z                  \\\"title\\\": post.get(\\\"title\\\"),\\n2025-12-05T00:53:38.8072421Z                  \\\"user\\\": post[\\\"user\\\"],\\n2025-12-05T00:53:38.8072756Z                  \\\"role\\\": post[\\\"role\\\"],\\n2025-12-05T00:53:38.8073104Z                  \\\"message\\\": post[\\\"message\\\"],\\n2025-12-05T00:53:38.8073471Z                  \\\"timestamp\\\": post[\\\"timestamp\\\"],\\n2025-12-05T00:53:38.8073868Z -                \\\"replies\\\": post_replies\\n2025-12-05T00:53:38.8074245Z +                \\\"replies\\\": post_replies,\\n2025-12-05T00:53:38.8074825Z              }\\n2025-12-05T00:53:38.8075138Z              posts_with_replies.append(post_dict)\\n2025-12-05T00:53:38.8075728Z          return posts_with_replies\\n2025-12-05T00:53:38.8076099Z      except Exception as e:\\n2025-12-05T00:53:38.8076464Z          print(f\\\"Error in get_posts_full: {str(e)}\\\")\\n2025-12-05T00:53:38.8076877Z          import traceback\\n2025-12-05T00:53:38.8077202Z +\\n2025-12-05T00:53:38.8077616Z          traceback.print_exc()\\n2025-12-05T00:53:38.8078192Z          raise HTTPException(status_code=500, detail=f\\\"Internal server error: {str(e)}\\\")\\n2025-12-05T00:53:38.8078737Z  \\n2025-12-05T00:53:38.8078943Z  \\n2025-12-05T00:53:38.8079250Z  @app.get(\\\"/api/posts/{post_id}\\\", response_model=Post)\\n2025-12-05T00:53:38.8079678Z  async def get_post(post_id: str):\\n2025-12-05T00:53:38.8080056Z      \\\"\\\"\\\"Get a specific post with its replies\\\"\\\"\\\"\\n2025-12-05T00:53:38.8080571Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:53:38.8081052Z      if not post:\\n2025-12-05T00:53:38.8081508Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:53:38.8081985Z -    \\n2025-12-05T00:53:38.8082237Z +\\n2025-12-05T00:53:38.8082666Z      post_replies = [reply for reply in replies_db if reply[\\\"post_id\\\"] == post_id]\\n2025-12-05T00:53:38.8083256Z      post_dict = post.copy()\\n2025-12-05T00:53:38.8083626Z      post_dict[\\\"replies\\\"] = post_replies\\n2025-12-05T00:53:38.8084024Z      return post_dict\\n2025-12-05T00:53:38.8084315Z  \\n2025-12-05T00:53:38.8084550Z @@ -187,11 +194,11 @@\\n2025-12-05T00:53:38.8084888Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:53:38.8085279Z          \\\"title\\\": post.title,\\n2025-12-05T00:53:38.8085652Z          \\\"user\\\": post.user,\\n2025-12-05T00:53:38.8085977Z          \\\"role\\\": post.role,\\n2025-12-05T00:53:38.8086337Z          \\\"message\\\": post.message,\\n2025-12-05T00:53:38.8086735Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:53:38.8087237Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:53:38.8087946Z      }\\n2025-12-05T00:53:38.8088226Z      posts_db.append(new_post)\\n2025-12-05T00:53:38.8088595Z      return new_post\\n2025-12-05T00:53:38.8088884Z  \\n2025-12-05T00:53:38.8089123Z  \\n2025-12-05T00:53:38.8089360Z @@ -199,11 +206,11 @@\\n2025-12-05T00:53:38.8089773Z  async def update_post(post_id: str, post_update: PostUpdate):\\n2025-12-05T00:53:38.8090251Z      \\\"\\\"\\\"Update a post\\\"\\\"\\\"\\n2025-12-05T00:53:38.8090672Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:53:38.8091130Z      if not post:\\n2025-12-05T00:53:38.8091549Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:53:38.8092049Z -    \\n2025-12-05T00:53:38.8092289Z +\\n2025-12-05T00:53:38.8092572Z      if post_update.title is not None:\\n2025-12-05T00:53:38.8092978Z          post[\\\"title\\\"] = post_update.title\\n2025-12-05T00:53:38.8093382Z      if post_update.message is not None:\\n2025-12-05T00:53:38.8093774Z          post[\\\"message\\\"] = post_update.message\\n2025-12-05T00:53:38.8094217Z      post[\\\"timestamp\\\"] = datetime.now().isoformat()\\n2025-12-05T00:53:38.8094605Z @@ -214,11 +221,11 @@\\n2025-12-05T00:53:38.8094910Z  async def delete_post(post_id: str):\\n2025-12-05T00:53:38.8095312Z      \\\"\\\"\\\"Delete a post and all its replies\\\"\\\"\\\"\\n2025-12-05T00:53:38.8095773Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:53:38.8096235Z      if not post:\\n2025-12-05T00:53:38.8096623Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:53:38.8097088Z -    \\n2025-12-05T00:53:38.8097552Z +\\n2025-12-05T00:53:38.8097810Z      posts_db.remove(post)\\n2025-12-05T00:53:38.8098169Z      # Delete all replies for this post\\n2025-12-05T00:53:38.8098687Z      replies_db[:] = [r for r in replies_db if r[\\\"post_id\\\"] != post_id]\\n2025-12-05T00:53:38.8099252Z      return {\\\"message\\\": \\\"Post deleted successfully\\\"}\\n2025-12-05T00:53:38.8099690Z  \\n2025-12-05T00:53:38.8099943Z @@ -228,18 +235,18 @@\\n2025-12-05T00:53:38.8100355Z      \\\"\\\"\\\"Create a new reply to a post (requires post_id in body)\\\"\\\"\\\"\\n2025-12-05T00:53:38.8101070Z      # Verify post exists\\n2025-12-05T00:53:38.8101512Z      post = next((p for p in posts_db if p[\\\"id\\\"] == reply.post_id), None)\\n2025-12-05T00:53:38.8102209Z      if not post:\\n2025-12-05T00:53:38.8102607Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:53:38.8103067Z -    \\n2025-12-05T00:53:38.8103285Z +\\n2025-12-05T00:53:38.8103513Z      new_reply = {\\n2025-12-05T00:53:38.8103795Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:53:38.8104153Z          \\\"post_id\\\": reply.post_id,\\n2025-12-05T00:53:38.8104514Z          \\\"user\\\": reply.user,\\n2025-12-05T00:53:38.8104839Z          \\\"role\\\": reply.role,\\n2025-12-05T00:53:38.8105179Z          \\\"message\\\": reply.message,\\n2025-12-05T00:53:38.8105559Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:53:38.8106003Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:53:38.8106375Z      }\\n2025-12-05T00:53:38.8106642Z      replies_db.append(new_reply)\\n2025-12-05T00:53:38.8106976Z      return new_reply\\n2025-12-05T00:53:38.8107255Z  \\n2025-12-05T00:53:38.8107731Z  \\n2025-12-05T00:53:38.8107955Z @@ -248,18 +255,18 @@\\n2025-12-05T00:53:38.8108470Z      \\\"\\\"\\\"Create a new reply to a post (post_id from URL, simplified body with user, role, message)\\\"\\\"\\\"\\n2025-12-05T00:53:38.8109063Z      # Verify post exists\\n2025-12-05T00:53:38.8109481Z      post = next((p for p in posts_db if p[\\\"id\\\"] == post_id), None)\\n2025-12-05T00:53:38.8109919Z      if not post:\\n2025-12-05T00:53:38.8110324Z          raise HTTPException(status_code=404, detail=\\\"Post not found\\\")\\n2025-12-05T00:53:38.8110790Z -    \\n2025-12-05T00:53:38.8111016Z +\\n2025-12-05T00:53:38.8111246Z      new_reply = {\\n2025-12-05T00:53:38.8111523Z          \\\"id\\\": str(uuid.uuid4()),\\n2025-12-05T00:53:38.8111862Z          \\\"post_id\\\": post_id,\\n2025-12-05T00:53:38.8112178Z          \\\"user\\\": reply.user,\\n2025-12-05T00:53:38.8112499Z          \\\"role\\\": reply.role,\\n2025-12-05T00:53:38.8112820Z          \\\"message\\\": reply.message,\\n2025-12-05T00:53:38.8113205Z -        \\\"timestamp\\\": datetime.now().isoformat()\\n2025-12-05T00:53:38.8113627Z +        \\\"timestamp\\\": datetime.now().isoformat(),\\n2025-12-05T00:53:38.8114002Z      }\\n2025-12-05T00:53:38.8114262Z      replies_db.append(new_reply)\\n2025-12-05T00:53:38.8114604Z      return new_reply\\n2025-12-05T00:53:38.8114887Z  \\n2025-12-05T00:53:38.8115109Z  \\n2025-12-05T00:53:38.8115341Z @@ -267,11 +274,11 @@\\n2025-12-05T00:53:38.8115764Z  async def update_reply(reply_id: str, reply_update: ReplyUpdate):\\n2025-12-05T00:53:38.8116280Z      \\\"\\\"\\\"Update a reply\\\"\\\"\\\"\\n2025-12-05T00:53:38.8116708Z      reply = next((r for r in replies_db if r[\\\"id\\\"] == reply_id), None)\\n2025-12-05T00:53:38.8117187Z      if not reply:\\n2025-12-05T00:53:38.8117750Z          raise HTTPException(status_code=404, detail=\\\"Reply not found\\\")\\n2025-12-05T00:53:38.8118229Z -    \\n2025-12-05T00:53:38.8118457Z +\\n2025-12-05T00:53:38.8118729Z      reply[\\\"message\\\"] = reply_update.message\\n2025-12-05T00:53:38.8119176Z      reply[\\\"timestamp\\\"] = datetime.now().isoformat()\\n2025-12-05T00:53:38.8119584Z      return reply\\n2025-12-05T00:53:38.8119843Z  \\n2025-12-05T00:53:38.8120053Z  \\n2025-12-05T00:53:38.8120274Z @@ -279,13 +286,14 @@\\n2025-12-05T00:53:38.8120586Z  async def delete_reply(reply_id: str):\\n2025-12-05T00:53:38.8120967Z      \\\"\\\"\\\"Delete a reply\\\"\\\"\\\"\\n2025-12-05T00:53:38.8121376Z      reply = next((r for r in replies_db if r[\\\"id\\\"] == reply_id), None)\\n2025-12-05T00:53:38.8121845Z      if not reply:\\n2025-12-05T00:53:38.8122245Z          raise HTTPException(status_code=404, detail=\\\"Reply not found\\\")\\n2025-12-05T00:53:38.8122718Z -    \\n2025-12-05T00:53:38.8122951Z +\\n2025-12-05T00:53:38.8123195Z      replies_db.remove(reply)\\n2025-12-05T00:53:38.8123594Z      return {\\\"message\\\": \\\"Reply deleted successfully\\\"}\\n2025-12-05T00:53:38.8123998Z  \\n2025-12-05T00:53:38.8124216Z  \\n2025-12-05T00:53:38.8124454Z  if __name__ == \\\"__main__\\\":\\n2025-12-05T00:53:38.8124770Z      import uvicorn\\n2025-12-05T00:53:38.8125033Z +\\n2025-12-05T00:53:38.8125314Z      uvicorn.run(app, host=\\\"0.0.0.0\\\", port=8000)\\n2025-12-05T00:53:38.8145411Z \\n2025-12-05T00:53:38.8146101Z Oh no! 💥 💔 💥\\n2025-12-05T00:53:38.8146447Z 3 files would be reformatted.\\n2025-12-05T00:53:38.8429006Z \\n2025-12-05T00:53:38.8451328Z ##[error]Black found code formatting issues. Some files need to be reformatted.\\n2025-12-05T00:53:38.8460698Z ##[notice]Run 'black --exclude='\\\\''/(env|\\\\.git|__pycache__)/'\\\\'' .' locally to fix formatting issues.\\n2025-12-05T00:53:38.8462898Z ##[error]Process completed with exit code 1.\\n2025-12-05T00:53:38.8573442Z Post job cleanup.\\n2025-12-05T00:53:38.9530726Z [command]/usr/bin/git version\\n2025-12-05T00:53:38.9573235Z git version 2.52.0\\n2025-12-05T00:53:38.9620464Z Temporarily overriding HOME='/home/runner/work/_temp/30c28bbf-cd95-4aad-8563-c9af7d9f328a' before making global git config changes\\n2025-12-05T00:53:38.9622627Z Adding repository directory to the temporary git global config as a safe directory\\n2025-12-05T00:53:38.9628430Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/release_engineering_agentic_workflow/release_engineering_agentic_workflow\\n2025-12-05T00:53:38.9675004Z [command]/usr/bin/git config --local --name-only --get-regexp core\\\\.sshCommand\\n2025-12-05T00:53:38.9711163Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'core\\\\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :\\\"\\n2025-12-05T00:53:38.9963502Z [command]/usr/bin/git config --local --name-only --get-regexp http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader\\n2025-12-05T00:53:38.9988476Z http.https://github.com/.extraheader\\n2025-12-05T00:53:39.0003207Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader\\n2025-12-05T00:53:39.0037629Z [command]/usr/bin/git submodule foreach --recursive sh -c \\\"git config --local --name-only --get-regexp 'http\\\\.https\\\\:\\\\/\\\\/github\\\\.com\\\\/\\\\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :\\\"\\n2025-12-05T00:53:39.0278541Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\\\\.gitdir:\\n2025-12-05T00:53:39.0314650Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url\\n2025-12-05T00:53:39.0703561Z Cleaning up orphan processes\\n\",\n    \"message_available\": \"true\",\n    \"deployment\": {\n      \"can_start\": \"true\",\n      \"reason\": \"M190.0.0 GVA validated.\\n\\nThere is no pending SC tickets.\\n\\nPlease start with the release.\",\n      \"component_id\": \"release_engineering_agentic_workflow\",\n      \"conversation_thread_title\": \"M190.0.0 Google Vertex AI Release\"\n    },\n    \"workflow\": {\n      \"build_id\": \"19948938764\",\n      \"status\": \"failure\",\n      \"logs_url\": \"https://api.github.com/repos/francodem/release_engineering_agentic_workflow/actions/runs/19948938764/logs\"\n    },\n    \"h1\": \"The CI/CD pipeline failed because the Python code in 'src/agent/re_agent.py', 'src/agent/re_agent_v2.py', and 'src/emulation/teams/app.py' does not adhere to the 'black' code formatter's standards. The 'black --check --diff' command, executed as part of the linting step, detected these formatting discrepancies and exited with status code 1, as evidenced by the log lines \\\"3 files would be reformatted.\\\" and \\\"Black found code formatting issues. Some files need to be reformatted.\\\" leading to \\\"Process completed with exit code 1.\\\".\",\n    \"h2\": \"The pipeline failed because the 'black' code formatter identified three Python files (/src/agent/re_agent.py, /src/agent/re_agent_v2.py, and /src/emulation/teams/app.py) that do not conform to its formatting standards. This is evidenced by the log entries \\\"black found code formatting issues. Some files need to be reformatted.\\\" and \\\"Process completed with exit code 1.\\\", immediately preceded by diffs indicating changes black would make to those specific files.\",\n    \"h3\": \"The CI/CD pipeline failed because the 'black' code formatter check detected unformatted Python files. Specifically, 'src/agent/re_agent.py', 'src/agent/re_agent_v2.py', and 'src/emulation/teams/app.py' would be reformatted if the 'black' command were run without the '--check' flag, causing the step to exit with code 1. This is evidenced by the lines \\\"would reformat .../src/agent/re_agent.py\\\", \\\"3 files would be reformatted.\\\", \\\"Black found code formatting issues. Some files need to be reformatted.\\\", and \\\"Process completed with exit code 1.\\\" following the execution of the 'black --check --diff' command.\"\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        4800,
        -768
      ],
      "id": "ee44d563-6871-4c8a-bd84-3f329cd8cd66",
      "name": "Edit Fields9"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "maxOutputTokens": 3000,
          "temperature": 0.1,
          "topK": 1,
          "topP": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        5904,
        -400
      ],
      "id": "b2a62fa6-401d-4c3e-a7f4-132b60ff97ac",
      "name": "Google Vertex Chat Model2",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=## Jira Details\n{{ JSON.stringify($json.output) }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "=You are a Release Engineering Automation Agent specialized in Jira incident lifecycle management. You operate within a strict CI/CD workflow loop.\n\n### CORE DIRECTIVE\nYour primary function is to manage Jira tickets based on provided SRE details. You have two exclusive modes of operation depending on the input JSON structure. You must strictly adhere to the defined JSON output format and status lifecycle.\n\n---\n\n### MODE 1: TICKET CREATION\n**Trigger:** You receive a JSON object containing a `jira` key, which holds the `summary` and `description`.\n*Example Input:* `{\"jira\": {\"summary\": \"...\", \"description\": \"...\"}}`\n\n**Execution Steps:**\n1.  **Extract:** Retrieve the data directly from `jira.summary` and `jira.description`.\n2.  **Tool Action:** Use the tool **`Create_an_issue_in_Jira_Software`** to create a new ticket using exactly these details.\n3.  **Output:** Once the tool confirms creation, return the \"jira_artifacts\" JSON with the status **`\"created\"`**.\n\n---\n\n### MODE 2: STATUS VALIDATION\n**Trigger:** You receive a specific JSON command: `{\"command\": \"check_again\"}`.\n\n**CRITICAL PROTOCOL:**\n* You are **FORBIDDEN** from guessing the status.\n* You are **FORBIDDEN** from using your memory of the previous status (e.g., do not just repeat \"created\").\n* You **MUST** invoke the tool **`Get_the_status_of_an_issue_in_Jira_Software`** using the Ticket ID established in Mode 1 for *every single* \"check_again\" request you receive.\n\n**Execution Steps:**\n1.  **Context:** Recall the Ticket ID of the issue you created in Mode 1.\n2.  **Tool Action:** Call **`Get_the_status_of_an_issue_in_Jira_Software`** with that ID.\n3.  **Normalize Status:** Map the raw status returned by the tool to the Strict Status Enum:\n    * **`\"completed\"`** IF AND ONLY IF the Jira status is: \"Done\", \"Resolved\", \"Closed\", \"Fixed\", \"Completed\", or \"Finalizado\".\n    * **`\"inProgress\"`** for ALL other active statuses (e.g., \"To Do\", \"In Progress\", \"In Review\", \"Open\", \"Por hacer\", \"En curso\", \"En revisión\").\n4.  **Output:** Return the \"jira_artifacts\" JSON with the normalized status.\n\n---\n\n### STRICT OUTPUT FORMAT\nFor EVERY interaction, you must return a single JSON object.\n* **No** markdown formatting (bolding, code blocks) outside the JSON.\n* **No** conversational text.\n\n**Required JSON Structure:**\n```json\n{\n  \"jira_artifacts\": {\n    \"id\": \"TICKET_ID_STRING\",\n    \"status\": \"STRICT_STATUS_ENUM\",\n    \"link\": \"TICKET_LINK_STRING\"\n  }\n}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 3,
      "position": [
        6000,
        -640
      ],
      "id": "079f510f-2125-416c-a994-11c1950f0b61",
      "name": "Jira Manager Agent",
      "retryOnFail": true,
      "maxTries": 5,
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "001",
        "contextWindowLength": 50
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        6064,
        -400
      ],
      "id": "c3fde710-de4e-4efd-88df-e9c51d329e6a",
      "name": "Simple Memory"
    },
    {
      "parameters": {
        "jsonSchemaExample": "{\n  \"jira_artifacts\": {\n    \"id\": \"string\",\n    \"status\": \"string\",\n    \"link\": \"string\"\n  }\n}",
        "autoFix": true
      },
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "typeVersion": 1.3,
      "position": [
        6528,
        -400
      ],
      "id": "63334d7b-6b1e-4414-89b7-4ab35a3d912b",
      "name": "Structured Output Parser2"
    },
    {
      "parameters": {
        "projectId": {
          "__rl": true,
          "value": "release-engineering-workflow",
          "mode": "list",
          "cachedResultName": "Release Engineering Workflow"
        },
        "options": {
          "temperature": 0.1,
          "topK": 1,
          "topP": 0.7
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGoogleVertex",
      "typeVersion": 1,
      "position": [
        6608,
        -240
      ],
      "id": "a17f3eb3-faa6-40c1-b77a-99e2bbe678da",
      "name": "Google Vertex Chat Model8",
      "credentials": {
        "googleApi": {
          "id": "R2IoiG9mzbt4Yqid",
          "name": "Google Service Account account"
        }
      }
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\n  \"output\": {\n    \"jira\": {\n      \"summary\": \"CI/CD Failure: Python Linting Issues Detected by Black Formatter\",\n      \"description\": \"The CI/CD pipeline failed during the linting step. The `black` code formatter, executed with `black --check --diff`, identified formatting inconsistencies in the following three Python files:\\n- `src/agent/re_agent.py`\\n- `src/agent/re_agent_v2.py`\\n- `src/emulation/teams/app.py`\\n\\nThe log output clearly indicates:\\n- \\\"3 files would be reformatted.\\\"\\n- \\\"Black found code formatting issues. Some files need to be reformatted.\\\"\\n- \\\"Process completed with exit code 1.\\\"\\n\\nThis confirms that the pipeline failed because the `black` check detected deviations from the defined code style, causing the job to terminate with a non-zero exit code. To resolve this, the identified files need to be reformatted using `black`.\"\n    }\n  }\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        5696,
        -592
      ],
      "id": "84f1f432-0ea3-43ee-97c3-b50998b1033e",
      "name": "Edit Fields10"
    },
    {
      "parameters": {
        "amount": 15
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        5984,
        -848
      ],
      "id": "a2acc306-98d2-4a24-a9ab-6b56e8c96851",
      "name": "Wait2",
      "webhookId": "ac36b5a1-914f-4bf8-9fa9-89526710c89d"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "{\"output\":{\"command\": \"check_again\"}}",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        6112,
        -848
      ],
      "id": "4e8e9db5-ef68-4669-a7b7-f16a69f1a207",
      "name": "check_again when inProgress1"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "f79a3206-7329-4985-a20c-4db59a9ac441",
              "leftValue": "={{ $json.output.jira_artifacts.status.toLowerCase() }}",
              "rightValue": "completed",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        6432,
        -656
      ],
      "id": "117ac251-1385-4234-9b5d-a294a35cd54e",
      "name": "If"
    },
    {
      "parameters": {
        "operation": "get",
        "issueKey": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Issue_Key', ``, 'string') }}",
        "additionalFields": {}
      },
      "type": "n8n-nodes-base.jiraTool",
      "typeVersion": 1,
      "position": [
        6384,
        -400
      ],
      "id": "3ae122f3-252d-46ce-a67e-a8120d476e30",
      "name": "Get_the_status_of_an_issue_in_Jira_Software",
      "credentials": {
        "jiraSoftwareCloudApi": {
          "id": "K5ShhbHnt545AI0J",
          "name": "Jira n8n Demo GDG Conn"
        }
      }
    },
    {
      "parameters": {
        "project": {
          "__rl": true,
          "value": "10000",
          "mode": "list",
          "cachedResultName": "Mi equipo de software"
        },
        "issueType": {
          "__rl": true,
          "value": "10003",
          "mode": "list",
          "cachedResultName": "Task"
        },
        "summary": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Summary', ``, 'string') }}",
        "additionalFields": {
          "description": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('Description', ``, 'string') }}"
        }
      },
      "type": "n8n-nodes-base.jiraTool",
      "typeVersion": 1,
      "position": [
        6224,
        -400
      ],
      "id": "7926b038-d4d0-4e34-9a41-7a9fd33b2dfe",
      "name": "Create_an_issue_in_Jira_Software",
      "credentials": {
        "jiraSoftwareCloudApi": {
          "id": "K5ShhbHnt545AI0J",
          "name": "Jira n8n Demo GDG Conn"
        }
      }
    }
  ],
  "pinData": {},
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "(TA-01) Teams Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Vertex Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "(TA-01) Teams Agent",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Structured Output Parser",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "TA-01": {
      "ai_memory": [
        [
          {
            "node": "(TA-01) Teams Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "TA-01 - Get Microsoft Teams post ID": {
      "ai_tool": [
        [
          {
            "node": "(TA-01) Teams Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "TA-01 - Get Microsoft Teams post replies": {
      "ai_tool": [
        [
          {
            "node": "(TA-01) Teams Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "(TA-01) Teams Agent": {
      "main": [
        [
          {
            "node": "if message available",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "(TA-01) Teams Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "if message available": {
      "main": [
        [
          {
            "node": "if we can start",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "check_again command",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "check_again command": {
      "main": [
        [
          {
            "node": "(TA-01) Teams Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "if we can start": {
      "main": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait1": {
      "main": [
        [
          {
            "node": "check_again when inProgress",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Google Vertex Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Structured Output Parser1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "GAWA-01": {
      "ai_memory": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "GAWA-01 - Run GitHub Workflow Tool": {
      "ai_tool": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "(GAWA-01) GitHub Actions Workflow Agent": {
      "main": [
        [
          {
            "node": "in progress",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GAWA-01 - Get GitHub Workflow Build ID Tool": {
      "ai_tool": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "GAWA-01 - Get GitHub Workflow Build ID Status Tool": {
      "ai_tool": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Compression": {
      "main": [
        [
          {
            "node": "Extract from File",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract from File": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "check_again when inProgress": {
      "main": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "was successful": {
      "main": [
        [],
        [
          {
            "node": "Logs Download",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "in progress": {
      "main": [
        [
          {
            "node": "Wait1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "was successful",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Logs Download": {
      "main": [
        [
          {
            "node": "Compression",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Hypothesis Generator 1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Hypothesis Generator 2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Hypothesis Generator 3",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser1": {
      "ai_outputParser": [
        [
          {
            "node": "(GAWA-01) GitHub Actions Workflow Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "VertexAI3": {
      "ai_languageModel": [
        [
          {
            "node": "Hypothesis Generator 1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "VertexAI5": {
      "ai_languageModel": [
        [
          {
            "node": "Hipothesis Voting Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory5": {
      "ai_memory": [
        [
          {
            "node": "Hipothesis Voting Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser7": {
      "ai_outputParser": [
        [
          {
            "node": "Hipothesis Voting Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Google Vertex Chat Model7": {
      "ai_languageModel": [
        [
          {
            "node": "Structured Output Parser7",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Merge4": {
      "main": [
        [
          {
            "node": "Edit Fields5",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields1": {
      "main": [
        [
          {
            "node": "Merge4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "VertexAI": {
      "ai_languageModel": [
        [
          {
            "node": "Hypothesis Generator 2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "VertexAI4": {
      "ai_languageModel": [
        [
          {
            "node": "Hypothesis Generator 3",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields3": {
      "main": [
        [
          {
            "node": "Merge4",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Edit Fields4": {
      "main": [
        [
          {
            "node": "Merge4",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Hypothesis Generator 1": {
      "main": [
        [
          {
            "node": "Edit Fields1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Hypothesis Generator 2": {
      "main": [
        [
          {
            "node": "Edit Fields3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Hypothesis Generator 3": {
      "main": [
        [
          {
            "node": "Edit Fields4",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields2": {
      "main": [
        [
          {
            "node": "Hypothesis Generator 1",
            "type": "main",
            "index": 0
          },
          {
            "node": "Hypothesis Generator 2",
            "type": "main",
            "index": 0
          },
          {
            "node": "Hypothesis Generator 3",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "Edit Fields10",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields5": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Edit Fields6": {
      "main": [
        []
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "Hipothesis Voting Agent",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields7": {
      "main": [
        []
      ]
    },
    "Hipothesis Voting Agent": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Edit Fields9": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields8": {
      "main": [
        [
          {
            "node": "Merge2",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Google Vertex Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    },
    "Merge2": {
      "main": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Structured Output Parser2": {
      "ai_outputParser": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Google Vertex Chat Model8": {
      "ai_languageModel": [
        [
          {
            "node": "Structured Output Parser2",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields10": {
      "main": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait2": {
      "main": [
        [
          {
            "node": "check_again when inProgress1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Jira Manager Agent": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [],
        [
          {
            "node": "Wait2",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "check_again when inProgress1": {
      "main": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get_the_status_of_an_issue_in_Jira_Software": {
      "ai_tool": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Create_an_issue_in_Jira_Software": {
      "ai_tool": [
        [
          {
            "node": "Jira Manager Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "22d7e781-9f05-4882-9ff2-756680eddb20",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "cc2f27e4a152ecba6e67e94e8d113f2bc4c959d72815a37d408dc76ee4fffa7a"
  },
  "id": "BoAxxpBIOf9B2co8",
  "tags": [
    {
      "updatedAt": "2025-11-17T08:28:00.596Z",
      "createdAt": "2025-11-17T08:28:00.596Z",
      "id": "1fyQ2cLs47TRiwrh",
      "name": "gdg"
    },
    {
      "updatedAt": "2025-11-17T08:28:03.606Z",
      "createdAt": "2025-11-17T08:28:03.606Z",
      "id": "e9uQulLQJ94QYpxZ",
      "name": "devfest"
    },
    {
      "updatedAt": "2025-11-17T08:28:07.547Z",
      "createdAt": "2025-11-17T08:28:07.547Z",
      "id": "pEMFb8GXGgc8khus",
      "name": "tijuana"
    },
    {
      "updatedAt": "2025-11-17T08:28:05.605Z",
      "createdAt": "2025-11-17T08:28:05.605Z",
      "id": "sCAzwNQunuXNw4uW",
      "name": "2025"
    }
  ]
}